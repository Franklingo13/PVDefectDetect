{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el archivo `unet_model.py` utilizado en este tutorial es solo para demostración.\n",
    "El autor original de `unet_model.py` es Supervisely.\n",
    "Consultar README de pv-vision y `unet_model.py` para conocer los términos de uso.\n",
    "Puede cambiar el modelo aquí con otros pesos para uso personal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from unet_model import construct_unet\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images\n",
    "import os\n",
    "\n",
    "# Importar Model Handler\n",
    "from pv_vision.nn import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will put this method into util in the future\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\" Clase para cargar el dataset de segmentación de paneles solares. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 image_folder, \n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        super().__init__(root, transforms)\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} not found.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} not found.\")\n",
    "\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        index = np.arange(len(self.image_list))\n",
    "        np.random.shuffle(index)\n",
    "        self.image_list = self.image_list[index]\n",
    "        self.mask_list = self.mask_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __getraw__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: Image doesn't match with mask\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.__getraw__(index)\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase Compose, realiza una serie de transformaciones a la imagen y la máscara\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: a list of transform\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: input image\n",
    "        target: input mask\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "# Clase FixResize, redimensiona la imagen y la máscara a un tamaño específico\n",
    "class FixResize:\n",
    "    # UNet requires input size to be multiple of 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "# Clase RandomHorizontalFlip, realiza un flip horizontal a la imagen y la máscara\n",
    "class ToTensor:\n",
    "    \"\"\"Transform the image to tensor. Scale the image to [0,1] float32.\n",
    "    Transform the mask to tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Clase RandomHorizontalFlip, realiza un flip horizontal a la imagen y la máscara\n",
    "class PILToTensor:\n",
    "    \"\"\"Transform the image to tensor. Keep raw type.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Clase RandomHorizontalFlip, realiza un flip horizontal a la imagen y la máscara\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de imágenes\n",
    "#images = [cv.imread(file) for file in list_images('/home/franklin/PVDefectDetect/TestsPV-vision/examples/crack_segmentation/img_for_prediction')]\n",
    "#images = [cv.imread(file) for file in list_images('/home/franklin/PVDefectDetect/Test_crack')]\n",
    "image_path = 'D:/Documentos/Universidad de Cuenca/Trabajo de Titulación/Datasets_EL/CeldasIndividuales/Mono2_V40_I5_t28'\n",
    "images = [cv.imread(file) for file in list_images(image_path)]\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "\n",
    "origin_path = 'D:/Documentos/Universidad de Cuenca/Trabajo de Titulación/CellAnotation_no_humanMasks/dataset_cells'\n",
    "\n",
    "valset = SolarDataset(root=origin_path, image_folder='images', \n",
    "                      mask_folder='annotations', transforms = transformers)\n",
    "\n",
    "# Verificar que las imágenes se cargaron correctamente\n",
    "print(f'Número de imágenes: {len(images)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código define una clase `myDataset` que hereda de la clase `Dataset` de PyTorch. Esta clase se utiliza para cargar y transformar las imágenes que se pasarán al modelo. La transformación se aplica a cada imagen cuando se accede a ella, no todas a la vez al principio. Esto es más eficiente en términos de memoria, especialmente cuando se trabaja con conjuntos de datos grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una clase personalizada que hereda de Dataset\n",
    "class myDataset(Dataset):\n",
    "    # El método de inicialización se llama cuando se crea una instancia de la clase\n",
    "    def __init__(self, images, transform):\n",
    "        # Guardar las imágenes y la transformación como atributos de la instancia\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    # El método __len__ devuelve el número de elementos en el conjunto de datos\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # El método __getitem__ se utiliza para obtener un elemento del conjunto de datos\n",
    "    def __getitem__(self, idx):\n",
    "        # Redimensionar la imagen al tamaño deseado\n",
    "        image = cv.resize(self.images[idx], (256, 256))\n",
    "        # Aplicar la transformación a la imagen\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        # Devolver la imagen transformada\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código define una transformación que se aplica a las imágenes antes de pasarlas al modelo. La transformación consta de dos pasos: convertir la imagen a un tensor de PyTorch y normalizar los valores de los píxeles. Luego, se crea una instancia de la clase `myDataset` que se utiliza para cargar y transformar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la transformación de las imágenes que se pasará al manejador del modelo\n",
    "transform = transforms.Compose([\n",
    "    # Convertir la imagen a un tensor de PyTorch y escalar los valores de los píxeles entre 0 y 1\n",
    "    transforms.ToTensor(),\n",
    "    # Normalizar cada canal de color de la imagen. Los valores de la media y la desviación estándar se especifican para cada canal (RGB). \n",
    "    # Estos valores son los valores de media y desviación estándar del conjunto de datos ImageNet.\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Crear una instancia de la clase myDataset. Esta clase es un tipo personalizado de Dataset que se utiliza para cargar y transformar las imágenes.\n",
    "# La lista de imágenes y la transformación compuesta se pasan como argumentos al inicializar el conjunto de datos.\n",
    "imgset = myDataset(images, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de pesos del modelo\n",
    "\n",
    "#weight_path = '/home/franklin/supervisely/neural network weights/crack_segmentation/unet_oversample_low_final_model_for_paper/model.pt'\n",
    "weight_path = 'D:/Documentos/PV_Vision/Neural_Network_W/crack_segmentation/unet_oversample_low_final_model_for_paper/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Definir el dispositivo en el que se ejecutará el modelo. Si hay una GPU disponible, se utilizará. De lo contrario, se utilizará la CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Dispositivo: {device}')\n",
    "\n",
    "# Crear una instancia del modelo U-Net con 5 canales de salida. \n",
    "# El número de canales de salida generalmente corresponde al número de clases que el modelo está diseñado para predecir.\n",
    "unet = construct_unet(5)\n",
    "\n",
    "# Envolver el modelo en un objeto DataParallel. \n",
    "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
    "unet = DataParallel(unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código define el dispositivo en el que se ejecutará el modelo (GPU si está disponible, de lo contrario CPU), crea una instancia del modelo U-Net, y luego envuelve el modelo en un objeto `DataParallel` para permitir la ejecución en paralelo en múltiples GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el manejador del modelo (ModelHandler). \n",
    "# Este objeto se encargará de la gestión del modelo, incluyendo la carga de los datos, la ejecución del modelo y el almacenamiento de los resultados.\n",
    "modelhandler = ModelHandler(\n",
    "    # El modelo que se va a utilizar. En este caso, es la instancia de U-Net que se ha creado anteriormente.\n",
    "    model=unet,\n",
    "    # El conjunto de datos que se utilizará para las pruebas. En este caso, es el conjunto de imágenes que se ha cargado y transformado anteriormente.\n",
    "    test_dataset=imgset,\n",
    "    # Indica que sólo se realizarán predicciones, no se entrenará el modelo.\n",
    "    predict_only=True,\n",
    "    # El tamaño del lote que se utilizará durante la validación. En este caso, se procesarán 2 imágenes a la vez.\n",
    "    batch_size_val=2,\n",
    "    # El dispositivo en el que se ejecutará el modelo. En este caso, es el dispositivo que hemos definido anteriormente (GPU si está disponible, de lo contrario CPU).\n",
    "    device=device,\n",
    "    # El directorio donde se guardarán los resultados. En este caso, los resultados se guardarán en un directorio llamado 'output'.\n",
    "    save_dir='D:/Documentos/Universidad de Cuenca/Trabajo de Titulación/Predicciones/Modulos/Celdas/output',\n",
    "    # El nombre que se utilizará para guardar los resultados. En este caso, los resultados se guardarán con el nombre 'unet_prediction'.\n",
    "    save_name='unet_cell_prediction'\n",
    ")\n",
    "\n",
    "# Cargar los pesos del modelo desde el archivo especificado por 'weight_path'.\n",
    "# Esto permite utilizar un modelo que ha sido entrenado previamente, en lugar de tener que entrenar el modelo desde cero.\n",
    "modelhandler.load_model(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El código anterior inicializa un objeto `ModelHandler` que se encargará de la gestión del modelo, incluyendo la carga de los datos, la ejecución del modelo y el almacenamiento de los resultados. Luego, carga los pesos del modelo desde un archivo especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DataParallel(DeepLab_pretrained(5))\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize modelhandler\n",
    "# The output is stored in the output folder\n",
    "modelhandler = ModelHandler(\n",
    "    model=model,\n",
    "    model_output='out',\n",
    "    train_dataset=trainset,\n",
    "    val_dataset=valset,\n",
    "    test_dataset=testset,\n",
    "    batch_size_train=32,\n",
    "    batch_size_val=32,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    num_epochs=10,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    save_dir='checkpoints',\n",
    "    save_name='deeplab.pt'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
