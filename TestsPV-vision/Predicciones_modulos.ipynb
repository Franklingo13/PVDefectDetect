{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el archivo `unet_model.py` utilizado en este tutorial es solo para demostración.\n",
    "El autor original de `unet_model.py` es Supervisely.\n",
    "Consultar README de pv-vision y `unet_model.py` para conocer los términos de uso.\n",
    "Puede cambiar el modelo aquí con otros pesos para uso personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from unet_model import construct_unet\n",
    "\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Model Handler\n",
    "from pv_vision.nn import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de imágenes\n",
    "#images = [cv.imread(file) for file in list_images('/home/franklin/PVDefectDetect/TestsPV-vision/examples/crack_segmentation/img_for_prediction')]\n",
    "#images = [cv.imread(file) for file in list_images('/home/franklin/PVDefectDetect/Test_crack')]\n",
    "images = [cv.imread(file) for file in list_images('D:/Documentos/Universidad de Cuenca/Trabajo de Titulación/PVDefectDetect/Test_crack')]\n",
    "\n",
    "# Carpeta con imágenes editadas con ImageJ /home/franklin/supervisely/Croped_images\n",
    "#images = [cv.imread(file) for file in list_images('/home/franklin/supervisely/Croped_images')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las imágenes se cargaron correctamente\n",
    "print(f'Número de imágenes: {len(images)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código define una clase `myDataset` que hereda de la clase `Dataset` de PyTorch. Esta clase se utiliza para cargar y transformar las imágenes que se pasarán al modelo. La transformación se aplica a cada imagen cuando se accede a ella, no todas a la vez al principio. Esto es más eficiente en términos de memoria, especialmente cuando se trabaja con conjuntos de datos grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una clase personalizada que hereda de Dataset\n",
    "class myDataset(Dataset):\n",
    "    # El método de inicialización se llama cuando se crea una instancia de la clase\n",
    "    def __init__(self, images, transform):\n",
    "        # Guardar las imágenes y la transformación como atributos de la instancia\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    # El método __len__ devuelve el número de elementos en el conjunto de datos\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # El método __getitem__ se utiliza para obtener un elemento del conjunto de datos\n",
    "    def __getitem__(self, idx):\n",
    "        # Redimensionar la imagen al tamaño deseado\n",
    "        image = cv.resize(self.images[idx], (256, 256))\n",
    "        # Aplicar la transformación a la imagen\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        # Devolver la imagen transformada\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código define una transformación que se aplica a las imágenes antes de pasarlas al modelo. La transformación consta de dos pasos: convertir la imagen a un tensor de PyTorch y normalizar los valores de los píxeles. Luego, se crea una instancia de la clase `myDataset` que se utiliza para cargar y transformar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la transformación de las imágenes que se pasará al manejador del modelo\n",
    "transform = transforms.Compose([\n",
    "    # Convertir la imagen a un tensor de PyTorch y escalar los valores de los píxeles entre 0 y 1\n",
    "    transforms.ToTensor(),\n",
    "    # Normalizar cada canal de color de la imagen. Los valores de la media y la desviación estándar se especifican para cada canal (RGB). \n",
    "    # Estos valores son los valores de media y desviación estándar del conjunto de datos ImageNet.\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Crear una instancia de la clase myDataset. Esta clase es un tipo personalizado de Dataset que se utiliza para cargar y transformar las imágenes.\n",
    "# La lista de imágenes y la transformación compuesta se pasan como argumentos al inicializar el conjunto de datos.\n",
    "imgset = myDataset(images, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de pesos del modelo\n",
    "\n",
    "#weight_path = '/home/franklin/supervisely/neural network weights/crack_segmentation/unet_oversample_low_final_model_for_paper/model.pt'\n",
    "weight_path = 'D:/Documentos/PV_Vision/Neural_Network_W/crack_segmentation/unet_oversample_low_final_model_for_paper/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el dispositivo en el que se ejecutará el modelo. Si hay una GPU disponible, se utilizará. De lo contrario, se utilizará la CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Dispositivo: {device}')\n",
    "\n",
    "# Crear una instancia del modelo U-Net con 5 canales de salida. \n",
    "# El número de canales de salida generalmente corresponde al número de clases que el modelo está diseñado para predecir.\n",
    "unet = construct_unet(5)\n",
    "\n",
    "# Envolver el modelo en un objeto DataParallel. \n",
    "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
    "unet = DataParallel(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el manejador del modelo (ModelHandler). \n",
    "# Este objeto se encargará de la gestión del modelo, incluyendo la carga de los datos, la ejecución del modelo y el almacenamiento de los resultados.\n",
    "modelhandler = ModelHandler(\n",
    "    # El modelo que se va a utilizar. En este caso, es la instancia de U-Net que se ha creado anteriormente.\n",
    "    model=unet,\n",
    "    # El conjunto de datos que se utilizará para las pruebas. En este caso, es el conjunto de imágenes que se ha cargado y transformado anteriormente.\n",
    "    test_dataset=imgset,\n",
    "    # Indica que sólo se realizarán predicciones, no se entrenará el modelo.\n",
    "    predict_only=True,\n",
    "    # El tamaño del lote que se utilizará durante la validación. En este caso, se procesarán 2 imágenes a la vez.\n",
    "    batch_size_val=2,\n",
    "    # El dispositivo en el que se ejecutará el modelo. En este caso, es el dispositivo que hemos definido anteriormente (GPU si está disponible, de lo contrario CPU).\n",
    "    device=device,\n",
    "    # El directorio donde se guardarán los resultados. En este caso, los resultados se guardarán en un directorio llamado 'output'.\n",
    "    save_dir='output',\n",
    "    # El nombre que se utilizará para guardar los resultados. En este caso, los resultados se guardarán con el nombre 'unet_prediction'.\n",
    "    save_name='unet_prediction'\n",
    ")\n",
    "\n",
    "# Cargar los pesos del modelo desde el archivo especificado por 'weight_path'.\n",
    "# Esto permite utilizar un modelo que ha sido entrenado previamente, en lugar de tener que entrenar el modelo desde cero.\n",
    "modelhandler.load_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el modelo en el conjunto de datos de prueba.\n",
    "# Esto generará predicciones para cada imagen en el conjunto de datos.\n",
    "masks = modelhandler.predict(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definió una transformación para redimensionar las imágenes a 256x256 y convertirlas a tensores de PyTorch.\n",
    "resize = transforms.Compose([transforms.Resize((256, 256)), transforms.PILToTensor()])\n",
    "\n",
    "# Se definió un mapa de colores para las diferentes clases de máscaras.\n",
    "color_map = {\n",
    "    'dark': (68, 114, 148),\n",
    "    'cross': (77, 137, 99),\n",
    "    'crack': (165, 59, 63),\n",
    "    'busbar': (222, 156, 83)\n",
    "}\n",
    "\n",
    "# Se definió una función para obtener las máscaras de las predicciones del modelo.\n",
    "def get_masks(masks_raw):\n",
    "    # Se creó una lista vacía para almacenar las máscaras.\n",
    "    masks_each = []\n",
    "    # Se aplicó la función softmax a las predicciones del modelo y se obtuvo la clase con la mayor probabilidad para cada píxel.\n",
    "    masks_all = torch.nn.functional.softmax(torch.from_numpy(masks_raw), dim=1).argmax(dim=1)\n",
    "    # Para cada máscara en masks_all, se crearon máscaras booleanas para cada clase y se añadieron a la lista masks_each.\n",
    "    for masks in masks_all:\n",
    "        busbar = masks==1\n",
    "        crack = masks==2\n",
    "        cross = masks==3\n",
    "        dark = masks==4\n",
    "        masks_each.append(torch.dstack([busbar, crack, cross, dark]).permute(2, 0, 1))\n",
    "    return masks_each\n",
    "\n",
    "# Se definió una función para dibujar las máscaras sobre las imágenes.\n",
    "def draw_mask(img, masks, colors=color_map, alpha=0.6):\n",
    "    # Se convirtió la imagen a un objeto de la clase Image de PIL y se redimensionó.\n",
    "    img = Image.fromarray(img)\n",
    "    img = resize(img)\n",
    "    # Se dibujaron las máscaras sobre la imagen con la opacidad especificada y se devolvió la imagen resultante.\n",
    "    combo = draw_segmentation_masks(img, masks, alpha=alpha, colors=[colors[key] for key in ['busbar', 'crack', 'cross', 'dark']])\n",
    "    return F.to_pil_image(combo)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
