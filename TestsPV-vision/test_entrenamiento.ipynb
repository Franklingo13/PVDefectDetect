{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuaderno de prueba para testear la capacidad de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el manejador de modelo: ModelHandler\n",
    "from pv_vision.nn import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definió una clase para el conjunto de datos solar, que hereda de la clase VisionDataset de PyTorch.\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
    "    \n",
    "    # Se definió el método de inicialización para la clase.\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 image_folder, \n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        # Se llamó al método de inicialización de la clase padre.\n",
    "        super().__init__(root, transforms)\n",
    "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
    "\n",
    "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
    "        np.random.seed(random_seed)\n",
    "        index = np.arange(len(self.image_list))\n",
    "        np.random.shuffle(index)\n",
    "        self.image_list = self.image_list[index]\n",
    "        self.mask_list = self.mask_list[index]\n",
    "\n",
    "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
    "    def __getraw__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.__getraw__(index)\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El código anterior define una clase para un conjunto de datos de imágenes solares. La clase tiene métodos para obtener la longitud del conjunto de datos, obtener el nombre de una imagen o máscara, obtener una imagen y su máscara correspondiente, y obtener un elemento del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definió una clase para componer varias transformaciones.\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: una lista de transformaciones\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: imagen de entrada\n",
    "        target: máscara de entrada\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
    "class FixResize:\n",
    "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    # Se definió el método para redimensionar la imagen y la máscara.\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
    "class ToTensor:\n",
    "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
    "    Transforma la máscara a tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
    "class PILToTensor:\n",
    "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para normalizar la imagen.\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    # Se definió el método para normalizar la imagen.\n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El código anterior define varias clases para transformaciones de imágenes y máscaras, incluyendo la composición de varias transformaciones, el redimensionamiento a un tamaño fijo, la transformación a tensores y la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las imágenes y etiquetas son solo para demostración tutorial.\n",
    "# El conjunto de datos completo que usamos para el desarrollo del modelo se puede encontrar aquí:\n",
    "# https://datahub.duramat.org/dataset/00b29daf-239c-47b6-bd96-bfb0875179a8/resource/c6626a05-e82f-4732-ade9-ec5441b83e46/download/crack_segmentation.zip\n",
    "\n",
    "# Se establece la ruta al directorio raíz que contiene las imágenes y las etiquetas.\n",
    "root = Path('/home/franklin/PV_vision/pv-vision/examples/crack_segmentation/img_label_for_training')\n",
    "\n",
    "\n",
    "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "\n",
    "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
    "trainset = SolarDataset(root, image_folder=\"train/img\", \n",
    "        mask_folder=\"train/ann\", transforms=transformers)\n",
    "\n",
    "valset = SolarDataset(root, image_folder=\"val/img\", \n",
    "        mask_folder=\"val/ann\", transforms=transformers)\n",
    "\n",
    "testset = SolarDataset(root, image_folder=\"testset/img\", \n",
    "        mask_folder=\"testset/ann\", transforms=transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código define la ruta al directorio raíz que contiene las imágenes y las etiquetas, las transformaciones a aplicar a las imágenes y las etiquetas, y crea los conjuntos de datos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El conjunto de datos de entrenamiento contiene 972 elementos.\n"
     ]
    }
   ],
   "source": [
    "# Verificación de que la carpeta haya sido establecida correctamente\n",
    "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una función para crear un modelo DeepLab preentrenado.\n",
    "def DeepLab_pretrained(num_classes):\n",
    "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
    "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
    "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
    "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
    "    \n",
    "    # Se devuelve el modelo modificado.\n",
    "    return deeplab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código define una función para crear un modelo DeepLab preentrenado con una arquitectura ResNet50 y reemplazar su clasificador con un nuevo clasificador que tiene un número específico de características de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Se define el dispositivo en el que se ejecutará el modelo. Si hay una GPU disponible, se usará. De lo contrario, se usará la CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se imprime el dispositivo utilizado.\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente. \n",
    "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
    "model = DataParallel(DeepLab_pretrained(5))\n",
    "\n",
    "# Se define la función de pérdida a utilizar durante el entrenamiento. En este caso, se utiliza la pérdida de entropía cruzada.\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento. \n",
    "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
    "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El código anterior define el dispositivo en el que se ejecutará el modelo, crea el modelo, define la función de pérdida, el optimizador y el programador de la tasa de aprendizaje a utilizar durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el manejador del modelo.\n",
    "# La salida se almacena en la carpeta de salida.\n",
    "modelhandler = ModelHandler(\n",
    "    # Se pasa el modelo que se va a entrenar.\n",
    "    model=model,\n",
    "    \n",
    "    # Se especifica el nombre de la carpeta de salida.\n",
    "    model_output='out',\n",
    "    \n",
    "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
    "    train_dataset=trainset,\n",
    "    val_dataset=valset,\n",
    "    test_dataset=testset,\n",
    "    \n",
    "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
    "    batch_size_train=32,\n",
    "    batch_size_val=32,\n",
    "    \n",
    "    # Se pasa el programador de la tasa de aprendizaje.\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    \n",
    "    # Se especifica el número de épocas para el entrenamiento.\n",
    "    num_epochs=10,\n",
    "    \n",
    "    # Se pasa la función de pérdida y el optimizador.\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    \n",
    "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
    "    device=device,\n",
    "    \n",
    "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
    "    save_dir='checkpoints',\n",
    "    \n",
    "    # Se especifica el nombre del archivo de punto de control.\n",
    "    save_name='deeplab.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código inicializa un manejador de modelo con varios parámetros, incluyendo el modelo a entrenar, los conjuntos de datos de entrenamiento, validación y prueba, el tamaño del lote, el programador de la tasa de aprendizaje, el número de épocas, la función de pérdida, el optimizador, el dispositivo, el directorio de guardado y el nombre del archivo de punto de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrena el modelo. Se debe tener en cuenta que este tutorial solo ejecuta 10 épocas.\n",
    "# En una situación real, puede requerir más iteraciones de entrenamiento.\n",
    "modelhandler.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código entrena el modelo utilizando el manejador de modelo. El número de épocas se especificó al inicializar el manejador de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza el proceso de entrenamiento.\n",
    "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
    "modelhandler.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código traza la pérdida del modelo durante el entrenamiento utilizando el manejador de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
    "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
    "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
    "np.argmin(modelhandler.running_record['val']['loss'])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este código busca la pérdida mínima en el conjunto de validación, que corresponde al mejor modelo. Se suma 1 al índice devuelto por 'np.argmin' porque los índices en Python comienzan en 0, pero las épocas comienzan en 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
