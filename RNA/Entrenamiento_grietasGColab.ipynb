{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "c8aaddf5-1d1d-4a73-f4bf-c6ccfe849a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CffxGlC2G09S",
        "outputId": "292d328a-a7a2-4414-f4bb-21faa61d8140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.1.0)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "ac4a6979-ee74-4162-e69b-6fe0560f99b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1012 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val2/img\",\n",
        "        mask_folder=\"val2/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "b9b8b7af-4fb2-4b03-db1e-350dd4013848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "b5889968-5774-401f-ed8c-6726c668e8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=20,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv3.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "789141c1-34c9-458d-ef95-e70595687a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1012 (0%)]\tLoss: 1.310609\n",
            " 16%|█▌        | 10/64 [01:11<06:00,  6.67s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1012 (16%)]\tLoss: 0.247088\n",
            " 31%|███▏      | 20/64 [02:17<04:48,  6.55s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1012 (31%)]\tLoss: 0.120111\n",
            " 47%|████▋     | 30/64 [03:21<03:38,  6.41s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1012 (47%)]\tLoss: 0.072300\n",
            " 62%|██████▎   | 40/64 [04:27<02:37,  6.57s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1012 (62%)]\tLoss: 0.075209\n",
            " 78%|███████▊  | 50/64 [05:30<01:30,  6.44s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1012 (78%)]\tLoss: 0.086028\n",
            " 94%|█████████▍| 60/64 [06:34<00:25,  6.28s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1012 (94%)]\tLoss: 0.090070\n",
            "100%|██████████| 64/64 [06:56<00:00,  6.51s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 13/13 [02:45<00:00, 12.70s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1857 (train) | 0.1385 (val)\n",
            "Epoch 2 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1012 (0%)]\tLoss: 0.064203\n",
            " 16%|█▌        | 10/64 [00:09<00:52,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1012 (16%)]\tLoss: 0.113115\n",
            " 31%|███▏      | 20/64 [00:19<00:43,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1012 (31%)]\tLoss: 0.075693\n",
            " 47%|████▋     | 30/64 [00:29<00:34,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1012 (47%)]\tLoss: 0.078597\n",
            " 62%|██████▎   | 40/64 [00:40<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1012 (62%)]\tLoss: 0.068127\n",
            " 78%|███████▊  | 50/64 [00:50<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1012 (78%)]\tLoss: 0.084022\n",
            " 94%|█████████▍| 60/64 [01:00<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1012 (94%)]\tLoss: 0.090276\n",
            "100%|██████████| 64/64 [01:04<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.86it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0905 (train) | 0.1127 (val)\n",
            "Epoch 3 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1012 (0%)]\tLoss: 0.067968\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1012 (16%)]\tLoss: 0.095864\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1012 (31%)]\tLoss: 0.052602\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1012 (47%)]\tLoss: 0.085096\n",
            " 62%|██████▎   | 40/64 [00:40<00:24,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1012 (62%)]\tLoss: 0.109847\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1012 (78%)]\tLoss: 0.086802\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1012 (94%)]\tLoss: 0.042223\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.02s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0793 (train) | 0.1250 (val)\n",
            "Epoch 4 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1012 (0%)]\tLoss: 0.078824\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1012 (16%)]\tLoss: 0.057160\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1012 (31%)]\tLoss: 0.078715\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1012 (47%)]\tLoss: 0.066035\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1012 (62%)]\tLoss: 0.060353\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1012 (78%)]\tLoss: 0.059158\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1012 (94%)]\tLoss: 0.085078\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.2580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0778 (train) | 0.2580 (val)\n",
            "Epoch 5 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1012 (0%)]\tLoss: 0.087695\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1012 (16%)]\tLoss: 0.064561\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1012 (31%)]\tLoss: 0.064532\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1012 (47%)]\tLoss: 0.053418\n",
            " 62%|██████▎   | 40/64 [00:40<00:24,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1012 (62%)]\tLoss: 0.048805\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1012 (78%)]\tLoss: 0.056078\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1012 (94%)]\tLoss: 0.067414\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.02s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0702 (train) | 0.1118 (val)\n",
            "Epoch 6 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1012 (0%)]\tLoss: 0.079819\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1012 (16%)]\tLoss: 0.072881\n",
            " 31%|███▏      | 20/64 [00:20<00:45,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1012 (31%)]\tLoss: 0.063789\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1012 (47%)]\tLoss: 0.073259\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1012 (62%)]\tLoss: 0.055568\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1012 (78%)]\tLoss: 0.057528\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1012 (94%)]\tLoss: 0.054244\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0655 (train) | 0.1012 (val)\n",
            "Epoch 7 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1012 (0%)]\tLoss: 0.058353\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1012 (16%)]\tLoss: 0.068087\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1012 (31%)]\tLoss: 0.043437\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1012 (47%)]\tLoss: 0.086817\n",
            " 62%|██████▎   | 40/64 [00:40<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1012 (62%)]\tLoss: 0.045194\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1012 (78%)]\tLoss: 0.055058\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1012 (94%)]\tLoss: 0.055103\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0613 (train) | 0.0915 (val)\n",
            "Epoch 8 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1012 (0%)]\tLoss: 0.085967\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1012 (16%)]\tLoss: 0.037478\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1012 (31%)]\tLoss: 0.077850\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1012 (47%)]\tLoss: 0.053131\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1012 (62%)]\tLoss: 0.060205\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1012 (78%)]\tLoss: 0.044233\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1012 (94%)]\tLoss: 0.052577\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.92it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0583 (train) | 0.0966 (val)\n",
            "Epoch 9 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1012 (0%)]\tLoss: 0.042559\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1012 (16%)]\tLoss: 0.056146\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1012 (31%)]\tLoss: 0.066300\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1012 (47%)]\tLoss: 0.042350\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1012 (62%)]\tLoss: 0.049194\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1012 (78%)]\tLoss: 0.038409\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1012 (94%)]\tLoss: 0.039892\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0579 (train) | 0.1019 (val)\n",
            "Epoch 10 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1012 (0%)]\tLoss: 0.058476\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1012 (16%)]\tLoss: 0.052684\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1012 (31%)]\tLoss: 0.030553\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1012 (47%)]\tLoss: 0.067730\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1012 (62%)]\tLoss: 0.046528\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1012 (78%)]\tLoss: 0.043799\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1012 (94%)]\tLoss: 0.062645\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0540 (train) | 0.1563 (val)\n",
            "Epoch 11 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1012 (0%)]\tLoss: 0.052348\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1012 (16%)]\tLoss: 0.047717\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1012 (31%)]\tLoss: 0.054382\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1012 (47%)]\tLoss: 0.036654\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1012 (62%)]\tLoss: 0.070334\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1012 (78%)]\tLoss: 0.068674\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1012 (94%)]\tLoss: 0.044812\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.88it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0527 (train) | 0.1250 (val)\n",
            "Epoch 12 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1012 (0%)]\tLoss: 0.045028\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1012 (16%)]\tLoss: 0.046204\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1012 (31%)]\tLoss: 0.041112\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1012 (47%)]\tLoss: 0.057973\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1012 (62%)]\tLoss: 0.048949\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1012 (78%)]\tLoss: 0.034897\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1012 (94%)]\tLoss: 0.061777\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.92it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0507 (train) | 0.1463 (val)\n",
            "Epoch 13 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1012 (0%)]\tLoss: 0.047334\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1012 (16%)]\tLoss: 0.041865\n",
            " 31%|███▏      | 20/64 [00:20<00:45,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1012 (31%)]\tLoss: 0.064111\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1012 (47%)]\tLoss: 0.054097\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1012 (62%)]\tLoss: 0.048762\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1012 (78%)]\tLoss: 0.048386\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1012 (94%)]\tLoss: 0.061795\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.1372 (val)\n",
            "Epoch 14 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1012 (0%)]\tLoss: 0.065256\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1012 (16%)]\tLoss: 0.081068\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1012 (31%)]\tLoss: 0.045073\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1012 (47%)]\tLoss: 0.055921\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1012 (62%)]\tLoss: 0.037898\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1012 (78%)]\tLoss: 0.064519\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1012 (94%)]\tLoss: 0.049150\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0483 (train) | 0.1587 (val)\n",
            "Epoch 15 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1012 (0%)]\tLoss: 0.033589\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1012 (16%)]\tLoss: 0.045131\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1012 (31%)]\tLoss: 0.042496\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1012 (47%)]\tLoss: 0.045205\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1012 (62%)]\tLoss: 0.032864\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1012 (78%)]\tLoss: 0.048930\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1012 (94%)]\tLoss: 0.047506\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0477 (train) | 0.1608 (val)\n",
            "Epoch 16 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1012 (0%)]\tLoss: 0.039610\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [160/1012 (16%)]\tLoss: 0.062426\n",
            " 31%|███▏      | 20/64 [00:20<00:45,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1012 (31%)]\tLoss: 0.034229\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [480/1012 (47%)]\tLoss: 0.052018\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1012 (62%)]\tLoss: 0.043353\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [800/1012 (78%)]\tLoss: 0.081894\n",
            " 94%|█████████▍| 60/64 [01:01<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1012 (94%)]\tLoss: 0.058933\n",
            "100%|██████████| 64/64 [01:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.96it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.1511 (val)\n",
            "Epoch 17 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1012 (0%)]\tLoss: 0.060521\n",
            " 16%|█▌        | 10/64 [00:10<00:54,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [160/1012 (16%)]\tLoss: 0.045721\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1012 (31%)]\tLoss: 0.049607\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [480/1012 (47%)]\tLoss: 0.054240\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1012 (62%)]\tLoss: 0.040284\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [800/1012 (78%)]\tLoss: 0.031706\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1012 (94%)]\tLoss: 0.057326\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0463 (train) | 0.1470 (val)\n",
            "Epoch 18 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1012 (0%)]\tLoss: 0.048822\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [160/1012 (16%)]\tLoss: 0.050123\n",
            " 31%|███▏      | 20/64 [00:20<00:45,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1012 (31%)]\tLoss: 0.032500\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [480/1012 (47%)]\tLoss: 0.038467\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1012 (62%)]\tLoss: 0.033953\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [800/1012 (78%)]\tLoss: 0.066188\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1012 (94%)]\tLoss: 0.046622\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0461 (train) | 0.1482 (val)\n",
            "Epoch 19 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1012 (0%)]\tLoss: 0.035770\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [160/1012 (16%)]\tLoss: 0.032540\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1012 (31%)]\tLoss: 0.032858\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [480/1012 (47%)]\tLoss: 0.042692\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1012 (62%)]\tLoss: 0.043031\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [800/1012 (78%)]\tLoss: 0.030595\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1012 (94%)]\tLoss: 0.031384\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.83it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0455 (train) | 0.1608 (val)\n",
            "Epoch 20 / 20\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/64 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1012 (0%)]\tLoss: 0.052951\n",
            " 16%|█▌        | 10/64 [00:09<00:54,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [160/1012 (16%)]\tLoss: 0.041268\n",
            " 31%|███▏      | 20/64 [00:20<00:44,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1012 (31%)]\tLoss: 0.046189\n",
            " 47%|████▋     | 30/64 [00:30<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [480/1012 (47%)]\tLoss: 0.064142\n",
            " 62%|██████▎   | 40/64 [00:41<00:24,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1012 (62%)]\tLoss: 0.034205\n",
            " 78%|███████▊  | 50/64 [00:51<00:14,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [800/1012 (78%)]\tLoss: 0.061502\n",
            " 94%|█████████▍| 60/64 [01:02<00:04,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1012 (94%)]\tLoss: 0.037224\n",
            "100%|██████████| 64/64 [01:06<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0455 (train) | 0.1508 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.1856874977293693,\n",
              "   0.0905339964647067,\n",
              "   0.07928385977217331,\n",
              "   0.07777353402654173,\n",
              "   0.07023091260859146,\n",
              "   0.06546686474867018,\n",
              "   0.061306005380605995,\n",
              "   0.05825951688079966,\n",
              "   0.057892225182103546,\n",
              "   0.05398765998513331,\n",
              "   0.05269777227060597,\n",
              "   0.050689508468501655,\n",
              "   0.0489910677546569,\n",
              "   0.04825238282737054,\n",
              "   0.04766845642754683,\n",
              "   0.047138882072075554,\n",
              "   0.04632553231457005,\n",
              "   0.04608136406646887,\n",
              "   0.04553350561810105,\n",
              "   0.0454771024701388]},\n",
              " 'val': {'loss': [0.13852828261328906,\n",
              "   0.11267631013945835,\n",
              "   0.12496210075006252,\n",
              "   0.25796579369684547,\n",
              "   0.11182551972749756,\n",
              "   0.10118656151178407,\n",
              "   0.09154506816369731,\n",
              "   0.09664972864273118,\n",
              "   0.1018812507027533,\n",
              "   0.15627388590719643,\n",
              "   0.12500944610049086,\n",
              "   0.14627399459117796,\n",
              "   0.13722587053368732,\n",
              "   0.1587420486822361,\n",
              "   0.16084815467276226,\n",
              "   0.15108447994400814,\n",
              "   0.1470473761602146,\n",
              "   0.14821010758964026,\n",
              "   0.1607588783996861,\n",
              "   0.1508027540837846]}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "d47b3e36-16fd-4b03-83bf-8bb4cd29f3c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "5a1f2165-8083-46fd-d7fd-88eda2994110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "d900217c-984f-40f4-c995-301ba8d7a76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unetv3.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unetv3.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "54fd117a-b457-4e4b-b1ba-9b2ebf682a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [05:01<00:00, 13.09s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1434\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}