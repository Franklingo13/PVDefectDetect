{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "016ee6a2-9dd8-4e43-c0a4-fe6255bda48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-13tOJejCxA",
        "outputId": "ae11ad9b-1238-46c6-dd5b-16f2944bb687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Collecting scikit-learn>=1.3.0 (from pv-vision)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 scikit-learn-1.5.1 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "d87818df-16bc-48e8-b22a-9a37e0dabb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1108 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val_resize/img\",\n",
        "        mask_folder=\"val_resize/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, )\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return correct / len(targets)\n",
        "        elif reduction == 'sum':\n",
        "            return correct\n",
        "        else:\n",
        "            raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        self._base[0] += correct\n",
        "        self._base[1] += len(targets)\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0] / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFPZp57F3wK",
        "outputId": "56c5d208-af9b-4cca-d37f-6312e33727b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 63.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "aa9347ef-29c6-4945-dced-a2e30a179191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "a1603277-4660-4241-d3f5-353c0d600467"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=20,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    evaluate_metric= Accuracy,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv5.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "7e01be6c-8993-4091-f92f-4c89237bc01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1108 (0%)]\tLoss: 1.366617\n",
            " 14%|█▍        | 10/70 [02:56<17:27, 17.45s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1108 (14%)]\tLoss: 0.340374\n",
            " 29%|██▊       | 20/70 [05:48<14:15, 17.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1108 (29%)]\tLoss: 0.234579\n",
            " 43%|████▎     | 30/70 [09:01<12:59, 19.49s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1108 (43%)]\tLoss: 0.191212\n",
            " 57%|█████▋    | 40/70 [12:00<08:55, 17.86s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1108 (57%)]\tLoss: 0.153726\n",
            " 71%|███████▏  | 50/70 [14:51<05:42, 17.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1108 (71%)]\tLoss: 0.117130\n",
            " 86%|████████▌ | 60/70 [17:42<02:54, 17.46s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1108 (86%)]\tLoss: 0.114055\n",
            "100%|██████████| 70/70 [20:21<00:00, 17.45s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 13/13 [03:40<00:00, 16.96s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1199\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.2256 (train) | 0.1199 (val)\n",
            "Epoch 2 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1108 (0%)]\tLoss: 0.111389\n",
            " 14%|█▍        | 10/70 [00:08<00:54,  1.10it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1108 (14%)]\tLoss: 0.116320\n",
            " 29%|██▊       | 20/70 [00:18<00:46,  1.08it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1108 (29%)]\tLoss: 0.125160\n",
            " 43%|████▎     | 30/70 [00:27<00:37,  1.08it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1108 (43%)]\tLoss: 0.105270\n",
            " 57%|█████▋    | 40/70 [00:37<00:27,  1.08it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1108 (57%)]\tLoss: 0.067701\n",
            " 71%|███████▏  | 50/70 [00:46<00:18,  1.07it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1108 (71%)]\tLoss: 0.105937\n",
            " 86%|████████▌ | 60/70 [00:56<00:09,  1.07it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1108 (86%)]\tLoss: 0.215328\n",
            "100%|██████████| 70/70 [01:05<00:00,  1.07it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1369\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1153 (train) | 0.1369 (val)\n",
            "Epoch 3 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1108 (0%)]\tLoss: 0.093440\n",
            " 14%|█▍        | 10/70 [00:09<00:56,  1.07it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1108 (14%)]\tLoss: 0.083053\n",
            " 29%|██▊       | 20/70 [00:18<00:47,  1.06it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1108 (29%)]\tLoss: 0.086355\n",
            " 43%|████▎     | 30/70 [00:28<00:37,  1.06it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1108 (43%)]\tLoss: 0.067985\n",
            " 57%|█████▋    | 40/70 [00:38<00:28,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1108 (57%)]\tLoss: 0.075687\n",
            " 71%|███████▏  | 50/70 [00:47<00:18,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1108 (71%)]\tLoss: 0.191314\n",
            " 86%|████████▌ | 60/70 [00:57<00:09,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1108 (86%)]\tLoss: 0.071446\n",
            "100%|██████████| 70/70 [01:06<00:00,  1.04it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.96it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 1.4449\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1056 (train) | 1.4449 (val)\n",
            "Epoch 4 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1108 (0%)]\tLoss: 0.138154\n",
            " 14%|█▍        | 10/70 [00:09<00:57,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1108 (14%)]\tLoss: 0.105759\n",
            " 29%|██▊       | 20/70 [00:19<00:47,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1108 (29%)]\tLoss: 0.096025\n",
            " 43%|████▎     | 30/70 [00:28<00:38,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1108 (43%)]\tLoss: 0.091355\n",
            " 57%|█████▋    | 40/70 [00:38<00:28,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1108 (57%)]\tLoss: 0.125398\n",
            " 71%|███████▏  | 50/70 [00:48<00:19,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1108 (71%)]\tLoss: 0.086239\n",
            " 86%|████████▌ | 60/70 [00:58<00:09,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1108 (86%)]\tLoss: 0.110066\n",
            "100%|██████████| 70/70 [01:07<00:00,  1.03it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1217\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0956 (train) | 0.1217 (val)\n",
            "Epoch 5 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1108 (0%)]\tLoss: 0.102520\n",
            " 14%|█▍        | 10/70 [00:09<00:57,  1.05it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1108 (14%)]\tLoss: 0.079064\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1108 (29%)]\tLoss: 0.101015\n",
            " 43%|████▎     | 30/70 [00:29<00:38,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1108 (43%)]\tLoss: 0.091375\n",
            " 57%|█████▋    | 40/70 [00:38<00:29,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1108 (57%)]\tLoss: 0.072645\n",
            " 71%|███████▏  | 50/70 [00:48<00:19,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1108 (71%)]\tLoss: 0.103577\n",
            " 86%|████████▌ | 60/70 [00:58<00:09,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1108 (86%)]\tLoss: 0.095825\n",
            "100%|██████████| 70/70 [01:08<00:00,  1.02it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0968\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0932 (train) | 0.0968 (val)\n",
            "Epoch 6 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1108 (0%)]\tLoss: 0.060929\n",
            " 14%|█▍        | 10/70 [00:09<00:57,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1108 (14%)]\tLoss: 0.096955\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1108 (29%)]\tLoss: 0.116273\n",
            " 43%|████▎     | 30/70 [00:29<00:38,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1108 (43%)]\tLoss: 0.083238\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1108 (57%)]\tLoss: 0.065206\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1108 (71%)]\tLoss: 0.068908\n",
            " 86%|████████▌ | 60/70 [00:58<00:09,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1108 (86%)]\tLoss: 0.081680\n",
            "100%|██████████| 70/70 [01:08<00:00,  1.02it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0913\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0831 (train) | 0.0913 (val)\n",
            "Epoch 7 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1108 (0%)]\tLoss: 0.075303\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1108 (14%)]\tLoss: 0.056772\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1108 (29%)]\tLoss: 0.093383\n",
            " 43%|████▎     | 30/70 [00:29<00:38,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1108 (43%)]\tLoss: 0.058234\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1108 (57%)]\tLoss: 0.105070\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1108 (71%)]\tLoss: 0.106142\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1108 (86%)]\tLoss: 0.066155\n",
            "100%|██████████| 70/70 [01:08<00:00,  1.02it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0862\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0811 (train) | 0.0862 (val)\n",
            "Epoch 8 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1108 (0%)]\tLoss: 0.072387\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1108 (14%)]\tLoss: 0.060807\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1108 (29%)]\tLoss: 0.087325\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1108 (43%)]\tLoss: 0.068666\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1108 (57%)]\tLoss: 0.088391\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1108 (71%)]\tLoss: 0.066616\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1108 (86%)]\tLoss: 0.072165\n",
            "100%|██████████| 70/70 [01:08<00:00,  1.02it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0974\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0779 (train) | 0.0974 (val)\n",
            "Epoch 9 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1108 (0%)]\tLoss: 0.126054\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1108 (14%)]\tLoss: 0.065504\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1108 (29%)]\tLoss: 0.071060\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1108 (43%)]\tLoss: 0.057267\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1108 (57%)]\tLoss: 0.076415\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1108 (71%)]\tLoss: 0.056984\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1108 (86%)]\tLoss: 0.054526\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.83it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0974\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0739 (train) | 0.0974 (val)\n",
            "Epoch 10 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1108 (0%)]\tLoss: 0.096378\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1108 (14%)]\tLoss: 0.106747\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1108 (29%)]\tLoss: 0.071796\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1108 (43%)]\tLoss: 0.065495\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1108 (57%)]\tLoss: 0.085757\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1108 (71%)]\tLoss: 0.059854\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1108 (86%)]\tLoss: 0.055200\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.96it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0706 (train) | 0.0886 (val)\n",
            "Epoch 11 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1108 (0%)]\tLoss: 0.114726\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1108 (14%)]\tLoss: 0.046010\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1108 (29%)]\tLoss: 0.058819\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1108 (43%)]\tLoss: 0.044364\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1108 (57%)]\tLoss: 0.109077\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1108 (71%)]\tLoss: 0.058741\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1108 (86%)]\tLoss: 0.047889\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.87it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1114\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0672 (train) | 0.1114 (val)\n",
            "Epoch 12 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1108 (0%)]\tLoss: 0.051871\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1108 (14%)]\tLoss: 0.058313\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1108 (29%)]\tLoss: 0.086816\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1108 (43%)]\tLoss: 0.072049\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1108 (57%)]\tLoss: 0.099397\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1108 (71%)]\tLoss: 0.068247\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1108 (86%)]\tLoss: 0.067840\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1075\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0654 (train) | 0.1075 (val)\n",
            "Epoch 13 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1108 (0%)]\tLoss: 0.057936\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1108 (14%)]\tLoss: 0.069985\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1108 (29%)]\tLoss: 0.052960\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1108 (43%)]\tLoss: 0.035818\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1108 (57%)]\tLoss: 0.059762\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1108 (71%)]\tLoss: 0.085257\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1108 (86%)]\tLoss: 0.123607\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1170\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0643 (train) | 0.1170 (val)\n",
            "Epoch 14 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1108 (0%)]\tLoss: 0.043420\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1108 (14%)]\tLoss: 0.064503\n",
            " 29%|██▊       | 20/70 [00:19<00:49,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1108 (29%)]\tLoss: 0.068590\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1108 (43%)]\tLoss: 0.078633\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1108 (57%)]\tLoss: 0.049813\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1108 (71%)]\tLoss: 0.065571\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1108 (86%)]\tLoss: 0.050155\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1334\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0626 (train) | 0.1334 (val)\n",
            "Epoch 15 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1108 (0%)]\tLoss: 0.058529\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1108 (14%)]\tLoss: 0.042901\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1108 (29%)]\tLoss: 0.062885\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1108 (43%)]\tLoss: 0.069143\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1108 (57%)]\tLoss: 0.065719\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1108 (71%)]\tLoss: 0.049383\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1108 (86%)]\tLoss: 0.077606\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.90it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1237\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0624 (train) | 0.1237 (val)\n",
            "Epoch 16 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1108 (0%)]\tLoss: 0.042782\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [160/1108 (14%)]\tLoss: 0.050123\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1108 (29%)]\tLoss: 0.072485\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [480/1108 (43%)]\tLoss: 0.055291\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1108 (57%)]\tLoss: 0.039824\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [800/1108 (71%)]\tLoss: 0.055360\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1108 (86%)]\tLoss: 0.046267\n",
            "100%|██████████| 70/70 [01:08<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1263\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0626 (train) | 0.1263 (val)\n",
            "Epoch 17 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1108 (0%)]\tLoss: 0.061467\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [160/1108 (14%)]\tLoss: 0.057377\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1108 (29%)]\tLoss: 0.049852\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [480/1108 (43%)]\tLoss: 0.033597\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1108 (57%)]\tLoss: 0.046894\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [800/1108 (71%)]\tLoss: 0.082155\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1108 (86%)]\tLoss: 0.047569\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1295\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0614 (train) | 0.1295 (val)\n",
            "Epoch 18 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1108 (0%)]\tLoss: 0.064241\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [160/1108 (14%)]\tLoss: 0.058096\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1108 (29%)]\tLoss: 0.047595\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [480/1108 (43%)]\tLoss: 0.085964\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1108 (57%)]\tLoss: 0.036063\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [800/1108 (71%)]\tLoss: 0.046394\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1108 (86%)]\tLoss: 0.078728\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1343\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0605 (train) | 0.1343 (val)\n",
            "Epoch 19 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1108 (0%)]\tLoss: 0.036140\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [160/1108 (14%)]\tLoss: 0.052603\n",
            " 29%|██▊       | 20/70 [00:19<00:48,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1108 (29%)]\tLoss: 0.072581\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [480/1108 (43%)]\tLoss: 0.051847\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1108 (57%)]\tLoss: 0.061433\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [800/1108 (71%)]\tLoss: 0.075103\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1108 (86%)]\tLoss: 0.039641\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1299\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0610 (train) | 0.1299 (val)\n",
            "Epoch 20 / 20\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1108 (0%)]\tLoss: 0.061952\n",
            " 14%|█▍        | 10/70 [00:09<00:58,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [160/1108 (14%)]\tLoss: 0.052747\n",
            " 29%|██▊       | 20/70 [00:19<00:49,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1108 (29%)]\tLoss: 0.073597\n",
            " 43%|████▎     | 30/70 [00:29<00:39,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [480/1108 (43%)]\tLoss: 0.064062\n",
            " 57%|█████▋    | 40/70 [00:39<00:29,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1108 (57%)]\tLoss: 0.072027\n",
            " 71%|███████▏  | 50/70 [00:49<00:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [800/1108 (71%)]\tLoss: 0.042410\n",
            " 86%|████████▌ | 60/70 [00:59<00:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1108 (86%)]\tLoss: 0.068415\n",
            "100%|██████████| 70/70 [01:09<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.91it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1324\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0604 (train) | 0.1324 (val)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.22560990281698937,\n",
              "   0.11532994911128433,\n",
              "   0.10557414220128249,\n",
              "   0.09558413887820089,\n",
              "   0.093240122152795,\n",
              "   0.08306494505827178,\n",
              "   0.08113660703712422,\n",
              "   0.07792234219045846,\n",
              "   0.073902413195221,\n",
              "   0.07060958808187114,\n",
              "   0.0672334556598956,\n",
              "   0.06535622391459744,\n",
              "   0.06429513672951757,\n",
              "   0.06260344898496294,\n",
              "   0.06238241080826801,\n",
              "   0.06259827789201633,\n",
              "   0.06141442286408765,\n",
              "   0.06050713761080904,\n",
              "   0.06096126389982253,\n",
              "   0.06040702133510087]},\n",
              " 'val': {'loss': [0.1199005060806507,\n",
              "   0.13685219891187622,\n",
              "   1.4449048240010332,\n",
              "   0.12166387555075855,\n",
              "   0.09680336212239614,\n",
              "   0.09125784613737246,\n",
              "   0.08616638318067643,\n",
              "   0.09744297774826607,\n",
              "   0.09738874035637553,\n",
              "   0.08861814773664242,\n",
              "   0.11142436513086644,\n",
              "   0.10748581410181232,\n",
              "   0.11702140827731389,\n",
              "   0.13342599018317897,\n",
              "   0.12368545256009916,\n",
              "   0.12633234044400657,\n",
              "   0.12948332058220374,\n",
              "   0.13428031762198703,\n",
              "   0.1299459555527059,\n",
              "   0.13239170301978181]}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "0dea9a70-4721-4cbc-82f7-13868b035af3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "67504b27-cc80-489f-b630-e1c715d36db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "22947163-24d2-47f0-e007-c11784a109ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints/epoch_7/unetv5.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints/epoch_7/unetv5.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "6608655e-1b1a-4ca1-ccea-2db4afdf07f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [06:23<00:00, 16.68s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.0902\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0902\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
