{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "5c984baf-7e4a-4fac-e04c-2927249e2f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CffxGlC2G09S",
        "outputId": "c3a2caa3-0bb9-4345-8a18-8844da0d517a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.1.0)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "36857021-a6a2-4f7d-ccf6-84d5e864a765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1322 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val2/img\",\n",
        "        mask_folder=\"val2/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFPZp57F3wK",
        "outputId": "f766e13e-8b79-41ba-cdaa-01bf4c91ef0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 67.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "8c71d055-d881-49d2-af08-06d6e800c2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "cfb5feb6-e11f-474c-e9c6-a032fcb22f63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=20,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unetv3.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "446b6c4b-eea8-4a85-cfc7-3975a725f420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1322 (0%)]\tLoss: 1.561277\n",
            " 12%|█▏        | 10/83 [02:58<17:38, 14.50s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1322 (12%)]\tLoss: 0.225379\n",
            " 24%|██▍       | 20/83 [05:20<14:52, 14.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1322 (24%)]\tLoss: 0.138700\n",
            " 36%|███▌      | 30/83 [07:42<12:29, 14.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1322 (36%)]\tLoss: 0.131450\n",
            " 48%|████▊     | 40/83 [10:06<10:11, 14.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1322 (48%)]\tLoss: 0.208181\n",
            " 60%|██████    | 50/83 [12:32<07:58, 14.49s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1322 (60%)]\tLoss: 0.212173\n",
            " 72%|███████▏  | 60/83 [14:55<05:26, 14.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1322 (72%)]\tLoss: 0.176257\n",
            " 84%|████████▍ | 70/83 [17:23<03:07, 14.41s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1120/1322 (84%)]\tLoss: 0.117848\n",
            " 96%|█████████▋| 80/83 [19:47<00:42, 14.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1322 (96%)]\tLoss: 0.076855\n",
            "100%|██████████| 83/83 [20:25<00:00, 14.76s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 13/13 [06:11<00:00, 28.55s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.3572\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.2356 (train) | 0.3572 (val)\n",
            "Epoch 2 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1322 (0%)]\tLoss: 0.114284\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1322 (12%)]\tLoss: 0.124766\n",
            " 24%|██▍       | 20/83 [00:20<01:06,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1322 (24%)]\tLoss: 0.179305\n",
            " 36%|███▌      | 30/83 [00:31<00:56,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1322 (36%)]\tLoss: 0.181743\n",
            " 48%|████▊     | 40/83 [00:42<00:45,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1322 (48%)]\tLoss: 0.086775\n",
            " 60%|██████    | 50/83 [00:52<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1322 (60%)]\tLoss: 0.175965\n",
            " 72%|███████▏  | 60/83 [01:03<00:23,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1322 (72%)]\tLoss: 0.159915\n",
            " 84%|████████▍ | 70/83 [01:13<00:13,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1120/1322 (84%)]\tLoss: 0.086721\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1322 (96%)]\tLoss: 0.153904\n",
            "100%|██████████| 83/83 [01:27<00:00,  1.05s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1132\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1391 (train) | 0.1132 (val)\n",
            "Epoch 3 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1322 (0%)]\tLoss: 0.086440\n",
            " 12%|█▏        | 10/83 [00:10<01:15,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1322 (12%)]\tLoss: 0.119965\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1322 (24%)]\tLoss: 0.098115\n",
            " 36%|███▌      | 30/83 [00:31<00:54,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1322 (36%)]\tLoss: 0.112336\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1322 (48%)]\tLoss: 0.104819\n",
            " 60%|██████    | 50/83 [00:52<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1322 (60%)]\tLoss: 0.143014\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1322 (72%)]\tLoss: 0.091625\n",
            " 84%|████████▍ | 70/83 [01:13<00:13,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1120/1322 (84%)]\tLoss: 0.078151\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1322 (96%)]\tLoss: 0.196864\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.91it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1023\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1228 (train) | 0.1023 (val)\n",
            "Epoch 4 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1322 (0%)]\tLoss: 0.119601\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1322 (12%)]\tLoss: 0.075020\n",
            " 24%|██▍       | 20/83 [00:20<01:04,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1322 (24%)]\tLoss: 0.086702\n",
            " 36%|███▌      | 30/83 [00:30<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1322 (36%)]\tLoss: 0.064223\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1322 (48%)]\tLoss: 0.139067\n",
            " 60%|██████    | 50/83 [00:52<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1322 (60%)]\tLoss: 0.100466\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1322 (72%)]\tLoss: 0.160669\n",
            " 84%|████████▍ | 70/83 [01:12<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1120/1322 (84%)]\tLoss: 0.093801\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1322 (96%)]\tLoss: 0.164098\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.86it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1303\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1170 (train) | 0.1303 (val)\n",
            "Epoch 5 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1322 (0%)]\tLoss: 0.150268\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1322 (12%)]\tLoss: 0.071567\n",
            " 24%|██▍       | 20/83 [00:20<01:04,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1322 (24%)]\tLoss: 0.086187\n",
            " 36%|███▌      | 30/83 [00:30<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1322 (36%)]\tLoss: 0.129764\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1322 (48%)]\tLoss: 0.091225\n",
            " 60%|██████    | 50/83 [00:51<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1322 (60%)]\tLoss: 0.112003\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1322 (72%)]\tLoss: 0.158963\n",
            " 84%|████████▍ | 70/83 [01:12<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1120/1322 (84%)]\tLoss: 0.180391\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1322 (96%)]\tLoss: 0.166709\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.05s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.98it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1379\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1132 (train) | 0.1379 (val)\n",
            "Epoch 6 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1322 (0%)]\tLoss: 0.102400\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1322 (12%)]\tLoss: 0.116545\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1322 (24%)]\tLoss: 0.081829\n",
            " 36%|███▌      | 30/83 [00:30<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1322 (36%)]\tLoss: 0.084746\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1322 (48%)]\tLoss: 0.078758\n",
            " 60%|██████    | 50/83 [00:51<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1322 (60%)]\tLoss: 0.070697\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1322 (72%)]\tLoss: 0.076503\n",
            " 84%|████████▍ | 70/83 [01:12<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1120/1322 (84%)]\tLoss: 0.140216\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1322 (96%)]\tLoss: 0.092569\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.90it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0976\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0982 (train) | 0.0976 (val)\n",
            "Epoch 7 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1322 (0%)]\tLoss: 0.100889\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1322 (12%)]\tLoss: 0.126189\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1322 (24%)]\tLoss: 0.087574\n",
            " 36%|███▌      | 30/83 [00:30<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1322 (36%)]\tLoss: 0.099920\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1322 (48%)]\tLoss: 0.110344\n",
            " 60%|██████    | 50/83 [00:51<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1322 (60%)]\tLoss: 0.086771\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1322 (72%)]\tLoss: 0.076938\n",
            " 84%|████████▍ | 70/83 [01:12<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1120/1322 (84%)]\tLoss: 0.060000\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1322 (96%)]\tLoss: 0.104436\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.85it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1074\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0944 (train) | 0.1074 (val)\n",
            "Epoch 8 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1322 (0%)]\tLoss: 0.083843\n",
            " 12%|█▏        | 10/83 [00:09<01:15,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1322 (12%)]\tLoss: 0.081194\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1322 (24%)]\tLoss: 0.091110\n",
            " 36%|███▌      | 30/83 [00:30<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1322 (36%)]\tLoss: 0.068794\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1322 (48%)]\tLoss: 0.093152\n",
            " 60%|██████    | 50/83 [00:51<00:33,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1322 (60%)]\tLoss: 0.156674\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1322 (72%)]\tLoss: 0.104967\n",
            " 84%|████████▍ | 70/83 [01:12<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1120/1322 (84%)]\tLoss: 0.075320\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1322 (96%)]\tLoss: 0.072871\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.04s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0933 (train) | 0.1000 (val)\n",
            "Epoch 9 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1322 (0%)]\tLoss: 0.092900\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1322 (12%)]\tLoss: 0.105263\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1322 (24%)]\tLoss: 0.109238\n",
            " 36%|███▌      | 30/83 [00:31<00:54,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1322 (36%)]\tLoss: 0.126896\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1322 (48%)]\tLoss: 0.107344\n",
            " 60%|██████    | 50/83 [00:52<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1322 (60%)]\tLoss: 0.081554\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1322 (72%)]\tLoss: 0.065756\n",
            " 84%|████████▍ | 70/83 [01:13<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1120/1322 (84%)]\tLoss: 0.063396\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1322 (96%)]\tLoss: 0.092511\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.05s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.84it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0999\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0917 (train) | 0.0999 (val)\n",
            "Epoch 10 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/83 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1322 (0%)]\tLoss: 0.083313\n",
            " 12%|█▏        | 10/83 [00:09<01:14,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1322 (12%)]\tLoss: 0.097693\n",
            " 24%|██▍       | 20/83 [00:20<01:05,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1322 (24%)]\tLoss: 0.063791\n",
            " 36%|███▌      | 30/83 [00:31<00:54,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1322 (36%)]\tLoss: 0.118616\n",
            " 48%|████▊     | 40/83 [00:41<00:44,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1322 (48%)]\tLoss: 0.077884\n",
            " 60%|██████    | 50/83 [00:52<00:34,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1322 (60%)]\tLoss: 0.080751\n",
            " 72%|███████▏  | 60/83 [01:02<00:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1322 (72%)]\tLoss: 0.061082\n",
            " 84%|████████▍ | 70/83 [01:13<00:13,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1120/1322 (84%)]\tLoss: 0.062858\n",
            " 96%|█████████▋| 80/83 [01:23<00:03,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1322 (96%)]\tLoss: 0.079602\n",
            "100%|██████████| 83/83 [01:26<00:00,  1.05s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 13/13 [00:07<00:00,  1.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1037\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0895 (train) | 0.1037 (val)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.23563915823618692,\n",
              "   0.13912137231469696,\n",
              "   0.12284814896634054,\n",
              "   0.11698763952808915,\n",
              "   0.11322309570485634,\n",
              "   0.09824321500156723,\n",
              "   0.09436049538913906,\n",
              "   0.0933468545732087,\n",
              "   0.09170350329260062,\n",
              "   0.08951800480011551]},\n",
              " 'val': {'loss': [0.35717991688876477,\n",
              "   0.11322671348608813,\n",
              "   0.10229460432112795,\n",
              "   0.13028589484182376,\n",
              "   0.13793997032549773,\n",
              "   0.09762838945805448,\n",
              "   0.10736505238755235,\n",
              "   0.09997916380757267,\n",
              "   0.09993111523031031,\n",
              "   0.10370630763688134]}}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "3f855499-6a86-4dbd-82fc-68b6525ea85f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "eff008ae-aaf5-452a-a0f0-08e914754e35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "0ba22fed-8e88-43b0-df56-971d3ed553a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unetv2.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unetv3.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "acc4b5a1-84ed-4d49-8253-70fc01c80712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [10:30<00:00, 27.43s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.0841\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0841\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
