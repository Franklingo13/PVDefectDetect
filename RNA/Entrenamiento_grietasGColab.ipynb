{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "ca4ae350-f796-448a-bbf4-75f0ce09cd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "dd76d943-d0eb-452c-e505-d524a6cd74a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "8c17d9d4-225e-4a69-c92a-16ff5587fa5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b098056-6aec-44aa-b264-b1cd5b92e8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 75.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "8ef9af52-3606-4890-bc5b-be9dbfbae6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "c22d09d0-98d1-41b8-935d-aed6943f70a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv15.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "521eeec1-bc26-429e-97c4-05e19581c014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=35,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv16.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "41f683d3-6769-4a60-a71a-b2d8991bec93",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.043618\n",
            " 22%|██▏       | 10/46 [02:04<06:14, 10.39s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.056415\n",
            " 43%|████▎     | 20/46 [03:45<04:21, 10.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.072711\n",
            " 65%|██████▌   | 30/46 [05:28<02:44, 10.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.042457\n",
            " 87%|████████▋ | 40/46 [07:14<01:03, 10.61s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.052982\n",
            "100%|██████████| 46/46 [08:11<00:00, 10.68s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [01:00<00:00, 20.05s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0540 (train) | 0.0968 (val)\n",
            "Epoch 2 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.039909\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.038830\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.052097\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.046998\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.065100\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0496 (train) | 0.0998 (val)\n",
            "Epoch 3 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.056057\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.054234\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.061226\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.056677\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.046291\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0501 (train) | 0.0946 (val)\n",
            "Epoch 4 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.046261\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.039587\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.039164\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.050924\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.041113\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0485 (train) | 0.0932 (val)\n",
            "Epoch 5 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.051880\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.061165\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.039230\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.055153\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.036979\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0487 (train) | 0.1097 (val)\n",
            "Epoch 6 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.034346\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.043662\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.063770\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.054181\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.055443\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0473 (train) | 0.0899 (val)\n",
            "Epoch 7 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.043541\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.038068\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.063156\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.042181\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.045150\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0879 (val)\n",
            "Epoch 8 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.040586\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.045571\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.040737\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.042020\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.048482\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0453 (train) | 0.0880 (val)\n",
            "Epoch 9 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.053820\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.035822\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.046854\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.051114\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.044899\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0870 (val)\n",
            "Epoch 10 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.047943\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.053866\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.034164\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.041542\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.035368\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0450 (train) | 0.0865 (val)\n",
            "Epoch 11 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.040401\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.044778\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.070243\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.036995\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.057950\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0446 (train) | 0.0862 (val)\n",
            "Epoch 12 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.053407\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.051061\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.052847\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.043649\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.033048\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0861 (val)\n",
            "Epoch 13 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.049207\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.056469\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.038776\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.036019\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.067351\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0858 (val)\n",
            "Epoch 14 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.053817\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.033414\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.055798\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.037859\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.047245\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0859 (val)\n",
            "Epoch 15 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.046626\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.031488\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.046489\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.057437\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.031737\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0859 (val)\n",
            "Epoch 16 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.035956\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.041222\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.045503\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.042641\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.043091\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0859 (val)\n",
            "Epoch 17 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.043552\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.055870\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.033700\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.044464\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.038604\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0857 (val)\n",
            "Epoch 18 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.041074\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.054396\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.051547\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.043036\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.034905\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0856 (val)\n",
            "Epoch 19 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.039251\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.037733\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.030582\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.049787\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.057300\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0857 (val)\n",
            "Epoch 20 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.056719\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.061129\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.041221\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.044949\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.049128\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0856 (val)\n",
            "Epoch 21 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.041679\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.052498\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.042212\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.041004\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.035256\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0858 (val)\n",
            "Epoch 22 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.040737\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.031646\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.031851\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.050655\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.052859\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0855 (val)\n",
            "Epoch 23 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.036252\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.044872\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.050399\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.043565\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.045034\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0855 (val)\n",
            "Epoch 24 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.047161\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.037754\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.049201\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.037456\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.061059\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0856 (val)\n",
            "Epoch 25 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.037247\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.041150\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.053674\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.048137\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.056819\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0856 (val)\n",
            "Epoch 26 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.046693\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.043942\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.053962\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.043497\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.052790\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0855 (val)\n",
            "Epoch 27 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.040208\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.046310\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.048459\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.040482\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.031820\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0856 (val)\n",
            "Epoch 28 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.045990\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.047774\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.058096\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.045556\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.035575\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0443 (train) | 0.0855 (val)\n",
            "Epoch 29 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.042088\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.048032\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.031687\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.042249\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.049437\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0856 (val)\n",
            "Epoch 30 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.037128\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.039388\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.032167\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.051421\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.041616\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0854 (val)\n",
            "Epoch 31 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.037612\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.052585\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.053505\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.035047\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.055698\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0856 (val)\n",
            "Epoch 32 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.033809\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.071246\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.054981\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.053290\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.043115\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0856 (val)\n",
            "Epoch 33 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.043081\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.041490\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.047793\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.044846\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.041773\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0855 (val)\n",
            "Epoch 34 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.031790\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.061470\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.033700\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.047298\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.041826\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0857 (val)\n",
            "Epoch 35 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.044513\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.054719\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.049866\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.035190\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.039676\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0857 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.05403893795287453,\n",
              "   0.04960371456983905,\n",
              "   0.05005599134547171,\n",
              "   0.048459975814212214,\n",
              "   0.048709650241294894,\n",
              "   0.04734891332065493,\n",
              "   0.04586932943276266,\n",
              "   0.045250820602352505,\n",
              "   0.04556297785451883,\n",
              "   0.044994118872770994,\n",
              "   0.04461720224318632,\n",
              "   0.044472767620848036,\n",
              "   0.04453312002342894,\n",
              "   0.04446600874307766,\n",
              "   0.04449836845674436,\n",
              "   0.044007629858610633,\n",
              "   0.04405137223396027,\n",
              "   0.044114946293486286,\n",
              "   0.044223196209707674,\n",
              "   0.04409111466281839,\n",
              "   0.04424741261697029,\n",
              "   0.04417157586451161,\n",
              "   0.04404577861058655,\n",
              "   0.044058503756134244,\n",
              "   0.044046517071831416,\n",
              "   0.043995329203867374,\n",
              "   0.044184447039900696,\n",
              "   0.04429885581986952,\n",
              "   0.04413530532545003,\n",
              "   0.043989022069463875,\n",
              "   0.044182164347118455,\n",
              "   0.044147382839662984,\n",
              "   0.04418596177677901,\n",
              "   0.04423094206250543,\n",
              "   0.0439994879328458]},\n",
              " 'val': {'loss': [0.09679502000411351,\n",
              "   0.09983135014772415,\n",
              "   0.09458919366200765,\n",
              "   0.09319032977024715,\n",
              "   0.10969956467549007,\n",
              "   0.0899011492729187,\n",
              "   0.08787156144777934,\n",
              "   0.08797487864891688,\n",
              "   0.087009958922863,\n",
              "   0.08653188248475392,\n",
              "   0.08617089440425237,\n",
              "   0.08614307393630345,\n",
              "   0.08582096546888351,\n",
              "   0.08589453001817067,\n",
              "   0.0859413668513298,\n",
              "   0.08585249135891597,\n",
              "   0.08571066707372665,\n",
              "   0.08562545478343964,\n",
              "   0.0857295220096906,\n",
              "   0.08555914958318074,\n",
              "   0.0858321487903595,\n",
              "   0.08554178724686305,\n",
              "   0.08554346611102422,\n",
              "   0.08557018637657166,\n",
              "   0.08559112995862961,\n",
              "   0.08554599930842717,\n",
              "   0.08561166375875473,\n",
              "   0.08551519364118576,\n",
              "   0.08563248813152313,\n",
              "   0.08544488499561946,\n",
              "   0.08561699092388153,\n",
              "   0.08562246213356654,\n",
              "   0.08553081502517064,\n",
              "   0.08570685237646103,\n",
              "   0.08570003509521484]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "2568693e-1d40-452d-86c8-19cef321d4aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "25fd6927-aeaa-4fd0-9ae4-c96a5f36bc7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "4ac21d98-e347-46fe-9a23-3f58eac0a0ac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_10/unetv15.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv16.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "ca76ae45-4464-447f-b578-bb0e75ec0909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:05<00:00, 20.48s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1089\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv16')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}