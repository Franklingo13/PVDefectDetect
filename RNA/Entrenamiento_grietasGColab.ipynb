{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "3eb47b84-40cc-4320-e26e-848da4f9a97e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "e2d71821-2bc6-42c3-9cb6-1b67d7e0b621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "d0dcd158-e287-4c9e-b474-d0698dfec7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "858e6c4d-4b69-45ee-d5a4-7d9b8bf025ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "fae106d1-75ef-4fb1-fd46-dc17f6591628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv16.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "bb355543-de04-46e6-c590-69250d7beee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=40,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv19.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "ec7caaab-7024-431b-9bc7-7278eb49d04a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.045352\n",
            " 22%|██▏       | 10/46 [00:22<00:46,  1.28s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.039537\n",
            " 43%|████▎     | 20/46 [00:34<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.058733\n",
            " 65%|██████▌   | 30/46 [00:45<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.031354\n",
            " 87%|████████▋ | 40/46 [00:57<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.049663\n",
            "100%|██████████| 46/46 [01:04<00:00,  1.41s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0444 (train) | 0.0860 (val)\n",
            "Epoch 2 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.049330\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.039271\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.055624\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.033116\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.056748\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0863 (val)\n",
            "Epoch 3 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.034743\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.046777\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.050603\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.038043\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.040442\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0851 (val)\n",
            "Epoch 4 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.065955\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.033393\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.044395\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.041128\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.040884\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0851 (val)\n",
            "Epoch 5 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.052863\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.044353\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.040394\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.033491\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.040176\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0852 (val)\n",
            "Epoch 6 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.049806\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.057309\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.041745\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.034730\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.040480\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0845 (val)\n",
            "Epoch 7 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.052536\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.031723\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.043289\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.046817\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.049053\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0845 (val)\n",
            "Epoch 8 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.046523\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.058768\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.056504\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.039028\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.048231\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0845 (val)\n",
            "Epoch 9 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.047723\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.039305\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.050158\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.034492\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.032697\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 10 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.044021\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.038728\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.040134\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.039757\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.064935\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0843 (val)\n",
            "Epoch 11 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.054808\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.048522\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.032624\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.033406\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.039059\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 12 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.038678\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.042509\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.058074\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.034659\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.041333\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 13 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.046710\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.044719\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.037927\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.037567\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.044057\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0841 (val)\n",
            "Epoch 14 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.047368\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.031437\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.038211\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.049964\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.043085\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0841 (val)\n",
            "Epoch 15 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.035069\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.051450\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.045916\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.025824\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.044854\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0841 (val)\n",
            "Epoch 16 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.041140\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.055784\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.046134\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.048779\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.028026\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0842 (val)\n",
            "Epoch 17 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.049112\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.043801\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.047505\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.046445\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.045439\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 18 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.047416\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.040583\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.034196\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.035919\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.044307\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0842 (val)\n",
            "Epoch 19 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.036183\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.043370\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.057141\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.033788\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.046182\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0842 (val)\n",
            "Epoch 20 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.043096\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.040944\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.031476\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.052982\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.057691\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0841 (val)\n",
            "Epoch 21 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.043736\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.035400\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.042723\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.036390\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.043179\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0842 (val)\n",
            "Epoch 22 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.049840\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.043718\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.045284\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.045401\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.036652\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0842 (val)\n",
            "Epoch 23 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.029554\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.030675\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.044807\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.042174\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.040261\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 24 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.040935\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.030101\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.045136\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.032369\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.038770\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0842 (val)\n",
            "Epoch 25 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.057181\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.048323\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.038356\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.038050\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.042152\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0841 (val)\n",
            "Epoch 26 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.035523\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.047016\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.047993\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.050687\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.038821\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 27 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.049209\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.041740\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.044037\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.039760\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.059488\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0842 (val)\n",
            "Epoch 28 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.041027\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.043183\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.032455\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.050908\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.045639\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0843 (val)\n",
            "Epoch 29 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.049837\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.055770\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.040752\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.052461\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.045506\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0842 (val)\n",
            "Epoch 30 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.042918\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.057935\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.043231\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.043805\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.053844\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0842 (val)\n",
            "Epoch 31 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.041993\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.040528\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.046715\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.040458\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.034795\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0841 (val)\n",
            "Epoch 32 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.041356\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.045913\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.029628\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.048853\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.054250\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 33 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.055524\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.038623\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.051285\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.036852\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.066740\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 34 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.031285\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.048408\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.044228\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.039425\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.035599\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0842 (val)\n",
            "Epoch 35 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.040491\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.058056\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.041552\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.050059\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.039941\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0841 (val)\n",
            "Epoch 36 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.038862\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.043021\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.058427\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.031239\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.042083\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0842 (val)\n",
            "Epoch 37 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.036692\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.038120\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.043918\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.054105\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.054219\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0841 (val)\n",
            "Epoch 38 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.034356\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.037592\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.032825\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.047755\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.036235\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0842 (val)\n",
            "Epoch 39 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.046418\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.030857\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.048666\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.041601\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.042277\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0841 (val)\n",
            "Epoch 40 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.053547\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.074893\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.050597\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.050075\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.036836\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0842 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.04439410130401685,\n",
              "   0.04421223598004864,\n",
              "   0.044229717121420445,\n",
              "   0.04415291228061779,\n",
              "   0.044006202413514,\n",
              "   0.04365161656871879,\n",
              "   0.04365033556880905,\n",
              "   0.043441880063627474,\n",
              "   0.043477085515784955,\n",
              "   0.043652627529949466,\n",
              "   0.043419671305811,\n",
              "   0.04345698820277074,\n",
              "   0.043270811605211464,\n",
              "   0.04343971349580979,\n",
              "   0.04349374644207035,\n",
              "   0.04349151513932167,\n",
              "   0.04341451172747041,\n",
              "   0.043332424850625495,\n",
              "   0.04333196156090978,\n",
              "   0.04334577335799799,\n",
              "   0.043420219051677936,\n",
              "   0.04343251608881307,\n",
              "   0.04344402719224968,\n",
              "   0.04340318956265594,\n",
              "   0.04338845027083786,\n",
              "   0.043400644840696966,\n",
              "   0.04356323900079407,\n",
              "   0.0436937308832439,\n",
              "   0.043496170975344806,\n",
              "   0.04342451505747567,\n",
              "   0.04329113145112089,\n",
              "   0.04339499330098105,\n",
              "   0.043449200325724344,\n",
              "   0.043263336352578376,\n",
              "   0.04340461094422088,\n",
              "   0.043409779424287497,\n",
              "   0.043319226759860864,\n",
              "   0.04325797039110416,\n",
              "   0.043378092287042924,\n",
              "   0.043666378299449936]},\n",
              " 'val': {'loss': [0.08595242847998937,\n",
              "   0.08629261702299118,\n",
              "   0.08510380238294601,\n",
              "   0.08508725215991338,\n",
              "   0.08523635069529216,\n",
              "   0.08454117923974991,\n",
              "   0.08448459704717,\n",
              "   0.08454439789056778,\n",
              "   0.08427416533231735,\n",
              "   0.08426766594250996,\n",
              "   0.08428260187307994,\n",
              "   0.08431376765171687,\n",
              "   0.08414898564418156,\n",
              "   0.08410161485274632,\n",
              "   0.08405910183986028,\n",
              "   0.0842232033610344,\n",
              "   0.08429911981026332,\n",
              "   0.0842005064090093,\n",
              "   0.08418278644482295,\n",
              "   0.08410771191120148,\n",
              "   0.08419438451528549,\n",
              "   0.08419260134299596,\n",
              "   0.08426417658726375,\n",
              "   0.08421419312556584,\n",
              "   0.08407167593638103,\n",
              "   0.08426815768082936,\n",
              "   0.08417375137408574,\n",
              "   0.08425132681926091,\n",
              "   0.08418988684813182,\n",
              "   0.08418465405702591,\n",
              "   0.08411140243212382,\n",
              "   0.08426837374766667,\n",
              "   0.08426474283138911,\n",
              "   0.08415101220210393,\n",
              "   0.08414844423532486,\n",
              "   0.08420365303754807,\n",
              "   0.08413895467917125,\n",
              "   0.08417681604623795,\n",
              "   0.08414958665768306,\n",
              "   0.08415184915065765]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "e93054e5-b141-4491-ef83-3c409fa8ec6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "3f5c5929-6ca9-41f6-a4f0-5da29a369165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "9be98c58-b4eb-46a2-e862-14fc78bc633f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_15/unetv19.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_15/unetv19.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "1673aadd-6024-4dd2-d17d-25cc07a74366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:07<00:00,  1.54it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1086\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv19')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}