{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "c7a0a67a-10ef-43ff-8e08-f5c02a36f083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "07ea7953-dad9-43ef-d55b-ff2cbb0c2dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "49aa5b14-cef9-4376-daf8-982a547e0655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "outputId": "5d5a4816-05a1-4015-e520-54550ae221f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 207MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "cc26bd7a-e224-4e54-d4a5-b5ccc4138704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "ad255dbe-542c-4fae-89d3-a862f7d2bab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv9.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "7b139a6d-5a94-4bff-8ddd-785a0aecc3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=64,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=30,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv10.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "accebe2f-d424-491d-86dc-f989f6203b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.059411\n",
            " 43%|████▎     | 10/23 [17:32<22:41, 104.71s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.047649\n",
            " 87%|████████▋ | 20/23 [34:46<05:08, 102.88s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.051407\n",
            "100%|██████████| 23/23 [39:21<00:00, 102.68s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [02:20<00:00, 46.78s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0564 (train) | 0.1066 (val)\n",
            "Epoch 2 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.053577\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.38it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.054421\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.050965\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0538 (train) | 0.1076 (val)\n",
            "Epoch 3 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.047262\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.055488\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.060480\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0534 (train) | 0.1049 (val)\n",
            "Epoch 4 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.058011\n",
            " 43%|████▎     | 10/23 [00:08<00:11,  1.14it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.051203\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.049704\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.44it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0534 (train) | 0.1078 (val)\n",
            "Epoch 5 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.053683\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.055610\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.046129\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0522 (train) | 0.1005 (val)\n",
            "Epoch 6 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.054311\n",
            " 43%|████▎     | 10/23 [00:09<00:13,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.048404\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.052168\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.62it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0511 (train) | 0.0988 (val)\n",
            "Epoch 7 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.051371\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.046755\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.38it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.044834\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.32it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0505 (train) | 0.0978 (val)\n",
            "Epoch 8 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.038500\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.050608\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.29it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.050313\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.24it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0500 (train) | 0.0980 (val)\n",
            "Epoch 9 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.053047\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.046436\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.38it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.054830\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0499 (train) | 0.0968 (val)\n",
            "Epoch 10 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.054369\n",
            " 43%|████▎     | 10/23 [00:08<00:11,  1.10it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.050092\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.052579\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.21it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0498 (train) | 0.0967 (val)\n",
            "Epoch 11 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.044985\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.040341\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.046586\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0495 (train) | 0.0963 (val)\n",
            "Epoch 12 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.042056\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.056167\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.039518\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.23it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0493 (train) | 0.0961 (val)\n",
            "Epoch 13 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.039127\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.049684\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.38it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.056124\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.32it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0494 (train) | 0.0961 (val)\n",
            "Epoch 14 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.054823\n",
            " 43%|████▎     | 10/23 [00:08<00:10,  1.20it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.045682\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.38it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.044211\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0493 (train) | 0.0959 (val)\n",
            "Epoch 15 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.053384\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.042927\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.062898\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0491 (train) | 0.0959 (val)\n",
            "Epoch 16 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.040041\n",
            " 43%|████▎     | 10/23 [00:08<00:13,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.057565\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.047622\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.59it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0958 (val)\n",
            "Epoch 17 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.051592\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.051081\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.055865\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.38it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0491 (train) | 0.0957 (val)\n",
            "Epoch 18 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.053579\n",
            " 43%|████▎     | 10/23 [00:08<00:14,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.047114\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.051967\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.23it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0492 (train) | 0.0957 (val)\n",
            "Epoch 19 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.052967\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.043705\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.39it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.051550\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.57it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0489 (train) | 0.0957 (val)\n",
            "Epoch 20 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.042881\n",
            " 43%|████▎     | 10/23 [00:08<00:10,  1.20it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.045207\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.050057\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.23it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0492 (train) | 0.0958 (val)\n",
            "Epoch 21 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.049745\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.044843\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.052099\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.57it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0491 (train) | 0.0956 (val)\n",
            "Epoch 22 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.055953\n",
            " 43%|████▎     | 10/23 [00:08<00:12,  1.08it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.048533\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.046441\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0491 (train) | 0.0957 (val)\n",
            "Epoch 23 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.066179\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.045965\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.042232\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0491 (train) | 0.0957 (val)\n",
            "Epoch 24 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.040405\n",
            " 43%|████▎     | 10/23 [00:09<00:13,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.056218\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.050216\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0957 (val)\n",
            "Epoch 25 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.041630\n",
            " 43%|████▎     | 10/23 [00:07<00:10,  1.30it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.060873\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.39it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.045243\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0489 (train) | 0.0956 (val)\n",
            "Epoch 26 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.052273\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.32it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.037731\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.049613\n",
            "100%|██████████| 23/23 [00:19<00:00,  1.21it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.59it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0489 (train) | 0.0956 (val)\n",
            "Epoch 27 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.045683\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.31it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.046619\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.35it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.045472\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.55it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0956 (val)\n",
            "Epoch 28 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.050646\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.34it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.049631\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.048932\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.22it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0957 (val)\n",
            "Epoch 29 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.054250\n",
            " 43%|████▎     | 10/23 [00:07<00:09,  1.36it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.046033\n",
            " 87%|████████▋ | 20/23 [00:15<00:02,  1.33it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.056045\n",
            "100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0956 (val)\n",
            "Epoch 30 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.047136\n",
            " 43%|████▎     | 10/23 [00:08<00:10,  1.21it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.045972\n",
            " 87%|████████▋ | 20/23 [00:16<00:02,  1.37it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.057977\n",
            "100%|██████████| 23/23 [00:18<00:00,  1.24it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0490 (train) | 0.0956 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.056391908451966066,\n",
              "   0.05376626371168221,\n",
              "   0.053413711011368735,\n",
              "   0.053384081582959896,\n",
              "   0.05221526807267667,\n",
              "   0.05110506034479909,\n",
              "   0.050518340616392744,\n",
              "   0.05002867001514556,\n",
              "   0.049905176893009946,\n",
              "   0.04979486274805384,\n",
              "   0.049453747796544684,\n",
              "   0.049302941104890724,\n",
              "   0.04942452918330473,\n",
              "   0.049293582239851655,\n",
              "   0.049126578585923494,\n",
              "   0.04901745351107056,\n",
              "   0.049075042835327154,\n",
              "   0.04918537023544558,\n",
              "   0.04893900835034114,\n",
              "   0.049225224024332236,\n",
              "   0.04905493734359577,\n",
              "   0.04908242390964742,\n",
              "   0.04911760573069637,\n",
              "   0.04904292389258219,\n",
              "   0.048879453888020674,\n",
              "   0.04893854017390601,\n",
              "   0.049024558772896375,\n",
              "   0.048956479490090465,\n",
              "   0.04904256515456165,\n",
              "   0.04895254453747993]},\n",
              " 'val': {'loss': [0.1066044494509697,\n",
              "   0.10762366155783336,\n",
              "   0.10487136989831924,\n",
              "   0.10775941610336304,\n",
              "   0.1004838968316714,\n",
              "   0.09878652542829514,\n",
              "   0.09777663151423137,\n",
              "   0.09798834721247356,\n",
              "   0.09675110131502151,\n",
              "   0.096650630235672,\n",
              "   0.09629086901744206,\n",
              "   0.09613982091347377,\n",
              "   0.09612337003151576,\n",
              "   0.09592570861180623,\n",
              "   0.09586813300848007,\n",
              "   0.09576898068189621,\n",
              "   0.09574999660253525,\n",
              "   0.09574205428361893,\n",
              "   0.09566924969355266,\n",
              "   0.09575805316368739,\n",
              "   0.09564482420682907,\n",
              "   0.09567192445198695,\n",
              "   0.09565145522356033,\n",
              "   0.09571571399768193,\n",
              "   0.09564900646607082,\n",
              "   0.09563584377368291,\n",
              "   0.09559691945711772,\n",
              "   0.09571817020575206,\n",
              "   0.09561274200677872,\n",
              "   0.09558302909135818]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "k55JhgMyG09V",
        "outputId": "1ae8fe03-b882-40de-ca32-85cc2c1a9fd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGyCAYAAADj6hCHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHJElEQVR4nO3de3wU9b3/8ffuJru5kIRAIOESiAqCCCTKJQZb8ZIa0FoQbSPyO4D16NEKB5tjzwFU8NI2tlVLFY7Utl7aI4JYQeqFiqnQKlHkJqKIhYIEIQkXyZXcduf3xySbLARIwpLZZF7Px2MeO/vd785+ZjKyb78zO+MwDMMQAACAzTitLgAAAMAKhCAAAGBLhCAAAGBLhCAAAGBLhCAAAGBLhCAAAGBLhCAAAGBLhCAAAGBLhCAAAGBLYVYXEIp8Pp8OHDigmJgYORwOq8sBAAAtYBiGysrK1Lt3bzmdLRjnMSy2cOFCo3///obH4zFGjx5tfPTRR6fsu337dmPSpElG//79DUnGr3/965P6rFu3zvjud79r9OrVy5BkrFixotU1FRQUGJKYmJiYmJiYOuBUUFDQou97S0eCli1bppycHC1evFjp6elasGCBsrKytHPnTvXs2fOk/pWVlTr//PP1/e9/Xz/+8Y+bXWZFRYVSU1P1wx/+UJMmTWpTXTExMZKkgoICxcbGtmkZAACgfZWWlio5Odn/PX4mDsOw7gaq6enpGjVqlBYuXCjJPAyVnJysmTNnavbs2ad9b0pKiu69917de++9p+zjcDi0YsUKTZw4sVV1lZaWKi4uTiUlJYQgAAA6iNZ+f1t2YnRNTY02bdqkzMzMxmKcTmVmZio/P79da6murlZpaWnABAAAOjfLQtDhw4fl9XqVmJgY0J6YmKjCwsJ2rSU3N1dxcXH+KTk5uV0/HwAAtD9+Ii9pzpw5Kikp8U8FBQVWlwQAAM4xy06MTkhIkMvlUlFRUUB7UVGRkpKS2rUWj8cjj8fTrp8JALAnn8+nmpoaq8vokMLDw+VyuYK2PMtCkNvt1ogRI5SXl+c/cdnn8ykvL08zZsywqiwAAM6Zmpoa7dmzRz6fz+pSOqyuXbsqKSkpKNfxs/Qn8jk5OZo2bZpGjhyp0aNHa8GCBaqoqNBtt90mSZo6dar69Omj3NxcSebO8/nnn/vnv/76a23dulVdunTRgAEDJEnl5eXatWuX/zP27NmjrVu3qlu3burXr187ryEAACbDMHTw4EG5XC4lJye37GJ+8DMMQ5WVlSouLpYk9erV66yXaWkIys7O1qFDhzRv3jwVFhYqLS1Nq1ev9p8svW/fvoCd5MCBA7rkkkv8zx9//HE9/vjjGjt2rNauXStJ2rhxo6666ip/n5ycHEnStGnT9MILL5z7lQIAoBl1dXWqrKxU7969FRUVZXU5HVJkZKQkqbi4WD179jzrQ2OWXicoVHGdIABAsFVVVWnPnj1KSUnxf5mj9Y4fP669e/fqvPPOU0RERMBrHeY6QQAA2BH3pDw7wdx+hCAAAGBLhCAAANBuUlJStGDBAqvLkGTxidEAACD0XXnllUpLSwtKePn4448VHR199kUFASEILWMYUm2l5A6NHRcAEDoMw5DX61VY2JljRY8ePdqhopbhcFhHcvRf0lfrzUDSnrx10qu3Sbl9pb0ftO9nAwAsNX36dK1bt06/+c1v5HA45HA49MILL8jhcOjtt9/WiBEj5PF49P7772v37t2aMGGCEhMT1aVLF40aNUrvvvtuwPJOPBzmcDj0+9//XjfeeKOioqI0cOBArVq1ql3WjRAU6qpKpU0vSs+Nk566RHp+vPS3R9svCPl80uv3SJ+tkAyf9NHi9vlcAOjkDMNQZU2dJVNrro7zm9/8RhkZGbrjjjt08OBBHTx40H+j8dmzZ+uxxx7Tjh07NHz4cJWXl+u6665TXl6etmzZonHjxumGG27Qvn37TvsZDz/8sH7wgx9o27Ztuu666zRlyhQdPXr0rLZvS3A4LBT5vNKev0tbl0g7/iLVHTfbHU4ziPzjCcnhkq6+/9zWYRjS2z+Rti1t/Oydb0uVR6Wobuf2swGgkzte69WQeX+15LM/fyRLUe6WRYC4uDi53W5FRUX57+35xRdfSJIeeeQRfec73/H37datm1JTU/3PH330Ua1YsUKrVq067S2xpk+frsmTJ0uSfv7zn+upp57Shg0bNG7cuFavW2swEhRKDu+S8h6RFgyT/jRR+vQVMwAlDJIyH5Z+/LmU9XOz799/Ka197NzWk/eI9PHvJTmkG5+VkoZLvlrp01fP7ecCADqEkSNHBjwvLy/Xfffdp4suukhdu3ZVly5dtGPHjjOOBA0fPtw/Hx0drdjYWP/tMc4lRoKsVlUibX9N+uRlqeCjxvaIOGnozVLaFKnPpVLDxaEy7jFHZN55QFqba47QjP3v4Nf1jyel958057/7a2n496XKI9LqbdInS6T0O4P/mQBgI5HhLn3+SJZlnx0MJ/7K67777tOaNWv0+OOPa8CAAYqMjNTNN9+smpqa0y4nPDw84LnD4WiXm8wSgqzg80r/ek/a+rL0xRtSXZXZ7nBKAzKltFulC8dL4RHNv3/MTDMIrZknvfczMyBd8ZPg1bfhd1Lew+b8dx6VRpo3tNWwm6V37pcObJGKPpcShwTvMwHAZhwOR4sPSVnN7XbL6/Wesd8HH3yg6dOn68Ybb5Rkjgzt3bv3HFfXdh1j63cWR3ZLW/4kfbJMKjvQ2N7jIjP4DP+BFJPUsmVdPssMU3kPS3/7qXmO0Ldzzr7GT5ZKb91nzl/xE+ny/2x8LTpBunCcGdw+WSJd+9Oz/zwAQMhLSUnRRx99pL1796pLly6nHKUZOHCgXnvtNd1www1yOBx68MEH22VEp604J6g97cqT3v+1GYAi46XRd0p3vCf9KN8MGy0NQA2+nSNd/YA5n/ew9P6Cs6tvx1+klT8y59Pvkq5q5sTrtFvNx0+WmT+dBwB0evfdd59cLpeGDBmiHj16nPIcnyeffFLx8fEaM2aMbrjhBmVlZenSSy9t52pbjrvIN+Oc3UW+8qj5c/PUW8wRlTBPcJa77pfmYTHJHJ0ZM7P1y9j9N2lJtuStMc9D+t5CydlMRvbWSk8MlioPS7e+Il1ozfFsAOhoGu4i39zdz9Fyp9uO3EU+lEV1kya/LA2ZELwAJJknRo+dbc6/84CUv6h179/3obR0ihmAhkyQbniq+QAkSa5w87CdJG19qe01AwBgMUJQZ3HlbOmK+l+J/XWu9OEzLXvfwU+kl75v3hJjQKY06feS6wynijUcEmu4ZhAAAB0QIaizcDikq+ZK3/4v8/nq2dJHz57+PYd2Sn+6UaoulfqNkX7wJynMfebPShpmTt4aafufz752AAAsQAjqTBwO6eoHpW/92Hz+9k/Mn7s355uvpD9ONK/90ytNunWp5I5q+WelTTEfty45m4oBALAMIaizcTika+ZLY+p/2v7WfdLG5wL7lB6U/vg981dqPQZL/+818+KMrTHs+5IzTDqwWSreEZzaAQBoR4SgzsjhkL7ziJRRf5+WN34sbXrBnK84Yt6S45u9UnyK9G8rpejurf+M6ARpYP0vwxgNAgB0QISgzsrhMH8uf1n9dX/+Mkv6cLH00k3SoS+kmF7S1Nel2F5t/4yGE6S3cc0gAEDHQwjqzBwO84ar6XeZz1f/j3nLi6ju5ghQfMrZLX/gteayyovM6wwBANCBEII6O4dDGveYNOoO87kn1jwHqOfgs192mFsaxjWDAAAdEyHIDhwO6bpfSbe8LN25VuqdFrxl+68Z9JZ0/JvgLRcA0GmkpKRowYIFVpdxEkKQXTgc0uDrpO4XBHe5vYZLiVwzCADQ8RCCcPYaRoP4lRgAoAMhBOHsNVwz6OtNUvEXVlcDAAiiZ599Vr1795bP5wtonzBhgn74wx9q9+7dmjBhghITE9WlSxeNGjVK7777rkXVtg4hCGevSw/zl2KS9AmjQQDQIoYh1VRYMxlGi8v8/ve/ryNHjui9997ztx09elSrV6/WlClTVF5eruuuu055eXnasmWLxo0bpxtuuEH79u07F1stqM5wp0yghdJuNU+O/mSZdPW8M9+EFQDsrrZS+nlvaz577gHJHd2irvHx8Ro/fryWLFmia665RpL06quvKiEhQVdddZWcTqdSU1P9/R999FGtWLFCq1at0owZM85J+cHCSBCCY2CWFNlNKi+U/vXemfsDADqMKVOm6M9//rOqq6slSS+99JJuueUWOZ1OlZeX67777tNFF12krl27qkuXLtqxYwcjQbCRMLc0/AfSR4vNawYN/I7VFQFAaAuPMkdkrPrsVrjhhhtkGIbefPNNjRo1Sv/4xz/061//WpJ03333ac2aNXr88cc1YMAARUZG6uabb1ZNTc25qDyoCEEInrRbzRD0Rf01gyLjra4IAEKXw9HiQ1JWi4iI0KRJk/TSSy9p165dGjRokC699FJJ0gcffKDp06frxhtvlCSVl5dr7969FlbbchwOQ/AkDZcSh0reamn7a1ZXAwAIoilTpujNN9/Uc889pylTpvjbBw4cqNdee01bt27VJ598oltvvfWkX5KFKkIQgsfh4JpBANBJXX311erWrZt27typW2+91d/+5JNPKj4+XmPGjNENN9ygrKws/yhRqHMYRit+J2cTpaWliouLU0lJiWJjY60up2MpPyQ9OVjy1Un3bJB6DLK6IgAICVVVVdqzZ4/OO+88RUREWF1Oh3W67dja729GghBcTa8ZxGgQACCEEYIQfKmTzcdtyySf19paAAA4BUIQgu/CceY1g8oOSru5ZhAAIDQRghB8YW7zfmISt9EAAIQsQhDOjYZfie14Qzp+zNJSACCU8HuksxPM7UcIwrnRK1XqebF5zaDPuGYQALhcLknqEFdSDmWVlZWSpPDw8LNeFleMxrnRcM2gd+43fyU28odWVwQAlgoLC1NUVJQOHTqk8PBwOZ2MQ7SGYRiqrKxUcXGxunbt6g+VZ4MQhHNn+A+kNfOk/R9Lh76UelxodUUAYBmHw6FevXppz549+uqrr6wup8Pq2rWrkpKSgrIsQhDOnS49zWsGffm2eYJ05kNWVwQAlnK73Ro4cCCHxNooPDw8KCNADQhBOLfSbq0PQUulqx+UnMHbeQGgI3I6nVwxOkRwQBLn1oVZ5t3kyw5K/1prdTUAAPiFRAhatGiRUlJSFBERofT0dG3YsOGUfT/77DPddNNNSklJkcPh0IIFC856mTiHwjyN1wz6+A9SB7mzMACg87M8BC1btkw5OTmaP3++Nm/erNTUVGVlZam4uLjZ/pWVlTr//PP12GOPnfLEqNYuE+dY2hTzceeb0nPXSoXbra0HAACFwF3k09PTNWrUKC1cuFCS5PP5lJycrJkzZ2r27NmnfW9KSoruvfde3XvvvUFbpsRd5M+JTS9Kf71fqimTHC4p4x7pytmSO9rqygAAnUSHuot8TU2NNm3apMzMTH+b0+lUZmam8vPz222Z1dXVKi0tDZgQZCOmSTM2SEMmSIZXWv+UtOgyaedqqysDANiUpSHo8OHD8nq9SkxMDGhPTExUYWFhuy0zNzdXcXFx/ik5OblNn40ziO0t/eCP0q2vSHH9pJJ90svZ0rJ/k0oPWF0dAMBmLD8nKBTMmTNHJSUl/qmgoMDqkjq3C7Okez6ULp9lHhrbsUpaOFr66LeSz2t1dQAAm7A0BCUkJMjlcqmoqCigvaioqM1Xg2zLMj0ej2JjYwMmnGPuaOk7j0j/8Xepz0jzXKG3/1v6/TXSga1WVwcAsAFLQ5Db7daIESOUl5fnb/P5fMrLy1NGRkbILBPnUNJQ6fY10vVPSp446cAW6XdXSavnSNVlVlcHAOjELD8clpOTo9/97nd68cUXtWPHDt19992qqKjQbbfdJkmaOnWq5syZ4+9fU1OjrVu3auvWraqpqdHXX3+trVu3ateuXS1eJkKM0ymNul2a8bE09CbJ8Ekf/q+0KF3a8YbV1QEAOinLb5uRnZ2tQ4cOad68eSosLFRaWppWr17tP7F53759AXfaPXDggC655BL/88cff1yPP/64xo4dq7Vr17ZomQhRMYnSzc+Zt9p4I0c69pW0bIo06Hrpul9KcX2trhAA0IlYfp2gUMR1gkJATaX091+ZP6X31Unh0eZd6dNulfqOkhwOqysEAISY1n5/E4KaQQgKIcU7pL/cKxV82NjW7QIpdbKUmi117WdZaQCA0EIICgJCUIjx+aS9/5A+eVn6fJVUW9H4Wsq3zdGhi74nebpYVyMAwHKEoCAgBIWw6nLzukJbl5jBqEF4tDTke+YIUcq3zZOtAQC2QggKAkJQB3Fsn/TJMnOE6OjuxvbYvuahstRbpYQBrVumYZg/za88IlUeNR9rK6XzrpCiugW3fgBAUBGCgoAQ1MEYhrT/Y3N0aPtrUnVJ42t9R5mjQ70vkY4fbQw2/scjJz/31Z78GeFR0iX/Jl12t9TtvPZbNwBAixGCgoAQ1IHVVkk73zJHh3blmTdrbYuwCCkqwRz9qT0uHfmn2e5wmucfjflPqe+I4NUNADhrhKAgIAR1EmVF0qevSNtekcqLpej6UBPV3Zwim8w3bY/qLrmjGpdjGNKeddL6p6Vd7za29xsjjZkpXTiOc5AAIAQQgoKAEIRTKvpMWr9Q+nR542Gz7gOlMTOk4bdI4RHW1gcANkYICgJCEM6o9ID00WJp4/NSdanZFt1DGn2nNPJ2Kbq7tfUBgA0RgoKAEIQWqyqVtvxJyv9fqXS/2RYWKV0yRcq4R+p2vrX1AYCNEIKCgBCEVvPWSp+/Ln3wG6lwW32jQ7roBml4thQRa/7CLCxCCo9snMIipTAPtwEBgCAgBAUBIQhtZhjSnr/Xn0S9poVvctQHoggzKIVHNAak8Egpto8Un1I/9TcfuyQSnADgBK39/rb8LvJAp+JwSOePNaeiz6UP/9ccGaqtkuqOmz+3r60yL8Do//m+YT6vrTSvZdQSYZGNgahr/yYhKcVsd0efk9UDgM6EkaBmMBKEduGtrQ9Fx5sEpBOe11RIJQXSN3ulb74yp9L9kuE7/bKje5iBKLaPeSjOEyt5YuqnZuYj6h/Do/m5P4AOi5EgoKNwhZtTRCuDdl1NYzA69lV9QGoyVZVIFYfMSR+3sihHk4AUIznDzdEth8O8UKTDafZxOBvbAp47Gp+7wqXIePN6TJHx5rWYIuNPmO9mfg6H9gBYgBAEdDRhbqn7BebUnOPf1I8a7ZXKCs17oVWX1j82nUob26tK6w/PGY3t7cUZ1hiOIrs1BqTwKDNIOcMkl7sxNDrDT5h3N98vrOkJ6E3OtwqLZLQLgCRCEND5NASK3mktf49hSHVVjQGpqsR89NWZr8kwD8EZ9Y+nfV4/762Wjh8zz3M6/o15f7bj3wTO1x03P8M/ctVOXJ7GQNRcUHKGB452nTR/ilGxhnk5moxuNTdf//ykeUlOl1lfmLv+0VMf7Brm3advazjMWldt/k39U/3z2qbPT+hnqHF7uKPrt0fDfKR5uNQd1TjftF9YhLkOhmEGasMn+eof/c99Jzxv+rpx8vYNmJrb1k0mX53krTHX31tz5vm66sY2w9skQLubmcIbt3NzfZyuxr9tqIxq+rzm4fTaSvPRP18u1dSfg1h73Fyv8MjGv7X/scmPMxr+hyRU1i2ICEEAzH/cGv7h69Kz/T639niTcNQ0LB01v6x9tfVfVLX18zWSty5w3ltT/7zJfF1N/XlVTU5I99Y0fq632pxUcsrSgLZremi46WHjJoeLm847neZIpjNMcrjMUOUMC3x0uBr7OJv08dY2CTr1Iae20gy1QV0lV2BA8o/Uuhprdjjr5+sfHc5mXm/SljxaGn1HcOtsJUIQAOuER0pxfczpXPN560dCGk4+rzrhRPSqxi8Pb60aR7eajHgZTdt8J4yCndBPqn/NaPJ4Qpt08us+rxnQ6qobRy7qagLb/KMY1YGv+erqRy0iGqfwhnlP43WpTtXucDQZJahs2XxbvmwdJ35J1ocENbN9/du5FVzNjdqEN98W5jE/P2Ck6ISRo7oT26rPUFOTv6flPz1ySO4u5gieO7pxNM8dbf79vTX1/x1UnvBYJdVWNK6n4ZVqyswpWAwfIQgA2oXTZf7Dz+UDgsvnbfzilJqMBDQTdBpea4umh1qbmxrOCXO62uewjc/bGEj9wdc4Yb7p4eIT5pu2+bxmyPDV1U++xnl/u7d+amj3maHMFd54SLJh/w6Pagw+DYcp28IwGkeamgakuob/Yag/lOiv39v49whoO+HwZ0NbwoVB+3O0FSEIANB2TlfjrwnPJf/5NiFyUrvTJTnrDw11Vg6HeW5amFuK7Gp1NedEiOxNAAAA7YsQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbCkkQtCiRYuUkpKiiIgIpaena8OGDaftv3z5cg0ePFgREREaNmyY3nrrrYDXi4qKNH36dPXu3VtRUVEaN26c/vnPf57LVQAAAB2M5SFo2bJlysnJ0fz587V582alpqYqKytLxcXFzfZfv369Jk+erNtvv11btmzRxIkTNXHiRG3fvl2SZBiGJk6cqH/96196/fXXtWXLFvXv31+ZmZmqqKhoz1UDAAAhzGEYhmFlAenp6Ro1apQWLlwoSfL5fEpOTtbMmTM1e/bsk/pnZ2eroqJCb7zxhr/tsssuU1pamhYvXqwvv/xSgwYN0vbt23XxxRf7l5mUlKSf//zn+vd///cz1lRaWqq4uDiVlJQoNjY2SGsKAADOpdZ+f1s6ElRTU6NNmzYpMzPT3+Z0OpWZman8/Pxm35Ofnx/QX5KysrL8/aurqyVJERERAcv0eDx6//33m11mdXW1SktLAyYAANC5WRqCDh8+LK/Xq8TExID2xMREFRYWNvuewsLC0/YfPHiw+vXrpzlz5uibb75RTU2NfvGLX2j//v06ePBgs8vMzc1VXFycf0pOTg7C2gEAgFBm+TlBwRYeHq7XXntNX375pbp166aoqCi99957Gj9+vJzO5ld3zpw5Kikp8U8FBQXtXDUAAGhvYVZ+eEJCglwul4qKigLai4qKlJSU1Ox7kpKSzth/xIgR2rp1q0pKSlRTU6MePXooPT1dI0eObHaZHo9HHo/nLNcGAAB0JJaOBLndbo0YMUJ5eXn+Np/Pp7y8PGVkZDT7noyMjID+krRmzZpm+8fFxalHjx765z//qY0bN2rChAnBXQEAANBhWToSJEk5OTmaNm2aRo4cqdGjR2vBggWqqKjQbbfdJkmaOnWq+vTpo9zcXEnSrFmzNHbsWD3xxBO6/vrrtXTpUm3cuFHPPvusf5nLly9Xjx491K9fP3366aeaNWuWJk6cqGuvvdaSdQQAAKHH8hCUnZ2tQ4cOad68eSosLFRaWppWr17tP/l53759AefyjBkzRkuWLNEDDzyguXPnauDAgVq5cqWGDh3q73Pw4EHl5OSoqKhIvXr10tSpU/Xggw+2+7oBAIDQZfl1gkIR1wkCAKDj6VDXCQIAALAKIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANgSIQgAANhSSISgRYsWKSUlRREREUpPT9eGDRtO23/58uUaPHiwIiIiNGzYML311lsBr5eXl2vGjBnq27evIiMjNWTIEC1evPhcrgIAAOhgLA9By5YtU05OjubPn6/NmzcrNTVVWVlZKi4ubrb/+vXrNXnyZN1+++3asmWLJk6cqIkTJ2r79u3+Pjk5OVq9erX+7//+Tzt27NC9996rGTNmaNWqVe21WgAAIMQ5DMMwWvumgoICORwO9e3bV5K0YcMGLVmyREOGDNGdd97ZqmWlp6dr1KhRWrhwoSTJ5/MpOTlZM2fO1OzZs0/qn52drYqKCr3xxhv+tssuu0xpaWn+0Z6hQ4cqOztbDz74oL/PiBEjNH78eP30pz89Y02lpaWKi4tTSUmJYmNjW7U+AADAGq39/m7TSNCtt96q9957T5JUWFio73znO9qwYYPuv/9+PfLIIy1eTk1NjTZt2qTMzMzGgpxOZWZmKj8/v9n35OfnB/SXpKysrID+Y8aM0apVq/T111/LMAy99957+vLLL3Xttdc2u8zq6mqVlpYGTAAAoHNrUwjavn27Ro8eLUl65ZVXNHToUK1fv14vvfSSXnjhhRYv5/Dhw/J6vUpMTAxoT0xMVGFhYbPvKSwsPGP/p59+WkOGDFHfvn3ldrs1btw4LVq0SFdccUWzy8zNzVVcXJx/Sk5ObvE6AACAjqlNIai2tlYej0eS9O677+p73/ueJGnw4ME6ePBg8Kpro6effloffvihVq1apU2bNumJJ57QPffco3fffbfZ/nPmzFFJSYl/KigoaOeKAQBAewtry5suvvhiLV68WNdff73WrFmjRx99VJJ04MABde/evcXLSUhIkMvlUlFRUUB7UVGRkpKSmn1PUlLSafsfP35cc+fO1YoVK3T99ddLkoYPH66tW7fq8ccfP+lQmiR5PB5/qAMAAPbQppGgX/ziF/rtb3+rK6+8UpMnT1ZqaqokadWqVf7DZC3hdrs1YsQI5eXl+dt8Pp/y8vKUkZHR7HsyMjIC+kvSmjVr/P1ra2tVW1srpzNw1Vwul3w+X4trAwAAnVubRoKuvPJKHT58WKWlpYqPj/e333nnnYqKimrVsnJycjRt2jSNHDlSo0eP1oIFC1RRUaHbbrtNkjR16lT16dNHubm5kqRZs2Zp7NixeuKJJ3T99ddr6dKl2rhxo5599llJUmxsrMaOHauf/OQnioyMVP/+/bVu3Tr98Y9/1JNPPtmW1QUAAJ1Qm0LQ8ePHZRiGPwB99dVXWrFihS666CJlZWW1alnZ2dk6dOiQ5s2bp8LCQqWlpWn16tX+k5/37dsXMKozZswYLVmyRA888IDmzp2rgQMHauXKlRo6dKi/z9KlSzVnzhxNmTJFR48eVf/+/fWzn/1Md911V1tWFwAAdEJtuk7Qtddeq0mTJumuu+7SsWPHNHjwYIWHh+vw4cN68skndffdd5+LWtsN1wkCAKDjaZfrBG3evFnf/va3JUmvvvqqEhMT9dVXX+mPf/yjnnrqqbYsEgAAoF21KQRVVlYqJiZGkvTOO+9o0qRJcjqduuyyy/TVV18FtUAAAIBzoU0haMCAAVq5cqUKCgr017/+1X8l5uLiYg4fAQCADqFNIWjevHm67777lJKSotGjR/t/nv7OO+/okksuCWqBAAAA50KbToyWzNtXHDx4UKmpqf5fb23YsEGxsbEaPHhwUItsb5wYDQBAx9Pa7+82/UReMq/cnJSUpP3790uS+vbt26oLJQIAAFipTYfDfD6fHnnkEcXFxal///7q37+/unbtqkcffZSrMgMAgA6hTSNB999/v/7whz/oscce0+WXXy5Jev/99/XQQw+pqqpKP/vZz4JaJAAAQLC16Zyg3r17a/Hixf67xzd4/fXX9aMf/Uhff/110Aq0AucEAQDQ8bTLxRKPHj3a7MnPgwcP1tGjR9uySAAAgHbVphCUmpqqhQsXntS+cOFCDR8+/KyLAgAAONfadE7QL3/5S11//fV69913/dcIys/PV0FBgd56662gFggAAHAutGkkaOzYsfryyy9144036tixYzp27JgmTZqkzz77TH/605+CXSMAAEDQtfliic355JNPdOmll8rr9QZrkZbgxGgAADqedjkxGgAAoKMjBAEAAFsiBAEAAFtq1a/DJk2adNrXjx07dja1AAAAtJtWhaC4uLgzvj516tSzKggAAKA9tCoEPf/88+eqDgAAgHbFOUEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWQiIELVq0SCkpKYqIiFB6ero2bNhw2v7Lly/X4MGDFRERoWHDhumtt94KeN3hcDQ7/epXvzqXqwEAADoQy0PQsmXLlJOTo/nz52vz5s1KTU1VVlaWiouLm+2/fv16TZ48Wbfffru2bNmiiRMnauLEidq+fbu/z8GDBwOm5557Tg6HQzfddFN7rRYAAAhxDsMwDCsLSE9P16hRo7Rw4UJJks/nU3JysmbOnKnZs2ef1D87O1sVFRV64403/G2XXXaZ0tLStHjx4mY/Y+LEiSorK1NeXl6LaiotLVVcXJxKSkoUGxvbhrUCAADtrbXf35aOBNXU1GjTpk3KzMz0tzmdTmVmZio/P7/Z9+Tn5wf0l6SsrKxT9i8qKtKbb76p22+//ZR1VFdXq7S0NGACAACdm6Uh6PDhw/J6vUpMTAxoT0xMVGFhYbPvKSwsbFX/F198UTExMZo0adIp68jNzVVcXJx/Sk5ObuWaAACAjsbyc4LOteeee05TpkxRRETEKfvMmTNHJSUl/qmgoKAdKwQAAFYIs/LDExIS5HK5VFRUFNBeVFSkpKSkZt+TlJTU4v7/+Mc/tHPnTi1btuy0dXg8Hnk8nlZWDwAAOjJLR4LcbrdGjBgRcMKyz+dTXl6eMjIymn1PRkbGSSc4r1mzptn+f/jDHzRixAilpqYGt3AAANDhWToSJEk5OTmaNm2aRo4cqdGjR2vBggWqqKjQbbfdJkmaOnWq+vTpo9zcXEnSrFmzNHbsWD3xxBO6/vrrtXTpUm3cuFHPPvtswHJLS0u1fPlyPfHEE+2+TgAAIPRZHoKys7N16NAhzZs3T4WFhUpLS9Pq1av9Jz/v27dPTmfjgNWYMWO0ZMkSPfDAA5o7d64GDhyolStXaujQoQHLXbp0qQzD0OTJk9t1fQAAQMdg+XWCQhHXCQIAoOPpUNcJAgAAsAohCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2BIhCAAA2FJIhKBFixYpJSVFERERSk9P14YNG07bf/ny5Ro8eLAiIiI0bNgwvfXWWyf12bFjh773ve8pLi5O0dHRGjVqlPbt23euVgEAAHQwloegZcuWKScnR/Pnz9fmzZuVmpqqrKwsFRcXN9t//fr1mjx5sm6//XZt2bJFEydO1MSJE7V9+3Z/n927d+tb3/qWBg8erLVr12rbtm168MEHFRER0V6rBQAAQpzDMAzDygLS09M1atQoLVy4UJLk8/mUnJysmTNnavbs2Sf1z87OVkVFhd544w1/22WXXaa0tDQtXrxYknTLLbcoPDxcf/rTn9pUU2lpqeLi4lRSUqLY2Ng2LQMAALSv1n5/WzoSVFNTo02bNikzM9Pf5nQ6lZmZqfz8/Gbfk5+fH9BfkrKysvz9fT6f3nzzTV144YXKyspSz549lZ6erpUrV56yjurqapWWlgZMAACgc7M0BB0+fFher1eJiYkB7YmJiSosLGz2PYWFhaftX1xcrPLycj322GMaN26c3nnnHd14442aNGmS1q1b1+wyc3NzFRcX55+Sk5ODsHYAACCUWX5OULD5fD5J0oQJE/TjH/9YaWlpmj17tr773e/6D5edaM6cOSopKfFPBQUF7VkyAACwQJiVH56QkCCXy6WioqKA9qKiIiUlJTX7nqSkpNP2T0hIUFhYmIYMGRLQ56KLLtL777/f7DI9Ho88Hk9bVwMAAHRAlo4Eud1ujRgxQnl5ef42n8+nvLw8ZWRkNPuejIyMgP6StGbNGn9/t9utUaNGaefOnQF9vvzyS/Xv3z/IawAAADoqS0eCJCknJ0fTpk3TyJEjNXr0aC1YsEAVFRW67bbbJElTp05Vnz59lJubK0maNWuWxo4dqyeeeELXX3+9li5dqo0bN+rZZ5/1L/MnP/mJsrOzdcUVV+iqq67S6tWr9Ze//EVr1661YhUBAEAIsjwEZWdn69ChQ5o3b54KCwuVlpam1atX+09+3rdvn5zOxgGrMWPGaMmSJXrggQc0d+5cDRw4UCtXrtTQoUP9fW688UYtXrxYubm5+s///E8NGjRIf/7zn/Wtb32r3dcPAACEJsuvExSKuE4QAAAdT4e6ThAAAIBVCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEEAAMCWCEHt7IvCUvl83LMWAACrEYLa0fpdhzVh4Qf67z9vk5cgBACApQhB7ehQebXqfIZe3bRf9y7bqlqvz+qSAACwLUJQO5qQ1kcLJ1+iMKdDf/nkgGYs2azqOq/VZQEAYEuEoHY2flgvPTt1hNxhTv31syLd9adNqqolCAEA0N4IQRa4enCinps2ShHhTr2385B++MLHqqyps7osAABshRBkkW8NTNCLt41WtNul9buPaOofNqisqtbqsgAAsA1CkIXSz++uP/17umIiwrTxq2/0/37/kY5V1lhdFgAAtkAIstil/eL18h2XKT4qXJ/sL9Hk332kI+XVVpcFAECnRwgKAUP7xGnpnRlK6OLRjoOlyn72QxWXVlldFgAAnRohKEQMSorRK/9xmZJiI7SruFw/+G2+vj523OqyAADotAhBIeT8Hl30yn9kqG98pPYeqdQPFudr35FKq8sCAKBTIgSFmH7do/TKf2TovIRofX3suL7/2/Xafajc6rIAAOh0CEEhqHfXSC278zIN7NlFRaXVyv5tvr4oLLW6LAAAOhVCUIjqGRuhpXdepiG9YnW4vEa3PPuhtn9dYnVZAAB0GoSgENa9i0cv33GZUpO76lhlrSb/7kNt3veN1WUBANApOAzDMKwuItSUlpYqLi5OJSUlio2NtboclVXV6ocvfKyP934jl9Oh5PhIJXeLUt/4KCV3i1RyfJT6dYtScrcoxUeFy+FwWF0yAADtrrXf34SgZoRaCJKkypo6/eilzVq789Bp+0W7XQEBqV+3KCXHmwEpuVukotxh7VQxAADtixAUBKEYgiTJMAx9fey4Co4eV8E3ldp/tFIF3xxXwdFK7TtaqeKyM19p2umQXE6HHA6HXA6HXE6Hv83pcMjpbGx31Le76ttjIsI0Ma2PbhrRV108hCkAQGghBAVBqIagM6mq9Wr/NycHpIJvKrXvSKVKq4Jzp/ounjDdPKKvpo1J0XkJ0UFZJgAAZ4sQFAQdNQSdSWlVrapqvPIahnyG5PMZ8voMeQ1DhmHI65O8PkM+w5wa5832L4vK9OL6vdp9qMK/zKsG9dD0y8/TtwckyOnkXCQAgHUIQUHQWUNQMPh8ht7fdVgvrt+rv+0sVsPec36PaE0fk6JJl3KoDABgDUJQEBCCWmbv4Qr9Mf8rLd9YoLJq81BbjCdMN4/sq2kZKUrhUBkAoB0RgoKAENQ65dV1em3zfr2wfq/+VX+ozOGQrhrUU9PHpOjbAxP42T4A4JwjBAUBIahtGg6VvbB+r/72RbG//YIe0ZrGoTIAwDlGCAoCQtDZ23O4Qn/M36vlG/ervP5QWRdPmCZe0ltT0vvrol5sVwBAcBGCgoAQFDzl1XX686b9enH9Xv3rcOOvykb0j9eU9H66blgvRYS7LKwQANBZEIKCgBAUfIZhKH/3Eb300T799bNC1fnM3a5rVLi+P6Kvbk3vzzWHAABnhRAUBISgc6u4tEqvbCzQyxsK9PWx4/72bw1I0JT0fsockqhwF/f2BQC0DiEoCAhB7cPrM7R2Z7Fe+mif3mtyzaEeMR7dMipZt4zupz5dI60tEgDQYRCCgoAQ1P4KjlZq6cf7tOzj/Tpcbt4DzemQrh7cU1PS++uKC3vIxRWpAQCnQQgKAkKQdWrqfFrzeZH+78OvlP+vI/72Pl0jlXFBd13Sr6vSkrtqUGKMwjhkBgBoghAUBISg0LCruFwvb9inVzftV8nx2oDXIsNdGtYnTmn1oSgtuat6xUVwUUYAsDFCUBAQgkJLVa1XH+w6rK0Fx7Rl3zF9UnDMf5uOpnrGeOpHiuKVltxVw/vGKZqLMwKAbXTIELRo0SL96le/UmFhoVJTU/X0009r9OjRp+y/fPlyPfjgg9q7d68GDhyoX/ziF7ruuuv8r0+fPl0vvvhiwHuysrK0evXqFtVDCAptPp+hfx0u15Z9x/zBaGdRmby+wF3Z6ZAuTIxRWnJXDesbp4t6xWpQYgzBCAA6qQ4XgpYtW6apU6dq8eLFSk9P14IFC7R8+XLt3LlTPXv2PKn/+vXrdcUVVyg3N1ff/e53tWTJEv3iF7/Q5s2bNXToUElmCCoqKtLzzz/vf5/H41F8fHyLaiIEdTzHa7z69OsSbS34xh+MDpZUNdu3f/coDU6K0eCkWF3Uy3zs1y1KTk68BoAOrcOFoPT0dI0aNUoLFy6UJPl8PiUnJ2vmzJmaPXv2Sf2zs7NVUVGhN954w9922WWXKS0tTYsXL5ZkhqBjx45p5cqVbaqJENQ5FJVW+UeLPj9Yqi8Olqq4rLrZvlFuly5MjPGHooaQFBcV3s5VAwDaqrXf35YeF6ipqdGmTZs0Z84cf5vT6VRmZqby8/ObfU9+fr5ycnIC2rKysk4KPGvXrlXPnj0VHx+vq6++Wj/96U/VvXv3oK8DQldibITGDU3SuKFJ/rYj5dXaWVimHYVl+uJgqb4oLNPOojJV1ni1tcAMTE31jovQhUkxio9yK8rtqp/CzEdPmKLCXYr2NGnzv1Y/H+5ihAkAQpSlIejw4cPyer1KTEwMaE9MTNQXX3zR7HsKCwub7V9YWOh/Pm7cOE2aNEnnnXeedu/erblz52r8+PHKz8+Xy3Xyfaqqq6tVXd04QlBaWno2q4UQ1r2LR2MGeDRmQIK/rc7r094jlfqisFRfHCzTF4Wl2nGwTF8fO64DJVU6cIrDai0VEe5UlDtMkeGuwHm3S1HhLkW666fw+ql+Pqq+PTE2Qn3jI5UUG8FlAQAgiDrlGaK33HKLf37YsGEaPny4LrjgAq1du1bXXHPNSf1zc3P18MMPt2eJCCFhLqcG9OyiAT276LvDG9tLjtfqy6Iy7SouV3lVnSpq6lRZ41VlTZ0qq72qrPGqoqZOx2u8qmhor/GqsrpOlbVe/xWwq2p9qqqtOfs6nQ716hqhvl2j1Dc+Un3jGx4j1bdblBJjPIQkAGgFS0NQQkKCXC6XioqKAtqLioqUlJTU7HuSkpJa1V+Szj//fCUkJGjXrl3NhqA5c+YEHGIrLS1VcnJya1YFnVBcZLhGpXTTqJRurX6vYRiqqvX5g9HxWq+O15jBqarWfN7QXlXjbdKnznys9el4TZ3Kq+tUWFKlr48dV63XUMHR4yo4erzZz2wuJCXFeRQTEa4unjB1iQhTTMNjRHhQD9XV1Pnqw2D9+tZ4VeP1KdrjUnT9IcJoT5g8YU6u5QQgZFgagtxut0aMGKG8vDxNnDhRknlidF5enmbMmNHsezIyMpSXl6d7773X37ZmzRplZGSc8nP279+vI0eOqFevXs2+7vF45PF42rwewIkcDof/MFcwzkTz+QwVl1Vr/zeV2v/N8SaP5nxLQtLJNUpd3GYo6tIkHMV4zOfRnjB5fT5V1IeagJGwhrZqM7TVelv2+wqX06Eot0tdPGFNHsPMsNQwXx+YYiLCFBsRbj5Ghis2IlyxkfU1RoRxk90gq6o1A3oXTxgjirANyw+H5eTkaNq0aRo5cqRGjx6tBQsWqKKiQrfddpskaerUqerTp49yc3MlSbNmzdLYsWP1xBNP6Prrr9fSpUu1ceNGPfvss5Kk8vJyPfzww7rpppuUlJSk3bt367//+781YMAAZWVlWbaewNlwOh1KiotQUlyERqac/LrXZ+hQfUgq+KZS+4+aAam4rErl1XUqqzJHlRrmvT5DhiGVVdc1e+HJtgqrDzlR7jCFuRz+8FRV6/PXWVZl1nC2otwuf1CKjQxvMh+mLp5w/4nsEU3PtWrm3KuGx4hw1ynvT+fzGar1+VTnNVTr9am2/rHOa7Y3zNd4faqt85kjfE1H/OpHAJuOCp7qMczlUEIXT+MU41ZCF496xHjUo76texd3i0Ogz2foSEWNikqrVFhSpcLSqoD54tJqFZZWBVyVPdrtCgieDds49oRA2thubn+nwyGfYchrGPL5DPkM82/uMxqmJs99Zj+jvq3hPd6GyWgy36TN5zNUV//cZ5jzPp8hl9Mpd5g5eVxN5usf3Se2uVz+5xHhTkWGuxilbCGfz9zXDUPyhDk79I8/LA9B2dnZOnTokObNm6fCwkKlpaVp9erV/pOf9+3bJ6ez8T/2MWPGaMmSJXrggQc0d+5cDRw4UCtXrvRfI8jlcmnbtm168cUXdezYMfXu3VvXXnutHn30UUZ70Gm5AkLS6Q/fNRyqK6uuVXlDOKoyw1BZVZ3Kq2rNsFRdp3Cn0/ylW3j9r+Hc5uGtyBN+KdfQ5g5r/ovZ6zNUWVOniur6EaX6x4rqOvN8qvpH87nZXl5Vp9KqOpVV1ar0eJ1Kq2pVerxWFTVeSaoflfKqqLT5yx60hSfMqUi3Sw7JH2oavnDb05dF5Wfs0zUqvD4ouf2BKT7KrW8q6wNPaZWKSqpUXFatulbWX1F/ntuprrXVGbmcDsVEBI5AxkQ0BryGAHhie0xEmFxOR0A4DgjJXp+5H/lfM1+v8/lUU2fOV9d5VV3nU3Wtr3G+zqfq2ob5xter6rz1/cx2Sf6AF+5yKtzlkDvMJbfL4W9r+uj293EqzOlUjfd0n1vfXtv00VyfptwuM1h6wl3y1IdKT5jr9I/hLl3cO1YT0vpY8ef2s/w6QaGI6wQBoavO61N5dV1jMKoPSWVVtSqtqlPp8VqVVdU1jsacONrSTFtbuF1Ohbkc/i+eMKdT4WEOhTudJ40yRZ4wKtUwH+UOU6TbWd/H/NVgTZ1Ph8urdbi8WofKq3W4rMacLzPbjlTUtDqUORxSQhePkmIjlBgboaQ4jxJjIpQYF6GkWDM8J8ZGKMrtUln9Niw9IXye+Lysqu6kNkOSy+GQ0+mQ02EGC4fDYbY5zBFNl9MhZ8Nzh6Oxj9N8r6tJn4Z5l9MR+Fr987Am83X1oxM1dV7V1H9R19SZU3Vzz+vb2jvgotH3UnvrqcmXBHWZHeo6QQDQWmEup7pGudU1yh2U5TWMjDUGpDoZhhQeEHLMebfLqTBn4xe3FXw+Q8eO1wYEI/OxRscqa9Q1yq2kWI8/2CTGRqhHjKfFh8+6RbvVLTo427Yj8PoMVdV66w/T1gfpqtrG5/UBu6xJe0MIbOhvGIbC60dW3C6HwuqDccO+E17fdmJwDneZ72kYIfGE14+ohLnqR1aazIc5FRHuChhxcYc55ZBU6zUCgl/DiFNDW8PrgW3m6FS4y/yciCbLbfbzT6jFE25ebqZh1KjqDI9NR5ga2ob0sn6QgRAEwNaansTeETidDn9QuTAxxupyOjyX06Ho+h8CJMVFWF1Oh9Olg9+LkZ8AAAAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWyIEAQAAWwqzuoBQZBiGJKm0tNTiSgAAQEs1fG83fI+fCSGoGWVlZZKk5ORkiysBAACtVVZWpri4uDP2cxgtjUs24vP5dODAAcXExMjhcAR12aWlpUpOTlZBQYFiY2ODuuzOim3WNmy3tmG7tQ3brfXYZm1zuu1mGIbKysrUu3dvOZ1nPuOHkaBmOJ1O9e3b95x+RmxsLDt9K7HN2obt1jZst7Zhu7Ue26xtTrXdWjIC1IATowEAgC0RggAAgC0RgtqZx+PR/Pnz5fF4rC6lw2CbtQ3brW3Ybm3Ddms9tlnbBHO7cWI0AACwJUaCAACALRGCAACALRGCAACALRGCAACALRGC2tGiRYuUkpKiiIgIpaena8OGDVaXFNIeeughORyOgGnw4MFWlxVy/v73v+uGG25Q79695XA4tHLlyoDXDcPQvHnz1KtXL0VGRiozM1P//Oc/rSk2hJxpu02fPv2k/W/cuHHWFBsicnNzNWrUKMXExKhnz56aOHGidu7cGdCnqqpK99xzj7p3764uXbropptuUlFRkUUVh4aWbLcrr7zypP3trrvusqhi6z3zzDMaPny4/4KIGRkZevvtt/2vB2s/IwS1k2XLliknJ0fz58/X5s2blZqaqqysLBUXF1tdWki7+OKLdfDgQf/0/vvvW11SyKmoqFBqaqoWLVrU7Ou//OUv9dRTT2nx4sX66KOPFB0draysLFVVVbVzpaHlTNtNksaNGxew/7388svtWGHoWbdune655x59+OGHWrNmjWpra3XttdeqoqLC3+fHP/6x/vKXv2j58uVat26dDhw4oEmTJllYtfVast0k6Y477gjY3375y19aVLH1+vbtq8cee0ybNm3Sxo0bdfXVV2vChAn67LPPJAVxPzPQLkaPHm3cc889/uder9fo3bu3kZuba2FVoW3+/PlGamqq1WV0KJKMFStW+J/7fD4jKSnJ+NWvfuVvO3bsmOHxeIyXX37ZggpD04nbzTAMY9q0acaECRMsqaejKC4uNiQZ69atMwzD3LfCw8ON5cuX+/vs2LHDkGTk5+dbVWbIOXG7GYZhjB071pg1a5Z1RXUA8fHxxu9///ug7meMBLWDmpoabdq0SZmZmf42p9OpzMxM5efnW1hZ6PvnP/+p3r176/zzz9eUKVO0b98+q0vqUPbs2aPCwsKAfS8uLk7p6ensey2wdu1a9ezZU4MGDdLdd9+tI0eOWF1SSCkpKZEkdevWTZK0adMm1dbWBuxvgwcPVr9+/djfmjhxuzV46aWXlJCQoKFDh2rOnDmqrKy0oryQ4/V6tXTpUlVUVCgjIyOo+xk3UG0Hhw8fltfrVWJiYkB7YmKivvjiC4uqCn3p6el64YUXNGjQIB08eFAPP/ywvv3tb2v79u2KiYmxurwOobCwUJKa3fcaXkPzxo0bp0mTJum8887T7t27NXfuXI0fP175+flyuVxWl2c5n8+ne++9V5dffrmGDh0qydzf3G63unbtGtCX/a1Rc9tNkm699Vb1799fvXv31rZt2/Q///M/2rlzp1577TULq7XWp59+qoyMDFVVValLly5asWKFhgwZoq1btwZtPyMEIWSNHz/ePz98+HClp6erf//+euWVV3T77bdbWBns4JZbbvHPDxs2TMOHD9cFF1ygtWvX6pprrrGwstBwzz33aPv27Zyn10qn2m533nmnf37YsGHq1auXrrnmGu3evVsXXHBBe5cZEgYNGqStW7eqpKREr776qqZNm6Z169YF9TM4HNYOEhIS5HK5TjpzvaioSElJSRZV1fF07dpVF154oXbt2mV1KR1Gw/7Fvnf2zj//fCUkJLD/SZoxY4beeOMNvffee+rbt6+/PSkpSTU1NTp27FhAf/Y306m2W3PS09Mlydb7m9vt1oABAzRixAjl5uYqNTVVv/nNb4K6nxGC2oHb7daIESOUl5fnb/P5fMrLy1NGRoaFlXUs5eXl2r17t3r16mV1KR3Geeedp6SkpIB9r7S0VB999BH7Xivt379fR44csfX+ZxiGZsyYoRUrVuhvf/ubzjvvvIDXR4wYofDw8ID9befOndq3b5+t97czbbfmbN26VZJsvb+dyOfzqbq6Orj7WXDP3capLF261PB4PMYLL7xgfP7558add95pdO3a1SgsLLS6tJD1X//1X8batWuNPXv2GB988IGRmZlpJCQkGMXFxVaXFlLKysqMLVu2GFu2bDEkGU8++aSxZcsW46uvvjIMwzAee+wxo2vXrsbrr79ubNu2zZgwYYJx3nnnGcePH7e4cmudbruVlZUZ9913n5Gfn2/s2bPHePfdd41LL73UGDhwoFFVVWV16Za5++67jbi4OGPt2rXGwYMH/VNlZaW/z1133WX069fP+Nvf/mZs3LjRyMjIMDIyMiys2npn2m67du0yHnnkEWPjxo3Gnj17jNdff904//zzjSuuuMLiyq0ze/ZsY926dcaePXuMbdu2GbNnzzYcDofxzjvvGIYRvP2MENSOnn76aaNfv36G2+02Ro8ebXz44YdWlxTSsrOzjV69ehlut9vo06ePkZ2dbezatcvqskLOe++9Z0g6aZo2bZphGObP5B988EEjMTHR8Hg8xjXXXGPs3LnT2qJDwOm2W2VlpXHttdcaPXr0MMLDw43+/fsbd9xxh+3/p6W57SXJeP755/19jh8/bvzoRz8y4uPjjaioKOPGG280Dh48aF3RIeBM223fvn3GFVdcYXTr1s3weDzGgAEDjJ/85CdGSUmJtYVb6Ic//KHRv39/w+12Gz169DCuueYafwAyjODtZw7DMIw2jkwBAAB0WJwTBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAAbIkQBAAt4HA4tHLlSqvLABBEhCAAIW/69OlyOBwnTePGjbO6NAAdWJjVBQBAS4wbN07PP/98QJvH47GoGgCdASNBADoEj8ejpKSkgCk+Pl6SeajqmWee0fjx4xUZGanzzz9fr776asD7P/30U1199dWKjIxU9+7ddeedd6q8vDygz3PPPaeLL75YHo9HvXr10owZMwJeP3z4sG688UZFRUVp4MCBWrVq1bldaQDnFCEIQKfw4IMP6qabbtInn3yiKVOm6JZbbtGOHTskSRUVFcrKylJ8fLw+/vhjLV++XO+++25AyHnmmWd0zz336M4779Snn36qVatWacCAAQGf8fDDD+sHP/iBtm3bpuuuu05TpkzR0aNH23U9AQRR8O75CgDnxrRp0wyXy2VER0cHTD/72c8MwzDv0n3XXXcFvCc9Pd24++67DcMwjGeffdaIj483ysvL/a+/+eabhtPp9N8Zvnfv3sb9999/yhokGQ888ID/eXl5uSHJePvtt4O2ngDaF+cEAegQrrrqKj3zzDMBbd26dfPPZ2RkBLyWkZGhrVu3SpJ27Nih1NRURUdH+1+//PLL5fP5tHPnTjkcDh04cEDXXHPNaWsYPny4fz46OlqxsbEqLi5u6yoBsBghCECHEB0dfdLhqWCJjIxsUb/w8PCA5w6HQz6f71yUBKAdcE4QgE7hww8/POn5RRddJEm66KKL9Mknn6iiosL/+gcffCCn06lBgwYpJiZGKSkpysvLa9eaAViLkSAAHUJ1dbUKCwsD2sLCwpSQkCBJWr58uUaOHKlvfetbeumll7Rhwwb94Q9/kCRNmTJF8+fP17Rp0/TQQw/p0KFDmjlzpv7t3/5NiYmJkqSHHnpId911l3r27Knx48errKxMH3zwgWbOnNm+Kwqg3RCCAHQIq1evVq9evQLaBg0apC+++EKS+cutpUuX6kc/+pF69eqll19+WUOGDJEkRUVF6a9//atmzZqlUaNGKSoqSjfddJOefPJJ/7KmTZumqqoq/frXv9Z9992nhIQE3Xzzze23ggDancMwDMPqIgDgbDgcDq1YsUITJ060uhQAHQjnBAEAAFsiBAEAAFvinCAAHR5H9QG0BSNBAADAlghBAADAlghBAADAlghBAADAlghBAADAlghBAADAlghBAADAlghBAADAlghBAADAlv4/YvSlv0s9FBYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "8d420a5f-57e9-45d4-aa09-6ef9c945b8e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "90344f2a-fabd-4940-fa98-26f232d2d1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv10.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv10.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "6c2c6378-9ac2-4da3-a5dd-dccebd45a340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [09:45<00:00, 48.77s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1168\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv10')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}