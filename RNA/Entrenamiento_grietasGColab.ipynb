{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "798b674a-e01c-4e93-8849-669b644f1f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "5ab3bd81-33f2-4e73-c54d-cec3de5e6770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "83bc244c-b7e9-4686-cfca-822f9445fbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "c0cfe9a1-c6fa-4b3e-94cf-577b88d8e0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "40e9ee1b-b1b7-4a68-b6ca-b95d799a4346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv11.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "fa3f00ac-db95-4ee0-f679-4fea8c3908ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=30,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv12.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "c6f77ce6-dc04-42e9-976b-ec929e4f89f8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.064313\n",
            " 22%|██▏       | 10/46 [00:11<00:39,  1.11s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.159816\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.088556\n",
            " 65%|██████▌   | 30/46 [00:34<00:17,  1.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.119255\n",
            " 87%|████████▋ | 40/46 [00:45<00:06,  1.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.092965\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.3592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1362 (train) | 0.3592 (val)\n",
            "Epoch 2 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.156144\n",
            " 22%|██▏       | 10/46 [00:10<00:40,  1.11s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.090517\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.113688\n",
            " 65%|██████▌   | 30/46 [00:33<00:18,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.063570\n",
            " 87%|████████▋ | 40/46 [00:45<00:06,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.102410\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.14s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.2028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0977 (train) | 0.2028 (val)\n",
            "Epoch 3 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.102528\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.088920\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.115051\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.092169\n",
            " 87%|████████▋ | 40/46 [00:45<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.076224\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.14s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0840 (train) | 0.1493 (val)\n",
            "Epoch 4 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.073681\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.100371\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.091015\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.062216\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.081984\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.2257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0797 (train) | 0.2257 (val)\n",
            "Epoch 5 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.057363\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.077675\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.073183\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.069398\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.057888\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0784 (train) | 0.1766 (val)\n",
            "Epoch 6 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.136869\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.057607\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.063481\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.054818\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.065944\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0704 (train) | 0.1330 (val)\n",
            "Epoch 7 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.065110\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.043872\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.065163\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.082482\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.055798\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0650 (train) | 0.1301 (val)\n",
            "Epoch 8 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.079044\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.089101\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.056518\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.057997\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.061878\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0643 (train) | 0.1273 (val)\n",
            "Epoch 9 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.066894\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.065565\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.051007\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.064777\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.097016\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0629 (train) | 0.1214 (val)\n",
            "Epoch 10 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.047923\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.050087\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.060912\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.061178\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.053300\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0609 (train) | 0.1231 (val)\n",
            "Epoch 11 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.076178\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.041439\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.049241\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.061983\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.034744\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0591 (train) | 0.1179 (val)\n",
            "Epoch 12 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.045644\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.081117\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.042263\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.041738\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.053359\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0586 (train) | 0.1146 (val)\n",
            "Epoch 13 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.056708\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.058695\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.050008\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.071355\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.072073\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0581 (train) | 0.1146 (val)\n",
            "Epoch 14 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.047355\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.053038\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.059232\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.046197\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.058818\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0576 (train) | 0.1143 (val)\n",
            "Epoch 15 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.054074\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.058578\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.059517\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.063809\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.062051\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0579 (train) | 0.1133 (val)\n",
            "Epoch 16 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.050636\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.041101\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.051260\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.059496\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.063259\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0571 (train) | 0.1125 (val)\n",
            "Epoch 17 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.055758\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.051582\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.065467\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.064411\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.062041\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1124 (val)\n",
            "Epoch 18 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.066983\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.037356\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.058158\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.073864\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.056304\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0570 (train) | 0.1123 (val)\n",
            "Epoch 19 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.084556\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.053408\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.065429\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.037892\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.057558\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1126 (val)\n",
            "Epoch 20 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.054204\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.078743\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.048186\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.068820\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.049463\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0570 (train) | 0.1121 (val)\n",
            "Epoch 21 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.080175\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.048311\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.051958\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.045887\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.043539\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0566 (train) | 0.1124 (val)\n",
            "Epoch 22 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.059960\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.045571\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.053345\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.078115\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.056414\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0567 (train) | 0.1130 (val)\n",
            "Epoch 23 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.040754\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.053745\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.068052\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.049052\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.044691\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0563 (train) | 0.1120 (val)\n",
            "Epoch 24 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.043781\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.055013\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.077807\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.075025\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.072366\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0563 (train) | 0.1126 (val)\n",
            "Epoch 25 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.053142\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.043991\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.065753\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.052515\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.058463\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0563 (train) | 0.1117 (val)\n",
            "Epoch 26 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.053933\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.051015\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.057673\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.056607\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.078219\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.1128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0565 (train) | 0.1128 (val)\n",
            "Epoch 27 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.068921\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.057335\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.043293\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.050907\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.066319\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0566 (train) | 0.1120 (val)\n",
            "Epoch 28 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.059842\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.074258\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.067678\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.048823\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.102714\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.1118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0566 (train) | 0.1118 (val)\n",
            "Epoch 29 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.068378\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.055926\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.045132\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.061398\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.050559\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0565 (train) | 0.1123 (val)\n",
            "Epoch 30 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.038152\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.043152\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.056081\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.049693\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.069783\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.1119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0560 (train) | 0.1119 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.1361925006220444,\n",
              "   0.09772342350654412,\n",
              "   0.08402610762994699,\n",
              "   0.07968081948741583,\n",
              "   0.07844883856265526,\n",
              "   0.07044530996292604,\n",
              "   0.0649705871590974,\n",
              "   0.06430887117346074,\n",
              "   0.06288037314262376,\n",
              "   0.06089505336342888,\n",
              "   0.05909752309404401,\n",
              "   0.05859426933572117,\n",
              "   0.0580728290229523,\n",
              "   0.0575528665556632,\n",
              "   0.05785280327631208,\n",
              "   0.05714868458278903,\n",
              "   0.056824872197156436,\n",
              "   0.05703532758841249,\n",
              "   0.056840422384425514,\n",
              "   0.05704928769461467,\n",
              "   0.056641684566910974,\n",
              "   0.05672618370382686,\n",
              "   0.05628511409614304,\n",
              "   0.056346596969215935,\n",
              "   0.05634330318700997,\n",
              "   0.056484758125775775,\n",
              "   0.056620197656518906,\n",
              "   0.056585278677390674,\n",
              "   0.056450596957352765,\n",
              "   0.05602344706992978]},\n",
              " 'val': {'loss': [0.35924553871154785,\n",
              "   0.20275598267714182,\n",
              "   0.14930071930090585,\n",
              "   0.2257228841384252,\n",
              "   0.17661864558855692,\n",
              "   0.13301520546277365,\n",
              "   0.13012452175219855,\n",
              "   0.1272608314951261,\n",
              "   0.12140363454818726,\n",
              "   0.12310067067543666,\n",
              "   0.1178637941678365,\n",
              "   0.114645520846049,\n",
              "   0.11461662501096725,\n",
              "   0.11430915941794713,\n",
              "   0.11331774294376373,\n",
              "   0.11249382545550664,\n",
              "   0.11239458372195561,\n",
              "   0.1123448833823204,\n",
              "   0.11257750044266383,\n",
              "   0.11212705075740814,\n",
              "   0.11241141706705093,\n",
              "   0.1130205790201823,\n",
              "   0.11197202155987422,\n",
              "   0.11264273275931676,\n",
              "   0.11165590087572734,\n",
              "   0.11284547050793965,\n",
              "   0.11196520427862804,\n",
              "   0.1117553139726321,\n",
              "   0.11228812982638676,\n",
              "   0.111851766705513]}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "d125334f-35df-47bd-81f4-c576447d0ad5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "0bec288c-97a5-4de7-aa2f-45614d3b8320"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "aec1cfbb-5726-4377-abe6-7681b5412a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv11.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv12.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "2dbbfcbe-da9f-415e-a87d-98392575059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:18<00:00, 21.52s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1105\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv12')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}