{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "961ef1e2-7eb5-4ed5-f839-aa5968d367d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "dd97a968-caba-4d7d-8f57-65aaa1b60410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.5)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.8\n",
            "    Uninstalling widgetsnbextension-3.6.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.8\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1.post1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "94165535-42f9-467c-8f72-b6e4a83e0bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "#transformers = Compose([transforms.RandomRotation(degrees=30), FixResize(256), ToTensor(), Normalize()])\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Definición de una clase para calcular el Índice de Jaccard, o Intersección sobre Unión (IoU)\n",
        "class JaccardIndex:\n",
        "    def __init__(self):\n",
        "        # Se define el nombre de la métrica para referencia\n",
        "        self.__name__ = 'jaccard_index'\n",
        "\n",
        "    def __call__(self, preds, targets):\n",
        "        \"\"\"\n",
        "        Calcula el Índice de Jaccard (IoU) entre las predicciones y los objetivos.\n",
        "        \n",
        "        Parámetros:\n",
        "        preds: tensor de PyTorch con las predicciones del modelo.\n",
        "        targets: tensor de PyTorch con los valores verdaderos (ground truth).\n",
        "        \n",
        "        Retorna:\n",
        "        iou: El valor del Índice de Jaccard.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Asegurarse de que las predicciones sean binarias (0 o 1)\n",
        "        preds = (preds > 0.5).float()\n",
        "\n",
        "        # Calcular la intersección y la unión\n",
        "        intersection = torch.sum(preds * targets)\n",
        "        union = torch.sum(preds + targets) - intersection\n",
        "        \n",
        "        # Calcular IoU evitando la división por cero\n",
        "        iou = intersection / (union + 1e-8)\n",
        "        \n",
        "        return iou.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFPZp57F3wK",
        "outputId": "64b38c9e-6c86-4e75-94dc-a59dd79d8bfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 68.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "a3582038-8d0b-412a-c54b-3d27ee0fe9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0005)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=7, gamma=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "bb888515-b0fb-4d01-f669-80119182ab08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv25.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "c07df838-7c57-440d-f4c6-a9ab3eb1cd53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    evaluate_metric= JaccardIndex,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv26.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X1SfRwQCG09V",
        "outputId": "ab73059f-ce4b-4851-d69b-2fc8029fb95e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.036825\n",
            " 22%|██▏       | 10/46 [04:46<15:18, 25.50s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.037732\n",
            " 43%|████▎     | 20/46 [09:00<10:57, 25.30s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.043961\n",
            " 65%|██████▌   | 30/46 [13:14<06:46, 25.39s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.047226\n",
            " 87%|████████▋ | 40/46 [17:28<02:31, 25.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.044481\n",
            "100%|██████████| 46/46 [19:46<00:00, 25.80s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [02:18<00:00, 46.30s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0774\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0411 (train) | 0.0774 (val)\n",
            "Epoch 2 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.049227\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.044505\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.033817\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.034027\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.036913\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0774\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0409 (train) | 0.0774 (val)\n",
            "Epoch 3 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.047820\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.058421\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.041608\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.033491\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.033244\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0774\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0403 (train) | 0.0774 (val)\n",
            "Epoch 4 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.039803\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.034384\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.040294\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.034568\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.039999\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0765\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0399 (train) | 0.0765 (val)\n",
            "Epoch 5 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.042625\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.032562\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.034602\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.036949\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.037172\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0750\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0396 (train) | 0.0750 (val)\n",
            "Epoch 6 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.047321\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.041259\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.033489\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.046602\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.033987\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0745\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0396 (train) | 0.0745 (val)\n",
            "Epoch 7 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.032396\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.044109\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.038254\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.047434\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.039115\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0761\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0393 (train) | 0.0761 (val)\n",
            "Epoch 8 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.046128\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.035110\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.053193\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.023761\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.046447\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0725\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0380 (train) | 0.0725 (val)\n",
            "Epoch 9 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.032631\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.036126\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.045526\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.031153\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.039646\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0720\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0374 (train) | 0.0720 (val)\n",
            "Epoch 10 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.039660\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.034059\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.036397\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.041650\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.031312\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0719\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0372 (train) | 0.0719 (val)\n",
            "Epoch 11 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.043722\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.032136\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.030870\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.036522\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.046030\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0717\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0371 (train) | 0.0717 (val)\n",
            "Epoch 12 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.041511\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.026987\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.032661\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.035568\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.037906\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0715\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0372 (train) | 0.0715 (val)\n",
            "Epoch 13 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.034768\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.049703\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.040251\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.039839\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.036858\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0716\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0371 (train) | 0.0716 (val)\n",
            "Epoch 14 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.036978\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.033763\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.041015\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.033219\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.044044\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0371 (train) | 0.0713 (val)\n",
            "Epoch 15 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.030117\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.033645\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.025847\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.028149\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.043832\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0714 (val)\n",
            "Epoch 16 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.036173\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.026438\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.042226\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.039052\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.047535\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 17 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.043807\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.041077\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.028728\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.032790\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.041757\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 18 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.027849\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.042386\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.038036\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.024268\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.043253\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 19 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.044582\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.031487\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.036450\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.035269\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.042908\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0713 (val)\n",
            "Epoch 20 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.036043\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.049017\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.029493\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.048193\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.038053\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 21 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.027744\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.044412\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.051214\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.042047\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.026613\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 22 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.033175\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.025349\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.029860\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.047287\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.035270\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 23 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.043593\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.033881\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.039628\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.042171\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.026168\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 24 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.034095\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.031214\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.040032\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.038259\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.032727\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0370 (train) | 0.0712 (val)\n",
            "Epoch 25 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.042277\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.031220\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.026444\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.038042\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.027960\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0711\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0711 (val)\n",
            "Epoch 26 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.038022\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.040569\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.034828\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.044233\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.052873\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0366 (train) | 0.0713 (val)\n",
            "Epoch 27 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.030963\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.029232\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.030463\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.044684\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.043026\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0713 (val)\n",
            "Epoch 28 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.026416\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.039444\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.037642\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.043035\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.029544\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0712 (val)\n",
            "Epoch 29 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.040481\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.036647\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.034978\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.030281\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.043695\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0713 (val)\n",
            "Epoch 30 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.033340\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.031984\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.042626\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.035327\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.035818\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0712 (val)\n",
            "Epoch 31 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.045406\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.032512\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.038064\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.032295\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.032807\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0712 (val)\n",
            "Epoch 32 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.028830\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.038539\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.036902\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.038971\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.037095\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0713\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0713 (val)\n",
            "Epoch 33 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.044548\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.028615\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.046317\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.034759\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.034137\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0371 (train) | 0.0712 (val)\n",
            "Epoch 34 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.028120\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.029853\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.041554\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.030379\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.037416\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0712 (val)\n",
            "Epoch 35 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.056268\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.042039\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.032481\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.034296\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.046892\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0712 (val)\n",
            "Epoch 36 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.054803\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.037676\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.037083\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.039051\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.041750\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0714 (val)\n",
            "Epoch 37 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.026928\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.036923\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.034414\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.045771\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.043916\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0712 (val)\n",
            "Epoch 38 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.031703\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.044829\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.030814\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.038804\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.040167\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0368 (train) | 0.0712 (val)\n",
            "Epoch 39 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.034826\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.035411\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.032144\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.041198\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.030289\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0714 (val)\n",
            "Epoch 40 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.036303\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.036518\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.032872\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.026569\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.026646\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0367 (train) | 0.0714 (val)\n",
            "Epoch 41 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [0/1453 (0%)]\tLoss: 0.031259\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [320/1453 (22%)]\tLoss: 0.036439\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [640/1453 (43%)]\tLoss: 0.032832\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [960/1453 (65%)]\tLoss: 0.033723\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [1280/1453 (87%)]\tLoss: 0.044240\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 41\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 41 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0712 (val)\n",
            "Epoch 42 / 42\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [0/1453 (0%)]\tLoss: 0.039771\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [320/1453 (22%)]\tLoss: 0.047389\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [640/1453 (43%)]\tLoss: 0.027468\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [960/1453 (65%)]\tLoss: 0.037222\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [1280/1453 (87%)]\tLoss: 0.033094\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 42\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 42 \tAverage loss: 0.0712\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0369 (train) | 0.0712 (val)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.04107159146166061,\n",
              "   0.040859315873823,\n",
              "   0.04025951409885494,\n",
              "   0.03989655943427181,\n",
              "   0.039621457429339944,\n",
              "   0.03959092945475785,\n",
              "   0.03931974901138957,\n",
              "   0.03800194517947113,\n",
              "   0.03739738311292956,\n",
              "   0.03720764891184861,\n",
              "   0.03710320603207564,\n",
              "   0.037150331915799126,\n",
              "   0.03706842378622814,\n",
              "   0.037050235339652564,\n",
              "   0.03682957562064804,\n",
              "   0.03688746920215698,\n",
              "   0.03688859683060884,\n",
              "   0.03685429701241886,\n",
              "   0.03678775251332186,\n",
              "   0.036862622056840946,\n",
              "   0.03692705507011391,\n",
              "   0.03688078703639512,\n",
              "   0.03689244886923066,\n",
              "   0.03704320309402938,\n",
              "   0.03668698773213649,\n",
              "   0.03664121128803315,\n",
              "   0.036884686271855524,\n",
              "   0.036829111083613864,\n",
              "   0.03667664581221379,\n",
              "   0.03678372594113195,\n",
              "   0.036893472542085075,\n",
              "   0.036786738165230565,\n",
              "   0.03707519184903121,\n",
              "   0.036875944360270224,\n",
              "   0.03672840796457187,\n",
              "   0.0368559251745159,\n",
              "   0.03665444190522268,\n",
              "   0.036813475896655,\n",
              "   0.036734231634236,\n",
              "   0.036727120542189864,\n",
              "   0.03686880975377125,\n",
              "   0.036930210311517005]},\n",
              " 'val': {'loss': [0.0774121309320132,\n",
              "   0.07740147163470586,\n",
              "   0.07739999890327454,\n",
              "   0.0765091801683108,\n",
              "   0.07498693466186523,\n",
              "   0.0745497743288676,\n",
              "   0.07608605921268463,\n",
              "   0.0724802737434705,\n",
              "   0.07199662427107494,\n",
              "   0.07185077915589015,\n",
              "   0.07165861626466115,\n",
              "   0.07154357184966405,\n",
              "   0.07160845398902893,\n",
              "   0.07127484927574794,\n",
              "   0.07136682917674382,\n",
              "   0.07133647054433823,\n",
              "   0.07125095029671986,\n",
              "   0.07126136869192123,\n",
              "   0.07133120050032933,\n",
              "   0.07125569134950638,\n",
              "   0.07126152515411377,\n",
              "   0.07126216838757198,\n",
              "   0.0713353380560875,\n",
              "   0.07116234799226125,\n",
              "   0.07112804055213928,\n",
              "   0.07129071652889252,\n",
              "   0.07131927460432053,\n",
              "   0.07115604231754939,\n",
              "   0.07128387441237767,\n",
              "   0.07115388413270314,\n",
              "   0.07123370716969173,\n",
              "   0.07127191374699275,\n",
              "   0.07121291011571884,\n",
              "   0.07124398897091548,\n",
              "   0.07120299090941747,\n",
              "   0.07137792060772578,\n",
              "   0.07120521118243535,\n",
              "   0.07115258524815242,\n",
              "   0.07135452578465144,\n",
              "   0.07135493556658427,\n",
              "   0.07116656998793285,\n",
              "   0.07123871147632599]}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "385d070a-9952-4454-bbc2-1181f19fd075"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "65ecad57-c79a-4624-9007-f5935441c179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kH5xVXQyG09W",
        "outputId": "9a5e43b1-e321-4eb5-8aff-f835561fbc91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_25/unetv25.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_25/unetv25.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "ab0d1126-f07b-4d76-fb32-3635971c25ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [09:32<00:00, 47.69s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1188\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.1188\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv25')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
