{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "b64e693a-56dd-4afa-adf2-f06d2a686ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "f50076fd-a0b1-4765-875f-902097da2619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "8af57a10-893d-4762-b8a2-c4c2234b8728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "outputId": "59160fed-f256-4722-f06d-51cb10f2050e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 132MB/s] \n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "9923993c-75cb-46f2-968f-61da8e1b2ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "d026d128-9d98-4c8b-e1fb-0bf81247aebd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv11.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "39ff16e3-e0d9-40b3-e6c4-0dbe706da44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=35,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv14.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "b9408701-b1dd-414e-9ea6-45ba8c442a24",
        "collapsed": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.045821\n",
            " 22%|██▏       | 10/46 [02:10<06:41, 11.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.058580\n",
            " 43%|████▎     | 20/46 [04:03<04:47, 11.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.040189\n",
            " 65%|██████▌   | 30/46 [05:52<02:54, 10.93s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.043748\n",
            " 87%|████████▋ | 40/46 [07:42<01:06, 11.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.050913\n",
            "100%|██████████| 46/46 [08:41<00:00, 11.33s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [01:03<00:00, 21.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0917\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0475 (train) | 0.0917 (val)\n",
            "Epoch 2 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.040226\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.041831\n",
            " 43%|████▎     | 20/46 [00:24<00:31,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.048291\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.038019\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.053131\n",
            "100%|██████████| 46/46 [00:56<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0472 (train) | 0.0914 (val)\n",
            "Epoch 3 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.044763\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.043773\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.042666\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.046553\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.049736\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0471 (train) | 0.0915 (val)\n",
            "Epoch 4 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.039163\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.065523\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.064073\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.056326\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.045325\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0911\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0471 (train) | 0.0911 (val)\n",
            "Epoch 5 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.036385\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.040237\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.053993\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.054488\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.047469\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0472 (train) | 0.0918 (val)\n",
            "Epoch 6 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.051536\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.034635\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.050078\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.058508\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.042078\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0905\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0466 (train) | 0.0905 (val)\n",
            "Epoch 7 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.050811\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.037995\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.043673\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.049206\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.042129\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0902\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0902 (val)\n",
            "Epoch 8 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.048383\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.045113\n",
            " 43%|████▎     | 20/46 [00:24<00:31,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.048124\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.058838\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.034218\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0904 (val)\n",
            "Epoch 9 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.030501\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.043157\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.044879\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.051421\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.043645\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0467 (train) | 0.0903 (val)\n",
            "Epoch 10 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.045199\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.038400\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.039790\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.047845\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.052099\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0466 (train) | 0.0900 (val)\n",
            "Epoch 11 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.044663\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.054990\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.047319\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.056919\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.048686\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 12 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.038835\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.049610\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.058683\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.043256\n",
            " 87%|████████▋ | 40/46 [00:50<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.041487\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 13 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.040839\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.038646\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.067074\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.045483\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.039764\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0902\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0902 (val)\n",
            "Epoch 14 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.043097\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.050040\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.048685\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.047234\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.041957\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0900 (val)\n",
            "Epoch 15 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.041052\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.044405\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.047687\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.044610\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.042810\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0900 (val)\n",
            "Epoch 16 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.043455\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.055109\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.049775\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.036405\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.068438\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0900 (val)\n",
            "Epoch 17 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.053658\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.033370\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.049763\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.042457\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.050482\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 18 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.042101\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.042930\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.052358\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.039155\n",
            " 87%|████████▋ | 40/46 [00:50<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.052580\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0901 (val)\n",
            "Epoch 19 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.054300\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.043590\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.038787\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.044469\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.052855\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0901 (val)\n",
            "Epoch 20 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.072297\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.050686\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.047300\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.045909\n",
            " 87%|████████▋ | 40/46 [00:50<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.046302\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 21 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.045428\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.048295\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.045823\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.062519\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.044835\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 22 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.052299\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.045608\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.035791\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.039817\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.041754\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0899 (val)\n",
            "Epoch 23 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.052799\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.043978\n",
            " 43%|████▎     | 20/46 [00:24<00:31,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.055581\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.036686\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.031884\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0900 (val)\n",
            "Epoch 24 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.038891\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.046610\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.047475\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.043802\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.048928\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0462 (train) | 0.0900 (val)\n",
            "Epoch 25 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.043707\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.040841\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.046731\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.052402\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.047722\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0462 (train) | 0.0901 (val)\n",
            "Epoch 26 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.050260\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.043571\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.050733\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.049337\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.041078\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0902\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0902 (val)\n",
            "Epoch 27 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.048451\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.063641\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.038853\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.048112\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.044931\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0899 (val)\n",
            "Epoch 28 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.071509\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.036890\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.039224\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.041114\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.047539\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0900 (val)\n",
            "Epoch 29 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.050593\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.047967\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.046925\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.044704\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.035118\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0462 (train) | 0.0901 (val)\n",
            "Epoch 30 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.050393\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.032606\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.045358\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.048429\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.029938\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0900 (val)\n",
            "Epoch 31 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.039707\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.047520\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.062102\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.033769\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.046199\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0464 (train) | 0.0899 (val)\n",
            "Epoch 32 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.058599\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.061434\n",
            " 43%|████▎     | 20/46 [00:24<00:31,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.041395\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.046919\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.038798\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0463 (train) | 0.0899 (val)\n",
            "Epoch 33 / 35\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.041487\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.042430\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.046493\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.046780\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.040643\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0462 (train) | 0.0900 (val)\n",
            "Epoch 34 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.046274\n",
            " 22%|██▏       | 10/46 [00:11<00:44,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.056210\n",
            " 43%|████▎     | 20/46 [00:24<00:31,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.046694\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.041429\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.047295\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0464 (train) | 0.0901 (val)\n",
            "Epoch 35 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.041949\n",
            " 22%|██▏       | 10/46 [00:12<00:44,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.034347\n",
            " 43%|████▎     | 20/46 [00:24<00:32,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.032227\n",
            " 65%|██████▌   | 30/46 [00:37<00:19,  1.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.048686\n",
            " 87%|████████▋ | 40/46 [00:49<00:07,  1.23s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.056566\n",
            "100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0465 (train) | 0.0900 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.047486632398322626,\n",
              "   0.047196426256434804,\n",
              "   0.047058130071561906,\n",
              "   0.04709125341461678,\n",
              "   0.04716327316746249,\n",
              "   0.046592893526317,\n",
              "   0.046536169300100676,\n",
              "   0.046519595347678175,\n",
              "   0.046652095596173344,\n",
              "   0.046616946851497504,\n",
              "   0.04637570472027791,\n",
              "   0.04635225279488731,\n",
              "   0.04649258874925924,\n",
              "   0.046267869267599876,\n",
              "   0.04629474335798131,\n",
              "   0.046335673448100884,\n",
              "   0.046435365823840405,\n",
              "   0.04630330177786755,\n",
              "   0.046487058664775274,\n",
              "   0.04640653567915527,\n",
              "   0.04635315046165618,\n",
              "   0.04648971860921965,\n",
              "   0.04626599124953899,\n",
              "   0.04620287721721534,\n",
              "   0.046211149382000535,\n",
              "   0.04632810535292665,\n",
              "   0.04648138859090687,\n",
              "   0.04643177657458016,\n",
              "   0.04619843781722552,\n",
              "   0.04643400682614576,\n",
              "   0.04639851850574786,\n",
              "   0.04626025733296328,\n",
              "   0.046227651841153954,\n",
              "   0.046416292824645905,\n",
              "   0.04653943499007967]},\n",
              " 'val': {'loss': [0.09172407786051433,\n",
              "   0.09142073740561803,\n",
              "   0.09145066390434901,\n",
              "   0.09110987683137257,\n",
              "   0.09178401529788971,\n",
              "   0.09047169735034306,\n",
              "   0.09016593048969905,\n",
              "   0.09040738393863042,\n",
              "   0.0902808556954066,\n",
              "   0.09001727153857549,\n",
              "   0.09012304743131001,\n",
              "   0.09008405109246571,\n",
              "   0.09015083809693654,\n",
              "   0.09000124285618465,\n",
              "   0.09000534812609355,\n",
              "   0.08998425304889679,\n",
              "   0.09009712934494019,\n",
              "   0.09006944298744202,\n",
              "   0.0901187335451444,\n",
              "   0.0900625189145406,\n",
              "   0.09008652716875076,\n",
              "   0.08986165622870128,\n",
              "   0.08999281873305638,\n",
              "   0.09004852424065272,\n",
              "   0.09013692041238149,\n",
              "   0.09021430214246114,\n",
              "   0.0899387076497078,\n",
              "   0.09000314027070999,\n",
              "   0.090147465467453,\n",
              "   0.08996705214182536,\n",
              "   0.08993536978960037,\n",
              "   0.0899167110522588,\n",
              "   0.09003135561943054,\n",
              "   0.09011997034152348,\n",
              "   0.09002317488193512]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "312482e3-018e-4521-c462-76a129e43c17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "f8075e23-2d1b-40d4-962e-77019f952f3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "kH5xVXQyG09W",
        "outputId": "d6dcfaac-0d25-4377-bd5d-db55f384ffcb",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv13.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7aac965efa01>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodelhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv13.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pv_vision/nn/modelhandler.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;34m\"\"\" Load model from path \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         self.model.load_state_dict(\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         )\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv13.pt'"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv15.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "2dbbfcbe-da9f-415e-a87d-98392575059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:18<00:00, 21.52s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1105\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv14')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}