{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "50601806-12fe-4ed4-8d51-a097bd600c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "1844baae-a99b-48bf-c268-d922b77cbf81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "45651305-0c7d-4fab-ed75-d1c0888ad18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "outputId": "3df2abea-ca21-4d17-b9e4-c434c8b4d755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:11<00:00, 48.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "8c2d8aac-4bf9-4bc9-dc7a-b521daea4ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziFXmCGaUubr"
      },
      "outputs": [],
      "source": [
        "class Precision:\n",
        "    \"\"\"Calculate precision of a model\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"precision\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Compute the precision.\n",
        "        Args:\n",
        "        ------\n",
        "        outputs: torch.Tensor\n",
        "        The output of the model, shape (batch_size, num_classes)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        The ground truth label, shape (batch_size, )\n",
        "\n",
        "        reduction: str\n",
        "        The reduction method, 'mean' or 'sum'\n",
        "        If 'mean', return the mean precision of the batch\n",
        "        If 'sum', return the sum of correct predictions of the batch\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        precision: torch.Tensor\n",
        "        \"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return correct / total\n",
        "        elif reduction == 'sum':\n",
        "            return correct\n",
        "        else:\n",
        "            raise ValueError(\"reduction must be 'mean' or 'sum'\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Accumulate the metric over batches.\"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "        self.base[0] += correct\n",
        "        self.base[1] += total\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Return the accumulated score in one epoch.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # divide by zero warning\n",
        "            warnings.warn(\"The denominator is zero, return 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0] / self.base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "0ad52423-9ee4-4a2e-e2f0-0289ae89633d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetPV.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "1d41655f-8ba7-4981-ce68-b6509c54185d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=25,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv7.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "10eea47d-2568-494f-c66a-932005b0e71b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.204484\n",
            " 11%|█         | 10/91 [01:06<08:53,  6.58s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1453 (11%)]\tLoss: 0.238498\n",
            " 22%|██▏       | 20/91 [02:10<07:28,  6.31s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.209934\n",
            " 33%|███▎      | 30/91 [03:13<06:16,  6.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1453 (33%)]\tLoss: 0.140524\n",
            " 44%|████▍     | 40/91 [04:16<05:19,  6.26s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (44%)]\tLoss: 0.264599\n",
            " 55%|█████▍    | 50/91 [05:18<04:09,  6.10s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1453 (55%)]\tLoss: 0.159440\n",
            " 66%|██████▌   | 60/91 [06:22<03:17,  6.38s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (66%)]\tLoss: 0.109751\n",
            " 77%|███████▋  | 70/91 [07:26<02:11,  6.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1120/1453 (77%)]\tLoss: 0.123429\n",
            " 88%|████████▊ | 80/91 [08:29<01:09,  6.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (88%)]\tLoss: 0.210918\n",
            " 99%|█████████▉| 90/91 [09:32<00:06,  6.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1170/1453 (99%)]\tLoss: 0.152355\n",
            "100%|██████████| 91/91 [09:38<00:00,  6.36s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 6/6 [00:33<00:00,  5.50s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.3579\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1991 (train) | 0.3579 (val)\n",
            "Epoch 2 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.138066\n",
            " 11%|█         | 10/91 [00:09<01:16,  1.06it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1453 (11%)]\tLoss: 0.128993\n",
            " 22%|██▏       | 20/91 [00:18<01:08,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.175835\n",
            " 33%|███▎      | 30/91 [00:28<00:58,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1453 (33%)]\tLoss: 0.128769\n",
            " 44%|████▍     | 40/91 [00:38<00:48,  1.04it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (44%)]\tLoss: 0.129820\n",
            " 55%|█████▍    | 50/91 [00:48<00:39,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1453 (55%)]\tLoss: 0.158552\n",
            " 66%|██████▌   | 60/91 [00:58<00:30,  1.03it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (66%)]\tLoss: 0.129563\n",
            " 77%|███████▋  | 70/91 [01:08<00:20,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1120/1453 (77%)]\tLoss: 0.126239\n",
            " 88%|████████▊ | 80/91 [01:18<00:11,  1.00s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (88%)]\tLoss: 0.098934\n",
            " 99%|█████████▉| 90/91 [01:28<00:01,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1170/1453 (99%)]\tLoss: 0.171485\n",
            "100%|██████████| 91/91 [01:30<00:00,  1.01it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.2395\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1381 (train) | 0.2395 (val)\n",
            "Epoch 3 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.168030\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1453 (11%)]\tLoss: 0.112501\n",
            " 22%|██▏       | 20/91 [00:19<01:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.140273\n",
            " 33%|███▎      | 30/91 [00:29<00:59,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1453 (33%)]\tLoss: 0.121734\n",
            " 44%|████▍     | 40/91 [00:39<00:49,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (44%)]\tLoss: 0.154574\n",
            " 55%|█████▍    | 50/91 [00:49<00:40,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1453 (55%)]\tLoss: 0.074857\n",
            " 66%|██████▌   | 60/91 [00:59<00:30,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (66%)]\tLoss: 0.101680\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1120/1453 (77%)]\tLoss: 0.154202\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (88%)]\tLoss: 0.100680\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1170/1453 (99%)]\tLoss: 0.114560\n",
            "100%|██████████| 91/91 [01:31<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.5028\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1275 (train) | 0.5028 (val)\n",
            "Epoch 4 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.204818\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1453 (11%)]\tLoss: 0.141662\n",
            " 22%|██▏       | 20/91 [00:19<01:09,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.094677\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1453 (33%)]\tLoss: 0.145056\n",
            " 44%|████▍     | 40/91 [00:39<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (44%)]\tLoss: 0.106604\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1453 (55%)]\tLoss: 0.115094\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (66%)]\tLoss: 0.121153\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1120/1453 (77%)]\tLoss: 0.154522\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (88%)]\tLoss: 0.105585\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1170/1453 (99%)]\tLoss: 0.110492\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.2019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1168 (train) | 0.2019 (val)\n",
            "Epoch 5 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.080995\n",
            " 11%|█         | 10/91 [00:09<01:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1453 (11%)]\tLoss: 0.121430\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.121391\n",
            " 33%|███▎      | 30/91 [00:30<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1453 (33%)]\tLoss: 0.097537\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (44%)]\tLoss: 0.118672\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1453 (55%)]\tLoss: 0.103420\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (66%)]\tLoss: 0.070733\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1120/1453 (77%)]\tLoss: 0.085103\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (88%)]\tLoss: 0.183135\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1170/1453 (99%)]\tLoss: 0.060688\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.02s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.2773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1076 (train) | 0.2773 (val)\n",
            "Epoch 6 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.128699\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1453 (11%)]\tLoss: 0.065526\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.092351\n",
            " 33%|███▎      | 30/91 [00:30<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1453 (33%)]\tLoss: 0.104127\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (44%)]\tLoss: 0.060184\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1453 (55%)]\tLoss: 0.066551\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (66%)]\tLoss: 0.120621\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1120/1453 (77%)]\tLoss: 0.076026\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (88%)]\tLoss: 0.077967\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1170/1453 (99%)]\tLoss: 0.061339\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1996\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0949 (train) | 0.1996 (val)\n",
            "Epoch 7 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.069941\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1453 (11%)]\tLoss: 0.111479\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.077981\n",
            " 33%|███▎      | 30/91 [00:30<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1453 (33%)]\tLoss: 0.105091\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (44%)]\tLoss: 0.077520\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1453 (55%)]\tLoss: 0.077639\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (66%)]\tLoss: 0.064765\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1120/1453 (77%)]\tLoss: 0.079118\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (88%)]\tLoss: 0.077274\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1170/1453 (99%)]\tLoss: 0.085246\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.02s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.67it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0896 (train) | 0.1719 (val)\n",
            "Epoch 8 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.104525\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1453 (11%)]\tLoss: 0.108538\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.078476\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1453 (33%)]\tLoss: 0.096009\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (44%)]\tLoss: 0.071178\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1453 (55%)]\tLoss: 0.071413\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (66%)]\tLoss: 0.178597\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1120/1453 (77%)]\tLoss: 0.087257\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (88%)]\tLoss: 0.105536\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1170/1453 (99%)]\tLoss: 0.080945\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1753\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0867 (train) | 0.1753 (val)\n",
            "Epoch 9 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.071056\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1453 (11%)]\tLoss: 0.072915\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.113591\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1453 (33%)]\tLoss: 0.086895\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (44%)]\tLoss: 0.054977\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1453 (55%)]\tLoss: 0.067564\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (66%)]\tLoss: 0.078569\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1120/1453 (77%)]\tLoss: 0.084153\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (88%)]\tLoss: 0.076468\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1170/1453 (99%)]\tLoss: 0.161368\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1560\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0839 (train) | 0.1560 (val)\n",
            "Epoch 10 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.066902\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1453 (11%)]\tLoss: 0.062511\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.078753\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1453 (33%)]\tLoss: 0.098146\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (44%)]\tLoss: 0.049302\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1453 (55%)]\tLoss: 0.087892\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (66%)]\tLoss: 0.117364\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1120/1453 (77%)]\tLoss: 0.076101\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (88%)]\tLoss: 0.110014\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1170/1453 (99%)]\tLoss: 0.098418\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0827 (train) | 0.1623 (val)\n",
            "Epoch 11 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.080796\n",
            " 11%|█         | 10/91 [00:09<01:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1453 (11%)]\tLoss: 0.065901\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.077851\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1453 (33%)]\tLoss: 0.062262\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (44%)]\tLoss: 0.070903\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1453 (55%)]\tLoss: 0.053368\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (66%)]\tLoss: 0.074237\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1120/1453 (77%)]\tLoss: 0.056552\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (88%)]\tLoss: 0.077127\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1170/1453 (99%)]\tLoss: 0.048295\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0783 (train) | 0.1541 (val)\n",
            "Epoch 12 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.132176\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1453 (11%)]\tLoss: 0.046858\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.074096\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1453 (33%)]\tLoss: 0.057120\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (44%)]\tLoss: 0.057393\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1453 (55%)]\tLoss: 0.100963\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (66%)]\tLoss: 0.090816\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1120/1453 (77%)]\tLoss: 0.067758\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (88%)]\tLoss: 0.074764\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1170/1453 (99%)]\tLoss: 0.063388\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1484\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0760 (train) | 0.1484 (val)\n",
            "Epoch 13 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.105422\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1453 (11%)]\tLoss: 0.082199\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.062958\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1453 (33%)]\tLoss: 0.071638\n",
            " 44%|████▍     | 40/91 [00:39<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (44%)]\tLoss: 0.070805\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1453 (55%)]\tLoss: 0.074226\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (66%)]\tLoss: 0.050396\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1120/1453 (77%)]\tLoss: 0.073082\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (88%)]\tLoss: 0.095522\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1170/1453 (99%)]\tLoss: 0.075315\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1417\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0748 (train) | 0.1417 (val)\n",
            "Epoch 14 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.063384\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1453 (11%)]\tLoss: 0.062838\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.062792\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1453 (33%)]\tLoss: 0.074896\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (44%)]\tLoss: 0.081845\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1453 (55%)]\tLoss: 0.073722\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (66%)]\tLoss: 0.086835\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1120/1453 (77%)]\tLoss: 0.047960\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (88%)]\tLoss: 0.080640\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1170/1453 (99%)]\tLoss: 0.104693\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0745 (train) | 0.1437 (val)\n",
            "Epoch 15 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.069886\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1453 (11%)]\tLoss: 0.051385\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.063691\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1453 (33%)]\tLoss: 0.096405\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (44%)]\tLoss: 0.094462\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1453 (55%)]\tLoss: 0.052024\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (66%)]\tLoss: 0.077099\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1120/1453 (77%)]\tLoss: 0.076921\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (88%)]\tLoss: 0.052039\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1170/1453 (99%)]\tLoss: 0.056790\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1472\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0741 (train) | 0.1472 (val)\n",
            "Epoch 16 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.076929\n",
            " 11%|█         | 10/91 [00:09<01:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [160/1453 (11%)]\tLoss: 0.069675\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.127218\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [480/1453 (33%)]\tLoss: 0.058831\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (44%)]\tLoss: 0.051132\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [800/1453 (55%)]\tLoss: 0.062099\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (66%)]\tLoss: 0.073234\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1120/1453 (77%)]\tLoss: 0.078754\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (88%)]\tLoss: 0.063848\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1170/1453 (99%)]\tLoss: 0.104273\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1384\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0720 (train) | 0.1384 (val)\n",
            "Epoch 17 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.068040\n",
            " 11%|█         | 10/91 [00:09<01:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [160/1453 (11%)]\tLoss: 0.075476\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.074247\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [480/1453 (33%)]\tLoss: 0.075317\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (44%)]\tLoss: 0.060513\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [800/1453 (55%)]\tLoss: 0.057551\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (66%)]\tLoss: 0.068694\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1120/1453 (77%)]\tLoss: 0.063408\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (88%)]\tLoss: 0.084424\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1170/1453 (99%)]\tLoss: 0.081924\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0717 (train) | 0.1396 (val)\n",
            "Epoch 18 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.049609\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [160/1453 (11%)]\tLoss: 0.043847\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.052450\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [480/1453 (33%)]\tLoss: 0.065413\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (44%)]\tLoss: 0.075688\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [800/1453 (55%)]\tLoss: 0.069699\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (66%)]\tLoss: 0.065285\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1120/1453 (77%)]\tLoss: 0.056212\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (88%)]\tLoss: 0.061779\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1170/1453 (99%)]\tLoss: 0.055400\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1405\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0714 (train) | 0.1405 (val)\n",
            "Epoch 19 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.125071\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [160/1453 (11%)]\tLoss: 0.065697\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.061500\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [480/1453 (33%)]\tLoss: 0.079565\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (44%)]\tLoss: 0.072639\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [800/1453 (55%)]\tLoss: 0.045623\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (66%)]\tLoss: 0.043978\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1120/1453 (77%)]\tLoss: 0.082035\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (88%)]\tLoss: 0.100484\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1170/1453 (99%)]\tLoss: 0.065744\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1367\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0709 (train) | 0.1367 (val)\n",
            "Epoch 20 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.077602\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [160/1453 (11%)]\tLoss: 0.063657\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.093120\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [480/1453 (33%)]\tLoss: 0.088133\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (44%)]\tLoss: 0.083314\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [800/1453 (55%)]\tLoss: 0.053903\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (66%)]\tLoss: 0.058213\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1120/1453 (77%)]\tLoss: 0.076783\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (88%)]\tLoss: 0.093302\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1170/1453 (99%)]\tLoss: 0.122766\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1391\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0713 (train) | 0.1391 (val)\n",
            "Epoch 21 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.063166\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [160/1453 (11%)]\tLoss: 0.140934\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.074470\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [480/1453 (33%)]\tLoss: 0.079076\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (44%)]\tLoss: 0.065047\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [800/1453 (55%)]\tLoss: 0.098414\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (66%)]\tLoss: 0.058456\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1120/1453 (77%)]\tLoss: 0.048709\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (88%)]\tLoss: 0.075640\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1170/1453 (99%)]\tLoss: 0.058218\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1392\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0704 (train) | 0.1392 (val)\n",
            "Epoch 22 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.074808\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [160/1453 (11%)]\tLoss: 0.066261\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.062833\n",
            " 33%|███▎      | 30/91 [00:30<01:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [480/1453 (33%)]\tLoss: 0.066348\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (44%)]\tLoss: 0.070595\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [800/1453 (55%)]\tLoss: 0.074133\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (66%)]\tLoss: 0.063290\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1120/1453 (77%)]\tLoss: 0.049374\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (88%)]\tLoss: 0.070764\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1170/1453 (99%)]\tLoss: 0.040921\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1382\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0704 (train) | 0.1382 (val)\n",
            "Epoch 23 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.074494\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [160/1453 (11%)]\tLoss: 0.070304\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.062373\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [480/1453 (33%)]\tLoss: 0.069371\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (44%)]\tLoss: 0.083454\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [800/1453 (55%)]\tLoss: 0.120508\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (66%)]\tLoss: 0.063415\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1120/1453 (77%)]\tLoss: 0.063945\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (88%)]\tLoss: 0.045832\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1170/1453 (99%)]\tLoss: 0.058161\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1399\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0703 (train) | 0.1399 (val)\n",
            "Epoch 24 / 25\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.067400\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [160/1453 (11%)]\tLoss: 0.064135\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.059575\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [480/1453 (33%)]\tLoss: 0.116683\n",
            " 44%|████▍     | 40/91 [00:40<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (44%)]\tLoss: 0.100691\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [800/1453 (55%)]\tLoss: 0.055181\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (66%)]\tLoss: 0.082463\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1120/1453 (77%)]\tLoss: 0.079609\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (88%)]\tLoss: 0.108417\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1170/1453 (99%)]\tLoss: 0.078744\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1371\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0706 (train) | 0.1371 (val)\n",
            "Epoch 25 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.051143\n",
            " 11%|█         | 10/91 [00:09<01:19,  1.02it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [160/1453 (11%)]\tLoss: 0.035865\n",
            " 22%|██▏       | 20/91 [00:19<01:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.067651\n",
            " 33%|███▎      | 30/91 [00:29<01:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [480/1453 (33%)]\tLoss: 0.079161\n",
            " 44%|████▍     | 40/91 [00:39<00:50,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (44%)]\tLoss: 0.047682\n",
            " 55%|█████▍    | 50/91 [00:50<00:40,  1.00it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [800/1453 (55%)]\tLoss: 0.081708\n",
            " 66%|██████▌   | 60/91 [01:00<00:30,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (66%)]\tLoss: 0.047424\n",
            " 77%|███████▋  | 70/91 [01:10<00:20,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1120/1453 (77%)]\tLoss: 0.067975\n",
            " 88%|████████▊ | 80/91 [01:20<00:10,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (88%)]\tLoss: 0.106300\n",
            " 99%|█████████▉| 90/91 [01:30<00:00,  1.01it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1170/1453 (99%)]\tLoss: 0.152418\n",
            "100%|██████████| 91/91 [01:32<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0706 (train) | 0.1373 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.19912951879064872,\n",
              "   0.138057731445789,\n",
              "   0.12747909370694419,\n",
              "   0.11676659831406737,\n",
              "   0.10763802947008602,\n",
              "   0.09489720489852853,\n",
              "   0.08960151068317587,\n",
              "   0.08671364344077034,\n",
              "   0.08393892701215278,\n",
              "   0.08274191534896595,\n",
              "   0.07829172406743004,\n",
              "   0.075974837458306,\n",
              "   0.07482363704620192,\n",
              "   0.07451746663551698,\n",
              "   0.07409052511052845,\n",
              "   0.07204862136883483,\n",
              "   0.0716596531892594,\n",
              "   0.07139217206683966,\n",
              "   0.0709245612323079,\n",
              "   0.07131770457264808,\n",
              "   0.07043054354545665,\n",
              "   0.07039764819632131,\n",
              "   0.07033686571371858,\n",
              "   0.07060050016239604,\n",
              "   0.07063472917058594]},\n",
              " 'val': {'loss': [0.3578682839870453,\n",
              "   0.2394880255063375,\n",
              "   0.5027919511000315,\n",
              "   0.20192035535971323,\n",
              "   0.2772615651289622,\n",
              "   0.19955477863550186,\n",
              "   0.17194640884796777,\n",
              "   0.17533526321252188,\n",
              "   0.1560362900296847,\n",
              "   0.16233627001444498,\n",
              "   0.15411576131979624,\n",
              "   0.14843785017728806,\n",
              "   0.14172680924336115,\n",
              "   0.1437300518155098,\n",
              "   0.14717578142881393,\n",
              "   0.138445728768905,\n",
              "   0.1395657112201055,\n",
              "   0.1404579853018125,\n",
              "   0.1367221176624298,\n",
              "   0.13905582328637442,\n",
              "   0.1392091140151024,\n",
              "   0.1381823793053627,\n",
              "   0.13990430533885956,\n",
              "   0.13708676025271416,\n",
              "   0.13725726182262102]}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "135c4b97-9ed3-4053-f2ea-1caf17856cb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "0df2efc6-a8c3-4947-f911-d2d2fb48b898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "cea49cda-fa29-4a6d-cf0c-582960cb264c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_19/unetv7.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_19/unetv7.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "72e5751c-c79b-4b23-a0fb-278c2d3d3c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [02:13<00:00,  5.79s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1201\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputV7')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}