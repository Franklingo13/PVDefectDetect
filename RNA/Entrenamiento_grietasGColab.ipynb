{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "d3770ce9-6b5c-4f2c-a9d0-a96a0ccdda74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "e35b9798-8c6b-45c9-8a0a-e150c6c22c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "4e5fb534-7fad-4594-9116-07ac3fc71a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "82c66586-8b4f-4422-8d80-9a0a58dc8a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0015)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "c22d09d0-98d1-41b8-935d-aed6943f70a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv16.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "e876a001-10ab-4a86-fd82-4f0eee1ce2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=35,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv17.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "9629cd0c-03a2-4966-b3c9-6e38f2c712d8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 1.603056\n",
            " 22%|██▏       | 10/46 [00:20<00:45,  1.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.634152\n",
            " 43%|████▎     | 20/46 [00:32<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.385444\n",
            " 65%|██████▌   | 30/46 [00:44<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.275373\n",
            " 87%|████████▋ | 40/46 [00:55<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.207748\n",
            "100%|██████████| 46/46 [01:03<00:00,  1.37s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.3196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4863 (train) | 0.3196 (val)\n",
            "Epoch 2 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.153724\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.148500\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.161471\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.132022\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.126383\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.2986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1418 (train) | 0.2986 (val)\n",
            "Epoch 3 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.107526\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.155304\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.114022\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.115592\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.073934\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.2375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1157 (train) | 0.2375 (val)\n",
            "Epoch 4 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.088948\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.109154\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.096116\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.091977\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.069906\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0975 (train) | 0.1665 (val)\n",
            "Epoch 5 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.142281\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.121044\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.086348\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.058921\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.071628\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0863 (train) | 0.1538 (val)\n",
            "Epoch 6 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.072020\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.067646\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.059425\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.064432\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.072794\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0732 (train) | 0.1360 (val)\n",
            "Epoch 7 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.084737\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.061611\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.070067\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.082244\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.081777\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0699 (train) | 0.1274 (val)\n",
            "Epoch 8 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.060867\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.056264\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.061400\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.069783\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.053567\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0673 (train) | 0.1225 (val)\n",
            "Epoch 9 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.053526\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.058548\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.058559\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.054253\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.073092\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0647 (train) | 0.1184 (val)\n",
            "Epoch 10 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.062656\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.064629\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.062021\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.055363\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.068328\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0643 (train) | 0.1197 (val)\n",
            "Epoch 11 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.069999\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.061891\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.070852\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.046604\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.076476\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0625 (train) | 0.1136 (val)\n",
            "Epoch 12 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.048648\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.056949\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.089161\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.080030\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.055394\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0609 (train) | 0.1121 (val)\n",
            "Epoch 13 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.064131\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.048300\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.064530\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.059781\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.063906\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0592 (train) | 0.1108 (val)\n",
            "Epoch 14 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.050252\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.062046\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.051108\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.042514\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.047825\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0589 (train) | 0.1096 (val)\n",
            "Epoch 15 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.061043\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.056479\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.077032\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.049704\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.078384\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0588 (train) | 0.1098 (val)\n",
            "Epoch 16 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.067423\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.050776\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.065289\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.059255\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.050462\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0580 (train) | 0.1083 (val)\n",
            "Epoch 17 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.064011\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.049932\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.057527\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.047366\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.057472\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0582 (train) | 0.1078 (val)\n",
            "Epoch 18 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.040652\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.039158\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.065382\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.055064\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.045587\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0577 (train) | 0.1085 (val)\n",
            "Epoch 19 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.075114\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.053833\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.068996\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.043425\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.055183\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0575 (train) | 0.1074 (val)\n",
            "Epoch 20 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.046815\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.053431\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.049523\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.068552\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.091783\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0576 (train) | 0.1068 (val)\n",
            "Epoch 21 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.043498\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.058989\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.052321\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.051246\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.041745\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0577 (train) | 0.1072 (val)\n",
            "Epoch 22 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.053537\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.045839\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.053313\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.040954\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.068162\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0580 (train) | 0.1068 (val)\n",
            "Epoch 23 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.056061\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.077724\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.054017\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.054437\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.057908\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0567 (train) | 0.1070 (val)\n",
            "Epoch 24 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.054773\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.063348\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.050007\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.044542\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.050872\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0578 (train) | 0.1069 (val)\n",
            "Epoch 25 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.059927\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.063123\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.039684\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.051636\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.053611\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0575 (train) | 0.1070 (val)\n",
            "Epoch 26 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.057267\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.070685\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.049542\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.058859\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.056096\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.1071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1071 (val)\n",
            "Epoch 27 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.051711\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.063828\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.058722\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.075037\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.049446\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.1069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0572 (train) | 0.1069 (val)\n",
            "Epoch 28 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.055165\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.078714\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.062128\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.062665\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.065292\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0573 (train) | 0.1070 (val)\n",
            "Epoch 29 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.056914\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.057352\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.067343\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.048777\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.050327\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.1069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0569 (train) | 0.1069 (val)\n",
            "Epoch 30 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.062592\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.057980\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.052332\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.065038\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.046914\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.1072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1072 (val)\n",
            "Epoch 31 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.073068\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.057064\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.051316\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.048292\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.047116\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1070 (val)\n",
            "Epoch 32 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.062645\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.067584\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.046002\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.045191\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.053292\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.1068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0569 (train) | 0.1068 (val)\n",
            "Epoch 33 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.062463\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.040327\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.048685\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.055871\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.049270\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.1067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0575 (train) | 0.1067 (val)\n",
            "Epoch 34 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.053308\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.046646\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.076457\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.046374\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.058319\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.1068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0570 (train) | 0.1068 (val)\n",
            "Epoch 35 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.043366\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.054009\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.065956\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.052915\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.070093\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.1069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0571 (train) | 0.1069 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.4862786236296665,\n",
              "   0.14183744887647676,\n",
              "   0.11565173975225981,\n",
              "   0.09745076475620106,\n",
              "   0.08634319685589258,\n",
              "   0.07322056671503242,\n",
              "   0.0699136009810304,\n",
              "   0.06728301282923384,\n",
              "   0.06469519790685022,\n",
              "   0.06434604770414844,\n",
              "   0.062451315127154176,\n",
              "   0.06087439043699916,\n",
              "   0.059177681229398406,\n",
              "   0.05889389963906466,\n",
              "   0.058827627042573806,\n",
              "   0.05802848397741955,\n",
              "   0.058170157685332353,\n",
              "   0.0576574809244191,\n",
              "   0.0574567813300627,\n",
              "   0.057640604892744335,\n",
              "   0.057731738740915445,\n",
              "   0.057950731618131184,\n",
              "   0.056695418769502674,\n",
              "   0.0577835628156488,\n",
              "   0.057493454441479463,\n",
              "   0.05682481152850927,\n",
              "   0.057245857447016595,\n",
              "   0.057281458461932784,\n",
              "   0.05690115664592711,\n",
              "   0.05684061969405441,\n",
              "   0.05681570762664551,\n",
              "   0.05685954750691786,\n",
              "   0.05746715222546255,\n",
              "   0.056996356098510774,\n",
              "   0.05705660927197233]},\n",
              " 'val': {'loss': [0.31955525279045105,\n",
              "   0.29857046405474347,\n",
              "   0.23750637471675873,\n",
              "   0.1665195127328237,\n",
              "   0.15376057724157968,\n",
              "   0.13598956167697906,\n",
              "   0.12741251538197199,\n",
              "   0.1224849596619606,\n",
              "   0.11842083434263866,\n",
              "   0.11968402067820232,\n",
              "   0.11356406410535176,\n",
              "   0.11210733155409495,\n",
              "   0.11077394336462021,\n",
              "   0.10955171287059784,\n",
              "   0.1097513238588969,\n",
              "   0.10830674072106679,\n",
              "   0.10782231390476227,\n",
              "   0.10850958526134491,\n",
              "   0.10736970603466034,\n",
              "   0.10679948329925537,\n",
              "   0.1072423333923022,\n",
              "   0.10684750725825627,\n",
              "   0.10701148957014084,\n",
              "   0.10694462060928345,\n",
              "   0.10697704553604126,\n",
              "   0.10711574306090672,\n",
              "   0.10694308330615361,\n",
              "   0.1070008526245753,\n",
              "   0.10692261656125386,\n",
              "   0.10715831319491069,\n",
              "   0.1069824347893397,\n",
              "   0.10681517173846562,\n",
              "   0.10671210785706838,\n",
              "   0.10683288425207138,\n",
              "   0.1069262425104777]}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "819e0eb4-8e40-48b5-f148-213824c0cb91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "bb7a4c34-1225-4587-f2a1-d69adbac67b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "4ac21d98-e347-46fe-9a23-3f58eac0a0ac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_10/unetv15.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv16.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "ca76ae45-4464-447f-b578-bb0e75ec0909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:05<00:00, 20.48s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1089\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv16')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}