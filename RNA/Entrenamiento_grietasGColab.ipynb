{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "21f77708-134c-4ecc-c396-59bf4e802852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "9e4e6b8f-99cd-4767-8950-4401efa1434a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "2613dde4-ef8a-42f0-8709-f06d9a64e187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "outputId": "7b707213-bc75-4c98-f36e-225ba8a89f87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 87.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "952739a3-6a14-4e25-8503-305d6d6717bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziFXmCGaUubr"
      },
      "outputs": [],
      "source": [
        "class Precision:\n",
        "    \"\"\"Calculate precision of a model\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"precision\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Compute the precision.\n",
        "        Args:\n",
        "        ------\n",
        "        outputs: torch.Tensor\n",
        "        The output of the model, shape (batch_size, num_classes)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        The ground truth label, shape (batch_size, )\n",
        "\n",
        "        reduction: str\n",
        "        The reduction method, 'mean' or 'sum'\n",
        "        If 'mean', return the mean precision of the batch\n",
        "        If 'sum', return the sum of correct predictions of the batch\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        precision: torch.Tensor\n",
        "        \"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return correct / total\n",
        "        elif reduction == 'sum':\n",
        "            return correct\n",
        "        else:\n",
        "            raise ValueError(\"reduction must be 'mean' or 'sum'\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Accumulate the metric over batches.\"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "        self.base[0] += correct\n",
        "        self.base[1] += total\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Return the accumulated score in one epoch.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # divide by zero warning\n",
        "            warnings.warn(\"The denominator is zero, return 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0] / self.base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "ed8d2f6b-dd24-4413-a252-36e16d82b4f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv7.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "46939aa6-d621-4886-c587-54545e102086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=25,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv8.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "67dce4e5-62e6-4285-b1df-eb78cb139947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.056624\n",
            " 11%|█         | 10/91 [01:27<08:38,  6.40s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1453 (11%)]\tLoss: 0.073586\n",
            " 22%|██▏       | 20/91 [02:27<07:05,  6.00s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.059714\n",
            " 33%|███▎      | 30/91 [03:29<06:15,  6.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1453 (33%)]\tLoss: 0.057634\n",
            " 44%|████▍     | 40/91 [04:30<05:05,  5.98s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (44%)]\tLoss: 0.066564\n",
            " 55%|█████▍    | 50/91 [05:31<04:06,  6.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1453 (55%)]\tLoss: 0.072799\n",
            " 66%|██████▌   | 60/91 [06:32<03:09,  6.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (66%)]\tLoss: 0.049534\n",
            " 77%|███████▋  | 70/91 [07:32<02:06,  6.00s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1120/1453 (77%)]\tLoss: 0.098814\n",
            " 88%|████████▊ | 80/91 [08:33<01:07,  6.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (88%)]\tLoss: 0.116440\n",
            " 99%|█████████▉| 90/91 [09:35<00:06,  6.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1170/1453 (99%)]\tLoss: 0.095829\n",
            "100%|██████████| 91/91 [09:40<00:00,  6.38s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 6/6 [01:07<00:00, 11.28s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0760 (train) | 0.1396 (val)\n",
            "Epoch 2 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.071426\n",
            " 11%|█         | 10/91 [00:10<01:27,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1453 (11%)]\tLoss: 0.101633\n",
            " 22%|██▏       | 20/91 [00:21<01:17,  1.09s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.079803\n",
            " 33%|███▎      | 30/91 [00:32<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1453 (33%)]\tLoss: 0.055858\n",
            " 44%|████▍     | 40/91 [00:42<00:52,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (44%)]\tLoss: 0.098443\n",
            " 55%|█████▍    | 50/91 [00:53<00:42,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1453 (55%)]\tLoss: 0.085167\n",
            " 66%|██████▌   | 60/91 [01:03<00:31,  1.02s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (66%)]\tLoss: 0.063992\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1120/1453 (77%)]\tLoss: 0.056582\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (88%)]\tLoss: 0.064782\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1170/1453 (99%)]\tLoss: 0.077740\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0734 (train) | 0.1380 (val)\n",
            "Epoch 3 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.056708\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1453 (11%)]\tLoss: 0.064515\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.078880\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1453 (33%)]\tLoss: 0.063081\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (44%)]\tLoss: 0.085417\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1453 (55%)]\tLoss: 0.068797\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (66%)]\tLoss: 0.074627\n",
            " 77%|███████▋  | 70/91 [01:13<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1120/1453 (77%)]\tLoss: 0.067604\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (88%)]\tLoss: 0.073995\n",
            " 99%|█████████▉| 90/91 [01:34<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1170/1453 (99%)]\tLoss: 0.070744\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 6/6 [00:03<00:00,  2.00it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0719 (train) | 0.1476 (val)\n",
            "Epoch 4 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.065084\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1453 (11%)]\tLoss: 0.069165\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.070746\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1453 (33%)]\tLoss: 0.072682\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (44%)]\tLoss: 0.048969\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1453 (55%)]\tLoss: 0.070679\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (66%)]\tLoss: 0.074881\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1120/1453 (77%)]\tLoss: 0.069099\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (88%)]\tLoss: 0.049070\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1170/1453 (99%)]\tLoss: 0.085046\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0694 (train) | 0.1288 (val)\n",
            "Epoch 5 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.061363\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1453 (11%)]\tLoss: 0.053510\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.055109\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1453 (33%)]\tLoss: 0.087131\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (44%)]\tLoss: 0.057420\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1453 (55%)]\tLoss: 0.094686\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (66%)]\tLoss: 0.082853\n",
            " 77%|███████▋  | 70/91 [01:13<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1120/1453 (77%)]\tLoss: 0.052732\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (88%)]\tLoss: 0.046398\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1170/1453 (99%)]\tLoss: 0.087314\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0682 (train) | 0.1259 (val)\n",
            "Epoch 6 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.054130\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1453 (11%)]\tLoss: 0.049419\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.062336\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1453 (33%)]\tLoss: 0.051477\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (44%)]\tLoss: 0.061076\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1453 (55%)]\tLoss: 0.049217\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (66%)]\tLoss: 0.066015\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1120/1453 (77%)]\tLoss: 0.071393\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (88%)]\tLoss: 0.077848\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1170/1453 (99%)]\tLoss: 0.047924\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0639 (train) | 0.1254 (val)\n",
            "Epoch 7 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.055380\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1453 (11%)]\tLoss: 0.084561\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.108394\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1453 (33%)]\tLoss: 0.064424\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (44%)]\tLoss: 0.057978\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1453 (55%)]\tLoss: 0.053265\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (66%)]\tLoss: 0.058474\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1120/1453 (77%)]\tLoss: 0.066233\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (88%)]\tLoss: 0.051849\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1170/1453 (99%)]\tLoss: 0.077238\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0632 (train) | 0.1207 (val)\n",
            "Epoch 8 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.061547\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1453 (11%)]\tLoss: 0.082511\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.045326\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1453 (33%)]\tLoss: 0.104241\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (44%)]\tLoss: 0.051353\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1453 (55%)]\tLoss: 0.066587\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (66%)]\tLoss: 0.075532\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1120/1453 (77%)]\tLoss: 0.038054\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (88%)]\tLoss: 0.104847\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1170/1453 (99%)]\tLoss: 0.060697\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0637 (train) | 0.1236 (val)\n",
            "Epoch 9 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.080012\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1453 (11%)]\tLoss: 0.074342\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.060309\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1453 (33%)]\tLoss: 0.060918\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (44%)]\tLoss: 0.077292\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1453 (55%)]\tLoss: 0.059618\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (66%)]\tLoss: 0.081502\n",
            " 77%|███████▋  | 70/91 [01:13<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1120/1453 (77%)]\tLoss: 0.060968\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (88%)]\tLoss: 0.079998\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1170/1453 (99%)]\tLoss: 0.108312\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0624 (train) | 0.1218 (val)\n",
            "Epoch 10 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.070502\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1453 (11%)]\tLoss: 0.033034\n",
            " 22%|██▏       | 20/91 [00:20<01:13,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.072857\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1453 (33%)]\tLoss: 0.062147\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (44%)]\tLoss: 0.070951\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1453 (55%)]\tLoss: 0.059304\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (66%)]\tLoss: 0.066585\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1120/1453 (77%)]\tLoss: 0.046285\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (88%)]\tLoss: 0.055315\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1170/1453 (99%)]\tLoss: 0.059380\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0614 (train) | 0.1163 (val)\n",
            "Epoch 11 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.068229\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1453 (11%)]\tLoss: 0.046945\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.042848\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1453 (33%)]\tLoss: 0.068980\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (44%)]\tLoss: 0.059155\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1453 (55%)]\tLoss: 0.079570\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (66%)]\tLoss: 0.060656\n",
            " 77%|███████▋  | 70/91 [01:13<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1120/1453 (77%)]\tLoss: 0.044692\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (88%)]\tLoss: 0.056897\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1170/1453 (99%)]\tLoss: 0.070202\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0604 (train) | 0.1153 (val)\n",
            "Epoch 12 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.101080\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1453 (11%)]\tLoss: 0.064255\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.065166\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1453 (33%)]\tLoss: 0.040093\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (44%)]\tLoss: 0.052776\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1453 (55%)]\tLoss: 0.057717\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (66%)]\tLoss: 0.068503\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1120/1453 (77%)]\tLoss: 0.067362\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (88%)]\tLoss: 0.077222\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1170/1453 (99%)]\tLoss: 0.050970\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.74it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0602 (train) | 0.1152 (val)\n",
            "Epoch 13 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.048793\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1453 (11%)]\tLoss: 0.074690\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.060770\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1453 (33%)]\tLoss: 0.051854\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (44%)]\tLoss: 0.072488\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1453 (55%)]\tLoss: 0.052199\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (66%)]\tLoss: 0.043963\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1120/1453 (77%)]\tLoss: 0.045089\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (88%)]\tLoss: 0.042639\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1170/1453 (99%)]\tLoss: 0.055752\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0601 (train) | 0.1144 (val)\n",
            "Epoch 14 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.116770\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1453 (11%)]\tLoss: 0.078557\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.059995\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1453 (33%)]\tLoss: 0.063159\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (44%)]\tLoss: 0.066939\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1453 (55%)]\tLoss: 0.053538\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (66%)]\tLoss: 0.069335\n",
            " 77%|███████▋  | 70/91 [01:13<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1120/1453 (77%)]\tLoss: 0.060214\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (88%)]\tLoss: 0.065391\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1170/1453 (99%)]\tLoss: 0.077384\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0600 (train) | 0.1142 (val)\n",
            "Epoch 15 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.055941\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1453 (11%)]\tLoss: 0.074607\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.064617\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1453 (33%)]\tLoss: 0.053180\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (44%)]\tLoss: 0.050519\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1453 (55%)]\tLoss: 0.085864\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (66%)]\tLoss: 0.043662\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1120/1453 (77%)]\tLoss: 0.077111\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (88%)]\tLoss: 0.041736\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1170/1453 (99%)]\tLoss: 0.062831\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0600 (train) | 0.1149 (val)\n",
            "Epoch 16 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.099476\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [160/1453 (11%)]\tLoss: 0.079610\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.053614\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [480/1453 (33%)]\tLoss: 0.062040\n",
            " 44%|████▍     | 40/91 [00:41<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (44%)]\tLoss: 0.063008\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [800/1453 (55%)]\tLoss: 0.048268\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (66%)]\tLoss: 0.067271\n",
            " 77%|███████▋  | 70/91 [01:13<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1120/1453 (77%)]\tLoss: 0.058378\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (88%)]\tLoss: 0.048922\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1170/1453 (99%)]\tLoss: 0.027279\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.99it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0596 (train) | 0.1140 (val)\n",
            "Epoch 17 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.056320\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [160/1453 (11%)]\tLoss: 0.041097\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.085019\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [480/1453 (33%)]\tLoss: 0.052932\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (44%)]\tLoss: 0.048702\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [800/1453 (55%)]\tLoss: 0.058601\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (66%)]\tLoss: 0.064150\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1120/1453 (77%)]\tLoss: 0.064890\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (88%)]\tLoss: 0.072855\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1170/1453 (99%)]\tLoss: 0.042987\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0590 (train) | 0.1140 (val)\n",
            "Epoch 18 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.058114\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [160/1453 (11%)]\tLoss: 0.057193\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.076337\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [480/1453 (33%)]\tLoss: 0.056906\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (44%)]\tLoss: 0.063737\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [800/1453 (55%)]\tLoss: 0.080473\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (66%)]\tLoss: 0.042964\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1120/1453 (77%)]\tLoss: 0.062416\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (88%)]\tLoss: 0.074793\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1170/1453 (99%)]\tLoss: 0.090324\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0593 (train) | 0.1131 (val)\n",
            "Epoch 19 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.039444\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [160/1453 (11%)]\tLoss: 0.066721\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.129251\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [480/1453 (33%)]\tLoss: 0.037027\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (44%)]\tLoss: 0.043858\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [800/1453 (55%)]\tLoss: 0.045429\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (66%)]\tLoss: 0.059539\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1120/1453 (77%)]\tLoss: 0.037598\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (88%)]\tLoss: 0.102813\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1170/1453 (99%)]\tLoss: 0.061388\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0596 (train) | 0.1135 (val)\n",
            "Epoch 20 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.076978\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [160/1453 (11%)]\tLoss: 0.044658\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.065592\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [480/1453 (33%)]\tLoss: 0.054403\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (44%)]\tLoss: 0.063105\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [800/1453 (55%)]\tLoss: 0.041317\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (66%)]\tLoss: 0.047715\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1120/1453 (77%)]\tLoss: 0.054124\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (88%)]\tLoss: 0.048636\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1170/1453 (99%)]\tLoss: 0.056740\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0593 (train) | 0.1137 (val)\n",
            "Epoch 21 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.074136\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [160/1453 (11%)]\tLoss: 0.051438\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.045158\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [480/1453 (33%)]\tLoss: 0.059188\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (44%)]\tLoss: 0.058982\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [800/1453 (55%)]\tLoss: 0.064133\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (66%)]\tLoss: 0.046350\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1120/1453 (77%)]\tLoss: 0.060583\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (88%)]\tLoss: 0.061910\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1170/1453 (99%)]\tLoss: 0.058365\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0594 (train) | 0.1137 (val)\n",
            "Epoch 22 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.048574\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [160/1453 (11%)]\tLoss: 0.078469\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.069647\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [480/1453 (33%)]\tLoss: 0.037315\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (44%)]\tLoss: 0.070239\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [800/1453 (55%)]\tLoss: 0.065937\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (66%)]\tLoss: 0.044678\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1120/1453 (77%)]\tLoss: 0.037798\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (88%)]\tLoss: 0.079826\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1170/1453 (99%)]\tLoss: 0.056583\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0591 (train) | 0.1139 (val)\n",
            "Epoch 23 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.070048\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [160/1453 (11%)]\tLoss: 0.063665\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.046581\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [480/1453 (33%)]\tLoss: 0.062523\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (44%)]\tLoss: 0.060292\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [800/1453 (55%)]\tLoss: 0.054738\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (66%)]\tLoss: 0.050575\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1120/1453 (77%)]\tLoss: 0.051938\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (88%)]\tLoss: 0.066380\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1170/1453 (99%)]\tLoss: 0.090411\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0596 (train) | 0.1140 (val)\n",
            "Epoch 24 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.047260\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [160/1453 (11%)]\tLoss: 0.079845\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.051734\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [480/1453 (33%)]\tLoss: 0.069663\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (44%)]\tLoss: 0.094522\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [800/1453 (55%)]\tLoss: 0.096083\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (66%)]\tLoss: 0.119163\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1120/1453 (77%)]\tLoss: 0.037443\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (88%)]\tLoss: 0.039571\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1170/1453 (99%)]\tLoss: 0.036598\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0595 (train) | 0.1142 (val)\n",
            "Epoch 25 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.078111\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [160/1453 (11%)]\tLoss: 0.085528\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.034337\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [480/1453 (33%)]\tLoss: 0.059140\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (44%)]\tLoss: 0.048451\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [800/1453 (55%)]\tLoss: 0.045978\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (66%)]\tLoss: 0.072233\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1120/1453 (77%)]\tLoss: 0.038964\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (88%)]\tLoss: 0.042105\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1170/1453 (99%)]\tLoss: 0.065085\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0594 (train) | 0.1143 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.07603863135995491,\n",
              "   0.0734082664589347,\n",
              "   0.07194327225643278,\n",
              "   0.06944576041684508,\n",
              "   0.06823159304062253,\n",
              "   0.06388677851503993,\n",
              "   0.06322215884636782,\n",
              "   0.06368830214470564,\n",
              "   0.06235802176691135,\n",
              "   0.061401090834030836,\n",
              "   0.06044745766759657,\n",
              "   0.06015406415656117,\n",
              "   0.060109714178159496,\n",
              "   0.05998243630465687,\n",
              "   0.06003653438068306,\n",
              "   0.05964549660492952,\n",
              "   0.05902767137041686,\n",
              "   0.059279333069377,\n",
              "   0.0595752207661036,\n",
              "   0.05925493549968322,\n",
              "   0.05944375411260563,\n",
              "   0.05911362086309291,\n",
              "   0.05956190444031668,\n",
              "   0.059517673535319914,\n",
              "   0.05942929515593313]},\n",
              " 'val': {'loss': [0.13964994375904402,\n",
              "   0.13802048936486244,\n",
              "   0.14760005474090576,\n",
              "   0.12878504395484924,\n",
              "   0.12585787350932756,\n",
              "   0.12543008973201117,\n",
              "   0.12067131201426189,\n",
              "   0.12359992663065593,\n",
              "   0.12183974559108417,\n",
              "   0.11633394782741864,\n",
              "   0.11531720558802287,\n",
              "   0.1151667187611262,\n",
              "   0.11436327422658603,\n",
              "   0.11424497639139493,\n",
              "   0.11492591227094333,\n",
              "   0.11400859306255977,\n",
              "   0.11404738078514735,\n",
              "   0.11312822873393695,\n",
              "   0.11349952593445778,\n",
              "   0.11370155836145084,\n",
              "   0.11373320842782657,\n",
              "   0.11386071642239888,\n",
              "   0.11402653157711029,\n",
              "   0.11424505213896434,\n",
              "   0.11431806161999702]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "7f4bb0f2-34d3-415f-c9f4-4525e83c3366"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "b45729ce-a79e-4673-9bae-1d1b1595e317"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "b955295c-8bd7-4c3b-fa61-5baf87ece6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_18/unetv8.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_18/unetv8.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "de1dc520-c38a-4118-c701-89eb8a013f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [04:23<00:00, 11.47s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1421\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv8')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}