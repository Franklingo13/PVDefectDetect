{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "aaa2c853-c253-4680-9192-9de5b19570e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CffxGlC2G09S",
        "outputId": "ff9b5437-867b-48ab-a7ec-81bd873f255c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.1.0)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ],
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "dc1596dc-3be2-4aaa-b4af-75314f39341f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1012 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/images\",\n",
        "        mask_folder=\"train/annotations\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "2e1f1e30-21b1-4cf4-988d-9e95a2d172fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "6e520c89-b98d-48ef-e72a-73977983eb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=8,\n",
        "    batch_size_val=8,\n",
        "\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=10,\n",
        "\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unet.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "75ebd144-2f5e-448b-96ac-286abb10690a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1012 (0%)]\tLoss: 1.699033\n",
            "  8%|▊         | 10/127 [02:13<25:17, 12.97s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [80/1012 (8%)]\tLoss: 0.294187\n",
            " 16%|█▌        | 20/127 [04:28<23:10, 13.00s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1012 (16%)]\tLoss: 0.191381\n",
            " 24%|██▎       | 30/127 [06:46<22:46, 14.09s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [240/1012 (24%)]\tLoss: 0.201321\n",
            " 31%|███▏      | 40/127 [09:06<20:40, 14.26s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1012 (31%)]\tLoss: 0.151854\n",
            " 39%|███▉      | 50/127 [11:29<18:41, 14.57s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [400/1012 (39%)]\tLoss: 0.087588\n",
            " 47%|████▋     | 60/127 [13:54<15:25, 13.81s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1012 (47%)]\tLoss: 0.133334\n",
            " 55%|█████▌    | 70/127 [16:14<13:54, 14.65s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [560/1012 (55%)]\tLoss: 0.093750\n",
            " 63%|██████▎   | 80/127 [18:36<10:51, 13.86s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1012 (63%)]\tLoss: 0.039686\n",
            " 71%|███████   | 90/127 [20:55<08:48, 14.27s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [720/1012 (71%)]\tLoss: 0.102554\n",
            " 79%|███████▊  | 100/127 [23:15<06:22, 14.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1012 (79%)]\tLoss: 0.145144\n",
            " 87%|████████▋ | 110/127 [25:27<03:29, 12.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [880/1012 (87%)]\tLoss: 0.048814\n",
            " 94%|█████████▍| 120/127 [27:46<01:36, 13.83s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1012 (94%)]\tLoss: 0.073437\n",
            "100%|██████████| 127/127 [29:16<00:00, 13.83s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 20/20 [04:44<00:00, 14.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.6284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1745 (train) | 0.6284 (val)\n",
            "Epoch 2 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1012 (0%)]\tLoss: 0.083405\n",
            "  8%|▊         | 10/127 [00:06<01:13,  1.60it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [80/1012 (8%)]\tLoss: 0.071144\n",
            " 16%|█▌        | 20/127 [00:12<01:08,  1.56it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1012 (16%)]\tLoss: 0.209116\n",
            " 24%|██▎       | 30/127 [00:19<01:02,  1.56it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [240/1012 (24%)]\tLoss: 0.062182\n",
            " 31%|███▏      | 40/127 [00:25<00:55,  1.57it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1012 (31%)]\tLoss: 0.058936\n",
            " 39%|███▉      | 50/127 [00:31<00:48,  1.59it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [400/1012 (39%)]\tLoss: 0.042388\n",
            " 47%|████▋     | 60/127 [00:38<00:41,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1012 (47%)]\tLoss: 0.097273\n",
            " 55%|█████▌    | 70/127 [00:44<00:35,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [560/1012 (55%)]\tLoss: 0.079349\n",
            " 63%|██████▎   | 80/127 [00:50<00:28,  1.64it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1012 (63%)]\tLoss: 0.083646\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.64it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [720/1012 (71%)]\tLoss: 0.087941\n",
            " 79%|███████▊  | 100/127 [01:03<00:16,  1.65it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1012 (79%)]\tLoss: 0.055426\n",
            " 87%|████████▋ | 110/127 [01:09<00:10,  1.64it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [880/1012 (87%)]\tLoss: 0.070164\n",
            " 94%|█████████▍| 120/127 [01:15<00:04,  1.65it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1012 (94%)]\tLoss: 0.060220\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.59it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.77it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.7166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0826 (train) | 0.7166 (val)\n",
            "Epoch 3 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1012 (0%)]\tLoss: 0.079343\n",
            "  8%|▊         | 10/127 [00:05<01:11,  1.64it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [80/1012 (8%)]\tLoss: 0.085495\n",
            " 16%|█▌        | 20/127 [00:12<01:05,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1012 (16%)]\tLoss: 0.103735\n",
            " 24%|██▎       | 30/127 [00:18<00:59,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [240/1012 (24%)]\tLoss: 0.058364\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1012 (31%)]\tLoss: 0.045534\n",
            " 39%|███▉      | 50/127 [00:30<00:47,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [400/1012 (39%)]\tLoss: 0.055345\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1012 (47%)]\tLoss: 0.065517\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.60it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [560/1012 (55%)]\tLoss: 0.067498\n",
            " 63%|██████▎   | 80/127 [00:49<00:29,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1012 (63%)]\tLoss: 0.083715\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [720/1012 (71%)]\tLoss: 0.063356\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1012 (79%)]\tLoss: 0.095292\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [880/1012 (87%)]\tLoss: 0.074217\n",
            " 94%|█████████▍| 120/127 [01:14<00:04,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1012 (94%)]\tLoss: 0.054743\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 7.4440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0729 (train) | 7.4440 (val)\n",
            "Epoch 4 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1012 (0%)]\tLoss: 0.054525\n",
            "  8%|▊         | 10/127 [00:05<01:11,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [80/1012 (8%)]\tLoss: 0.087541\n",
            " 16%|█▌        | 20/127 [00:12<01:05,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1012 (16%)]\tLoss: 0.076913\n",
            " 24%|██▎       | 30/127 [00:18<00:59,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [240/1012 (24%)]\tLoss: 0.082265\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1012 (31%)]\tLoss: 0.049336\n",
            " 39%|███▉      | 50/127 [00:30<00:47,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [400/1012 (39%)]\tLoss: 0.069293\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1012 (47%)]\tLoss: 0.080217\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [560/1012 (55%)]\tLoss: 0.064636\n",
            " 63%|██████▎   | 80/127 [00:49<00:28,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1012 (63%)]\tLoss: 0.080465\n",
            " 71%|███████   | 90/127 [00:55<00:22,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [720/1012 (71%)]\tLoss: 0.093517\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1012 (79%)]\tLoss: 0.033334\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [880/1012 (87%)]\tLoss: 0.066290\n",
            " 94%|█████████▍| 120/127 [01:14<00:04,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1012 (94%)]\tLoss: 0.105210\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 1.4418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0715 (train) | 1.4418 (val)\n",
            "Epoch 5 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1012 (0%)]\tLoss: 0.061282\n",
            "  8%|▊         | 10/127 [00:05<01:11,  1.64it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [80/1012 (8%)]\tLoss: 0.105020\n",
            " 16%|█▌        | 20/127 [00:12<01:05,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1012 (16%)]\tLoss: 0.056139\n",
            " 24%|██▎       | 30/127 [00:18<00:59,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [240/1012 (24%)]\tLoss: 0.092887\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1012 (31%)]\tLoss: 0.108032\n",
            " 39%|███▉      | 50/127 [00:30<00:47,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [400/1012 (39%)]\tLoss: 0.056348\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1012 (47%)]\tLoss: 0.084414\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [560/1012 (55%)]\tLoss: 0.035175\n",
            " 63%|██████▎   | 80/127 [00:49<00:28,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1012 (63%)]\tLoss: 0.091230\n",
            " 71%|███████   | 90/127 [00:55<00:22,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [720/1012 (71%)]\tLoss: 0.045293\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1012 (79%)]\tLoss: 0.054805\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [880/1012 (87%)]\tLoss: 0.051396\n",
            " 94%|█████████▍| 120/127 [01:14<00:04,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1012 (94%)]\tLoss: 0.073904\n",
            "100%|██████████| 127/127 [01:18<00:00,  1.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.5967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0655 (train) | 0.5967 (val)\n",
            "Epoch 6 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1012 (0%)]\tLoss: 0.123633\n",
            "  8%|▊         | 10/127 [00:05<01:11,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [80/1012 (8%)]\tLoss: 0.056744\n",
            " 16%|█▌        | 20/127 [00:12<01:05,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1012 (16%)]\tLoss: 0.071639\n",
            " 24%|██▎       | 30/127 [00:18<00:59,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [240/1012 (24%)]\tLoss: 0.049632\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1012 (31%)]\tLoss: 0.073331\n",
            " 39%|███▉      | 50/127 [00:31<00:47,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [400/1012 (39%)]\tLoss: 0.045624\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1012 (47%)]\tLoss: 0.037444\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [560/1012 (55%)]\tLoss: 0.048072\n",
            " 63%|██████▎   | 80/127 [00:49<00:28,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1012 (63%)]\tLoss: 0.042321\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [720/1012 (71%)]\tLoss: 0.027662\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1012 (79%)]\tLoss: 0.028331\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [880/1012 (87%)]\tLoss: 0.033604\n",
            " 94%|█████████▍| 120/127 [01:14<00:04,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1012 (94%)]\tLoss: 0.027325\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.61it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.67it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.6814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0577 (train) | 0.6814 (val)\n",
            "Epoch 7 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1012 (0%)]\tLoss: 0.127746\n",
            "  8%|▊         | 10/127 [00:05<01:11,  1.63it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [80/1012 (8%)]\tLoss: 0.037206\n",
            " 16%|█▌        | 20/127 [00:12<01:05,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1012 (16%)]\tLoss: 0.069449\n",
            " 24%|██▎       | 30/127 [00:18<01:00,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [240/1012 (24%)]\tLoss: 0.034175\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1012 (31%)]\tLoss: 0.049913\n",
            " 39%|███▉      | 50/127 [00:31<00:47,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [400/1012 (39%)]\tLoss: 0.050997\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1012 (47%)]\tLoss: 0.049338\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [560/1012 (55%)]\tLoss: 0.033856\n",
            " 63%|██████▎   | 80/127 [00:49<00:29,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1012 (63%)]\tLoss: 0.058440\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [720/1012 (71%)]\tLoss: 0.054539\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1012 (79%)]\tLoss: 0.068890\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [880/1012 (87%)]\tLoss: 0.066769\n",
            " 94%|█████████▍| 120/127 [01:15<00:04,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1012 (94%)]\tLoss: 0.069275\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.78it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.6553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0506 (train) | 0.6553 (val)\n",
            "Epoch 8 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1012 (0%)]\tLoss: 0.031181\n",
            "  8%|▊         | 10/127 [00:05<01:12,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [80/1012 (8%)]\tLoss: 0.025799\n",
            " 16%|█▌        | 20/127 [00:12<01:06,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1012 (16%)]\tLoss: 0.062027\n",
            " 24%|██▎       | 30/127 [00:18<01:00,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [240/1012 (24%)]\tLoss: 0.047841\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1012 (31%)]\tLoss: 0.036034\n",
            " 39%|███▉      | 50/127 [00:31<00:47,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [400/1012 (39%)]\tLoss: 0.037646\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1012 (47%)]\tLoss: 0.060898\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [560/1012 (55%)]\tLoss: 0.029880\n",
            " 63%|██████▎   | 80/127 [00:49<00:29,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1012 (63%)]\tLoss: 0.036245\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [720/1012 (71%)]\tLoss: 0.042690\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1012 (79%)]\tLoss: 0.031846\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [880/1012 (87%)]\tLoss: 0.031790\n",
            " 94%|█████████▍| 120/127 [01:15<00:04,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1012 (94%)]\tLoss: 0.046508\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.75it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.6295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0476 (train) | 0.6295 (val)\n",
            "Epoch 9 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1012 (0%)]\tLoss: 0.060656\n",
            "  8%|▊         | 10/127 [00:06<01:12,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [80/1012 (8%)]\tLoss: 0.025601\n",
            " 16%|█▌        | 20/127 [00:12<01:06,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1012 (16%)]\tLoss: 0.047269\n",
            " 24%|██▎       | 30/127 [00:18<01:00,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [240/1012 (24%)]\tLoss: 0.043657\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1012 (31%)]\tLoss: 0.039479\n",
            " 39%|███▉      | 50/127 [00:31<00:47,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [400/1012 (39%)]\tLoss: 0.081044\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1012 (47%)]\tLoss: 0.063665\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [560/1012 (55%)]\tLoss: 0.042416\n",
            " 63%|██████▎   | 80/127 [00:49<00:29,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1012 (63%)]\tLoss: 0.037648\n",
            " 71%|███████   | 90/127 [00:56<00:23,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [720/1012 (71%)]\tLoss: 0.043910\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1012 (79%)]\tLoss: 0.048305\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [880/1012 (87%)]\tLoss: 0.022446\n",
            " 94%|█████████▍| 120/127 [01:15<00:04,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1012 (94%)]\tLoss: 0.042883\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.74it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.6274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.6274 (val)\n",
            "Epoch 10 / 10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/127 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1012 (0%)]\tLoss: 0.039276\n",
            "  8%|▊         | 10/127 [00:05<01:12,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [80/1012 (8%)]\tLoss: 0.023317\n",
            " 16%|█▌        | 20/127 [00:12<01:06,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1012 (16%)]\tLoss: 0.033021\n",
            " 24%|██▎       | 30/127 [00:18<01:00,  1.62it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [240/1012 (24%)]\tLoss: 0.052735\n",
            " 31%|███▏      | 40/127 [00:24<00:53,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1012 (31%)]\tLoss: 0.025197\n",
            " 39%|███▉      | 50/127 [00:31<00:47,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [400/1012 (39%)]\tLoss: 0.033690\n",
            " 47%|████▋     | 60/127 [00:37<00:41,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1012 (47%)]\tLoss: 0.026346\n",
            " 55%|█████▌    | 70/127 [00:43<00:35,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [560/1012 (55%)]\tLoss: 0.038079\n",
            " 63%|██████▎   | 80/127 [00:49<00:29,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1012 (63%)]\tLoss: 0.034126\n",
            " 71%|███████   | 90/127 [00:56<00:22,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [720/1012 (71%)]\tLoss: 0.042912\n",
            " 79%|███████▊  | 100/127 [01:02<00:16,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1012 (79%)]\tLoss: 0.040622\n",
            " 87%|████████▋ | 110/127 [01:08<00:10,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [880/1012 (87%)]\tLoss: 0.028100\n",
            " 94%|█████████▍| 120/127 [01:15<00:04,  1.61it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1012 (94%)]\tLoss: 0.058285\n",
            "100%|██████████| 127/127 [01:19<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.6839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.6839 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.17446107473298023,\n",
              "   0.0826398823925629,\n",
              "   0.07289011131515616,\n",
              "   0.07146774048331699,\n",
              "   0.06550930022250993,\n",
              "   0.05768502268042018,\n",
              "   0.05063847609953918,\n",
              "   0.047592697495763954,\n",
              "   0.04583575067077229,\n",
              "   0.04331125860864466]},\n",
              " 'val': {'loss': [0.6283981361696797,\n",
              "   0.716611695674158,\n",
              "   7.443969142821527,\n",
              "   1.4417573798087335,\n",
              "   0.5967450238043263,\n",
              "   0.6813793063163758,\n",
              "   0.6553435298704332,\n",
              "   0.6294804146212917,\n",
              "   0.6273663416985542,\n",
              "   0.683851557777774]}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "e16d0f49-d239-479d-f697-ce6fe9af4c8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "7fbf65df-ddf7-4c76-8f6e-a33ad6264dbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "99819dc0-64b5-4a8e-fedd-5546cb3b60f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unet.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/unet.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "2c76a5b8-7581-47de-e67c-f6c04f156675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41/41 [09:48<00:00, 14.36s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.8451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.8451\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}