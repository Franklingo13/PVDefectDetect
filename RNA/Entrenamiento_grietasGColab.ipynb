{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "b7bb82ae-6ae7-4dec-81ee-e6b1c707e7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "1c04c1c9-bef4-4c05-b816-f064bc14c9dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1.post1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.5)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.6.20)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de una clase personalizada para la rotación de imagen y máscara\n",
        "class RandomRotation:\n",
        "    def __init__(self, degrees):\n",
        "        self.degrees = degrees\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Rotar la imagen\n",
        "        angle = transforms.RandomRotation.get_params([-self.degrees, self.degrees])\n",
        "        image = F.rotate(image, angle, interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        # Rotar la máscara\n",
        "        target = F.rotate(target, angle, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n"
      ],
      "metadata": {
        "id": "iggYqFz__qYf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "82c37723-97bf-4d9e-adeb-e35734746ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([\n",
        "    RandomRotation(degrees=90),\n",
        "    FixResize(256),\n",
        "    ToTensor(),\n",
        "    Normalize()\n",
        "])\n",
        "#transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zB7a3yuP4Dps"
      },
      "outputs": [],
      "source": [
        "## Definición de una clase para calcular el Índice de Jaccard, o Intersección sobre Unión (IoU)\n",
        "class JaccardIndex:\n",
        "    def __init__(self):\n",
        "        # Se define el nombre de la métrica para referencia\n",
        "        self.__name__ = 'jaccard_index'\n",
        "\n",
        "    def __call__(self, preds, targets):\n",
        "        \"\"\"\n",
        "        Calcula el Índice de Jaccard (IoU) entre las predicciones y los objetivos.\n",
        "\n",
        "        Parámetros:\n",
        "        preds: tensor de PyTorch con las predicciones del modelo.\n",
        "        targets: tensor de PyTorch con los valores verdaderos (ground truth).\n",
        "\n",
        "        Retorna:\n",
        "        iou: El valor del Índice de Jaccard.\n",
        "        \"\"\"\n",
        "\n",
        "        # Asegurarse de que las predicciones sean binarias (0 o 1)\n",
        "        preds = (preds > 0.5).float()\n",
        "\n",
        "        # Calcular la intersección y la unión\n",
        "        intersection = torch.sum(preds * targets)\n",
        "        union = torch.sum(preds + targets) - intersection\n",
        "\n",
        "        # Calcular IoU evitando la división por cero\n",
        "        iou = intersection / (union + 1e-8)\n",
        "\n",
        "        return iou.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "b442ef9e-5e03-4498-f9a9-383d7d5d497c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0005)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=7, gamma=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "caf20b7b-0163-45de-a125-ce9589b9ebc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv25.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "7f197df1-4666-4a8b-d642-1262800f0136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= JaccardIndex,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv27.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X1SfRwQCG09V",
        "outputId": "24576e47-2813-4f2c-b55b-a3a1cee37f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.363482\n",
            " 22%|██▏       | 10/46 [04:22<14:56, 24.90s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.087876\n",
            " 43%|████▎     | 20/46 [08:35<10:47, 24.89s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.076247\n",
            " 65%|██████▌   | 30/46 [12:44<06:41, 25.10s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.070180\n",
            " 87%|████████▋ | 40/46 [16:54<02:28, 24.77s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.075810\n",
            "100%|██████████| 46/46 [19:09<00:00, 24.99s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [02:20<00:00, 46.75s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1082 (train) | 0.1344 (val)\n",
            "Epoch 2 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.069966\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.059984\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.094797\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.062078\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.070689\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0688 (train) | 0.1230 (val)\n",
            "Epoch 3 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.065404\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.061189\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.068016\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.059729\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.061742\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0641 (train) | 0.1132 (val)\n",
            "Epoch 4 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.057666\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.055542\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.084358\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.075356\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.053847\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0618 (train) | 0.1116 (val)\n",
            "Epoch 5 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.074782\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.074501\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.050055\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.065399\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.067947\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0598 (train) | 0.1093 (val)\n",
            "Epoch 6 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.076641\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.052169\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.051427\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.054349\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.052485\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0590 (train) | 0.1085 (val)\n",
            "Epoch 7 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.060009\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.069743\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.044120\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.064993\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.054141\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0579 (train) | 0.1056 (val)\n",
            "Epoch 8 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.060210\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.053541\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.068611\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.049670\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.050376\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0569 (train) | 0.1049 (val)\n",
            "Epoch 9 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.070741\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.052428\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.059046\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.059779\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.052340\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0562 (train) | 0.1019 (val)\n",
            "Epoch 10 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.051545\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.050779\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.056941\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.052266\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.058541\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0563 (train) | 0.1032 (val)\n",
            "Epoch 11 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.041876\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.042014\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.048546\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.059098\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.060021\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0561 (train) | 0.1036 (val)\n",
            "Epoch 12 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.062237\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.075902\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.052701\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.044607\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.047994\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0556 (train) | 0.1039 (val)\n",
            "Epoch 13 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.052757\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.049105\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.052911\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.043473\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.059322\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0554 (train) | 0.1025 (val)\n",
            "Epoch 14 / 14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.053641\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.057562\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.058905\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.058252\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.067849\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0555 (train) | 0.1003 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.10822570327533497,\n",
              "   0.06876620918471323,\n",
              "   0.06409238981620165,\n",
              "   0.06175097592908271,\n",
              "   0.05981260258127555,\n",
              "   0.05898972519680458,\n",
              "   0.057947282460809824,\n",
              "   0.05692419238485965,\n",
              "   0.056187466930415986,\n",
              "   0.05629718115236623,\n",
              "   0.056063580640168004,\n",
              "   0.05563605564959855,\n",
              "   0.05536739046429653,\n",
              "   0.05550131948340456]},\n",
              " 'val': {'loss': [0.13441630701224008,\n",
              "   0.12302894641955693,\n",
              "   0.11323947211106618,\n",
              "   0.11162944386402766,\n",
              "   0.10925211012363434,\n",
              "   0.10848825921614964,\n",
              "   0.10558742036422093,\n",
              "   0.10493667672077815,\n",
              "   0.10193049410978954,\n",
              "   0.10322875777880351,\n",
              "   0.10364521543184917,\n",
              "   0.10385494430859883,\n",
              "   0.10247811178366344,\n",
              "   0.10033628344535828]}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "672a17de-aab0-48bb-d8f0-fd70caf4a981"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "143b01df-ce07-4863-a651-cb1b1cf2ebd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kH5xVXQyG09W",
        "outputId": "f0f65840-6f95-45b0-af0a-76025821bca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_14/unetv26.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_14/unetv26.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "fb1f8ba4-c26a-4b1e-83ae-7e6e2a3b8043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [09:39<00:00, 48.30s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1879\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv26')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}