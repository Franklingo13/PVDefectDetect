{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "b10ae4fe-4851-44a4-e72c-aea442848dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "c6558224-4500-40ea-d688-7619fb4f5a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "90ac5a40-2afa-47aa-97c0-59a573e8adad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "#transformers = Compose([transforms.RandomRotation(degrees=30), FixResize(256), ToTensor(), Normalize()])\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "f95f7275-6316-46fd-aaff-d7ff445c5912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=6, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "e238f0fa-3754-42f5-9475-c334a5600d5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv23.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "33f38cda-9fef-4424-828e-9e17be0b8c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv24.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "b83c206c-a415-479f-cdf2-9aae6c28f2eb",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.044901\n",
            " 22%|██▏       | 10/46 [00:22<00:46,  1.29s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.049334\n",
            " 43%|████▎     | 20/46 [00:34<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.052017\n",
            " 65%|██████▌   | 30/46 [00:46<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.049704\n",
            " 87%|████████▋ | 40/46 [00:58<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.047674\n",
            "100%|██████████| 46/46 [01:05<00:00,  1.42s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0844 (val)\n",
            "Epoch 2 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.042455\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.033797\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.055143\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.061133\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.038041\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0849 (val)\n",
            "Epoch 3 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.044872\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.033621\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.042960\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.041643\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.052625\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0871 (val)\n",
            "Epoch 4 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.039215\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.049301\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.040200\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.034473\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.040663\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0845 (val)\n",
            "Epoch 5 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.051231\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.044706\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.056808\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.033015\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.050716\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0818 (val)\n",
            "Epoch 6 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.043190\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.045212\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.040522\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.047175\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.053057\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0839 (val)\n",
            "Epoch 7 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.074238\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.041234\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.038054\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.039206\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.041250\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0415 (train) | 0.0794 (val)\n",
            "Epoch 8 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.042148\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.044086\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.030860\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.040178\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.042049\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0405 (train) | 0.0782 (val)\n",
            "Epoch 9 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.035061\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.033414\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.052312\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.040774\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.034971\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0402 (train) | 0.0772 (val)\n",
            "Epoch 10 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.046846\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.038729\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.048681\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.043885\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.042389\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0400 (train) | 0.0771 (val)\n",
            "Epoch 11 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.040902\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.039617\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.029544\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.040973\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.042772\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0398 (train) | 0.0767 (val)\n",
            "Epoch 12 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.048450\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.035337\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.041724\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.039879\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.034288\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0395 (train) | 0.0762 (val)\n",
            "Epoch 13 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.037836\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.034966\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.041104\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.035575\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.032261\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0394 (train) | 0.0761 (val)\n",
            "Epoch 14 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.037326\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.042897\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.041840\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.040006\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.038814\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0761 (val)\n",
            "Epoch 15 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.041213\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.040327\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.030014\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.039647\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.045731\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0760 (val)\n",
            "Epoch 16 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.040685\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.050078\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.047973\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.033722\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.039686\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0760 (val)\n",
            "Epoch 17 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.031166\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.035451\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.031693\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.037309\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.035654\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0758 (val)\n",
            "Epoch 18 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.031671\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.048242\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.051233\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.037193\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.030412\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0759 (val)\n",
            "Epoch 19 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.031365\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.045112\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.036773\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.044401\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.033487\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 20 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.033796\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.036906\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.038363\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.041738\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.047483\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0759 (val)\n",
            "Epoch 21 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.032431\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.046136\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.049811\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.029487\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.044070\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0390 (train) | 0.0759 (val)\n",
            "Epoch 22 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.040476\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.042222\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.038920\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.028340\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.045073\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0760 (val)\n",
            "Epoch 23 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.041369\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.045722\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.031457\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.050774\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.046833\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0759 (val)\n",
            "Epoch 24 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.041322\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.044436\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.042866\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.051348\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.035320\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0757 (val)\n",
            "Epoch 25 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.038346\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.047763\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.028801\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.049738\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.043388\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0760 (val)\n",
            "Epoch 26 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.047980\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.044061\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.028138\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.041694\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.055288\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0758 (val)\n",
            "Epoch 27 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.038584\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.040970\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.030552\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.041928\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.036707\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0760 (val)\n",
            "Epoch 28 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.039144\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.046142\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.039056\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.037139\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.054955\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 29 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.033681\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.042880\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.045604\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.040224\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.031462\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0758 (val)\n",
            "Epoch 30 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.038167\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.042884\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.049410\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.041698\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.046712\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 31 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.045124\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.037202\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.038305\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.036538\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.035493\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 32 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.055346\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.038203\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.034867\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.041869\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.041686\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0761 (val)\n",
            "Epoch 33 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.032039\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.034553\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.037840\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.063956\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.040120\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0758 (val)\n",
            "Epoch 34 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.032416\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.038500\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.033306\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.031482\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.030250\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0759 (val)\n",
            "Epoch 35 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.042911\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.039671\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.036277\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.045159\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.036010\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0394 (train) | 0.0758 (val)\n",
            "Epoch 36 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.032229\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.032915\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.038421\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.033456\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.039894\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 37 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.041967\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.039211\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.032699\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.027800\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.031705\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0760 (val)\n",
            "Epoch 38 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.033717\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.035554\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.038824\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.029407\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.039518\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 39 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.033192\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.031915\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.047659\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.047786\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.031211\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0392 (train) | 0.0759 (val)\n",
            "Epoch 40 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.036102\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.042820\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.034945\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.049152\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.033283\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0390 (train) | 0.0759 (val)\n",
            "Epoch 41 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [0/1453 (0%)]\tLoss: 0.033474\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [320/1453 (22%)]\tLoss: 0.033166\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [640/1453 (43%)]\tLoss: 0.040731\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [960/1453 (65%)]\tLoss: 0.038777\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [1280/1453 (87%)]\tLoss: 0.037408\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 41\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 41 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0393 (train) | 0.0759 (val)\n",
            "Epoch 42 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [0/1453 (0%)]\tLoss: 0.046087\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [320/1453 (22%)]\tLoss: 0.043929\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [640/1453 (43%)]\tLoss: 0.043191\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [960/1453 (65%)]\tLoss: 0.030455\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [1280/1453 (87%)]\tLoss: 0.033493\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 42\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 42 \tAverage loss: 0.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0391 (train) | 0.0759 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.047002154974816836,\n",
              "   0.04355047024396765,\n",
              "   0.04447632717546806,\n",
              "   0.04452076832477339,\n",
              "   0.04359605698157243,\n",
              "   0.044189472866731104,\n",
              "   0.041498731729476435,\n",
              "   0.04049885686017773,\n",
              "   0.04021227542318645,\n",
              "   0.039951341418986555,\n",
              "   0.039751470096650324,\n",
              "   0.039533085618565514,\n",
              "   0.03937180741277958,\n",
              "   0.039314655139683366,\n",
              "   0.03915975316051402,\n",
              "   0.03926651375669491,\n",
              "   0.039287783969539816,\n",
              "   0.03908596318586892,\n",
              "   0.039187774592875944,\n",
              "   0.039269925061169775,\n",
              "   0.03901912894481966,\n",
              "   0.03907321269398956,\n",
              "   0.0391098393943912,\n",
              "   0.039163778903294824,\n",
              "   0.03918905556201935,\n",
              "   0.039299063938326946,\n",
              "   0.03910806617415616,\n",
              "   0.03917979461468464,\n",
              "   0.03930039893058933,\n",
              "   0.03919848631644405,\n",
              "   0.03916032111858058,\n",
              "   0.03915324658206718,\n",
              "   0.03914754245243069,\n",
              "   0.03908052549012267,\n",
              "   0.03936883029563215,\n",
              "   0.03916977289794891,\n",
              "   0.03912758595051843,\n",
              "   0.03917699406681107,\n",
              "   0.03918755309578065,\n",
              "   0.03901796431985093,\n",
              "   0.039279543727390204,\n",
              "   0.03906165372326468]},\n",
              " 'val': {'loss': [0.08438987533251445,\n",
              "   0.08488463113705318,\n",
              "   0.087148350973924,\n",
              "   0.0845402975877126,\n",
              "   0.08183114727338155,\n",
              "   0.08390313138564427,\n",
              "   0.07940489550431569,\n",
              "   0.0782254288593928,\n",
              "   0.07721953342358272,\n",
              "   0.07710944612820943,\n",
              "   0.07671860108772914,\n",
              "   0.07623756925264995,\n",
              "   0.07605353991190593,\n",
              "   0.07607043286164601,\n",
              "   0.07603754599889119,\n",
              "   0.07598547885815303,\n",
              "   0.07584684590498607,\n",
              "   0.07590121527512868,\n",
              "   0.07585765918095906,\n",
              "   0.07587766647338867,\n",
              "   0.07586264858643214,\n",
              "   0.07596107323964436,\n",
              "   0.07586924235026042,\n",
              "   0.07574968288342158,\n",
              "   0.07599887748559316,\n",
              "   0.07583542664845784,\n",
              "   0.07595940430959065,\n",
              "   0.07588527848323186,\n",
              "   0.07582876086235046,\n",
              "   0.07592056194941203,\n",
              "   0.07594078034162521,\n",
              "   0.07606134563684464,\n",
              "   0.07584718366463979,\n",
              "   0.075858640174071,\n",
              "   0.0758303627371788,\n",
              "   0.07592891156673431,\n",
              "   0.07599230110645294,\n",
              "   0.07589609424273173,\n",
              "   0.07586590697367986,\n",
              "   0.07586373140414555,\n",
              "   0.07591406255960464,\n",
              "   0.07585966090361278]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "7f6c324d-f2ef-4a5f-8f4a-54b37202557a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "c0a38d4c-b65e-4c85-cf22-91ab9130efa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "d280cccd-bb0d-4a64-912c-20e6cfe4bfa6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_24/unetv24.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_24/unetv24.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "e2f9a76d-a4e1-4886-9051-e04e78202884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:07<00:00,  1.56it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1099\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv24')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}