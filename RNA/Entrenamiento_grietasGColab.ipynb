{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas. \n",
    "Pensado para correr en Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión con Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de la librería de pv-vision\n",
    "!pip install pv-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el manejador de modelo: ModelHandler\n",
    "from pv_vision.nn import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de una clase para el conjunto de datos solar, \n",
    "# que hereda de la clase VisionDataset de PyTorch.\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
    "\n",
    "    # Se definió el método de inicialización para la clase.\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 image_folder,\n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        # Se llamó al método de inicialización de la clase padre.\n",
    "        super().__init__(root, transforms)\n",
    "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
    "\n",
    "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
    "        np.random.seed(random_seed)\n",
    "        index = np.arange(len(self.image_list))\n",
    "        np.random.shuffle(index)\n",
    "        self.image_list = self.image_list[index]\n",
    "        self.mask_list = self.mask_list[index]\n",
    "\n",
    "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
    "    def __getraw__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.__getraw__(index)\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de una clase para componer varias transformaciones.\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: una lista de transformaciones\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: imagen de entrada\n",
    "        target: máscara de entrada\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
    "class FixResize:\n",
    "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    # Se definió el método para redimensionar la imagen y la máscara.\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
    "class ToTensor:\n",
    "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
    "    Transforma la máscara a tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
    "class PILToTensor:\n",
    "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "# Se definió una clase para normalizar la imagen.\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    # Se definió el método para normalizar la imagen.\n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
    "root = Path(\n",
    "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/examples/crack_segmentation/img_label_for_training')\n",
    "\n",
    "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "\n",
    "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
    "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
    "        mask_folder=\"train/ann\", transforms=transformers)\n",
    "\n",
    "valset = SolarDataset(root, image_folder=\"val/img\",\n",
    "        mask_folder=\"val/ann\", transforms=transformers)\n",
    "\n",
    "testset = SolarDataset(root, image_folder=\"testset/img\",\n",
    "        mask_folder=\"testset/ann\", transforms=transformers)\n",
    "\n",
    "# Verificación de que la carpeta haya sido establecida correctamente\n",
    "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una función para crear un modelo DeepLab preentrenado.\n",
    "def DeepLab_pretrained(num_classes):\n",
    "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
    "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
    "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
    "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
    "\n",
    "    # Se devuelve el modelo modificado.\n",
    "    return deeplab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el dispositivo en el que se ejecutará el modelo. \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se imprime el dispositivo utilizado.\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
    "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
    "model = DataParallel(DeepLab_pretrained(5))\n",
    "\n",
    "# Se define la función de pérdida a utilizar durante el entrenamiento. \n",
    "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
    "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
    "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el manejador del modelo.\n",
    "# La salida se almacena en la carpeta de salida.\n",
    "modelhandler = ModelHandler(\n",
    "    # Se pasa el modelo que se va a entrenar.\n",
    "    model=model,\n",
    "\n",
    "    # Se especifica el nombre de la carpeta de salida.\n",
    "    model_output='out',\n",
    "\n",
    "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
    "    train_dataset=trainset,\n",
    "    val_dataset=valset,\n",
    "    test_dataset=testset,\n",
    "\n",
    "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
    "    batch_size_train=32,\n",
    "    batch_size_val=32,\n",
    "\n",
    "    # Se pasa el programador de la tasa de aprendizaje.\n",
    "    lr_scheduler=lr_scheduler,\n",
    "\n",
    "    # Se especifica el número de épocas para el entrenamiento.\n",
    "    num_epochs=20,\n",
    "\n",
    "    # Se pasa la función de pérdida y el optimizador.\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "\n",
    "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
    "    device=device,\n",
    "\n",
    "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
    "    save_dir='checkpoints',\n",
    "\n",
    "    # Se especifica el nombre del archivo de punto de control.\n",
    "    save_name='deeplab.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el entrenamiento del modelo.\n",
    "modelhandler.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza el proceso de entrenamiento.\n",
    "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
    "modelhandler.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
    "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
    "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
    "np.argmin(modelhandler.running_record['val']['loss'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
    "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
    "modelhandler.load_model('deeplab.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
    "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
    "_ = modelhandler.test_model(cache_output='testset_output')\n",
    "\n",
    "# La salida del modelo se almacena en self.cache['testset_output']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
