{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "49ce45ac-5d5d-4448-ddf3-ec734780e991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "083e4322-cbbc-4850-df3e-5332b57d3e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1.post1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.5)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.6.20)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de una clase personalizada para la rotación de imagen y máscara\n",
        "class RandomRotation:\n",
        "    def __init__(self, degrees):\n",
        "        self.degrees = degrees\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Rotar la imagen\n",
        "        angle = transforms.RandomRotation.get_params([-self.degrees, self.degrees])\n",
        "        image = F.rotate(image, angle, interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        # Rotar la máscara\n",
        "        target = F.rotate(target, angle, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n"
      ],
      "metadata": {
        "id": "iggYqFz__qYf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "ac2cd7dc-865f-4804-afa6-5e88725ee098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([\n",
        "    RandomRotation(degrees=90),\n",
        "    FixResize(256),\n",
        "    ToTensor(),\n",
        "    Normalize()\n",
        "])\n",
        "#transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zB7a3yuP4Dps"
      },
      "outputs": [],
      "source": [
        "## Definición de una clase para calcular el Índice de Jaccard, o Intersección sobre Unión (IoU)\n",
        "class JaccardIndex:\n",
        "    def __init__(self):\n",
        "        # Se define el nombre de la métrica para referencia\n",
        "        self.__name__ = 'jaccard_index'\n",
        "\n",
        "    def __call__(self, preds, targets):\n",
        "        \"\"\"\n",
        "        Calcula el Índice de Jaccard (IoU) entre las predicciones y los objetivos.\n",
        "\n",
        "        Parámetros:\n",
        "        preds: tensor de PyTorch con las predicciones del modelo.\n",
        "        targets: tensor de PyTorch con los valores verdaderos (ground truth).\n",
        "\n",
        "        Retorna:\n",
        "        iou: El valor del Índice de Jaccard.\n",
        "        \"\"\"\n",
        "\n",
        "        # Imprimir las formas de los tensores para diagnóstico\n",
        "        print(f\"Preds shape: {preds.shape}\")\n",
        "        print(f\"Targets shape: {targets.shape}\")\n",
        "\n",
        "        # Asegurarse de que las predicciones sean binarias (0 o 1)\n",
        "        preds = (preds > 0.5).float()\n",
        "\n",
        "        # Verificar si las formas de los tensores son compatibles\n",
        "        if preds.shape != targets.shape:\n",
        "            raise ValueError(f\"Shape mismatch: preds shape {preds.shape} does not match targets shape {targets.shape}\")\n",
        "\n",
        "        # Calcular la intersección y la unión\n",
        "        intersection = torch.sum(preds * targets)\n",
        "        union = torch.sum(preds + targets) - intersection\n",
        "\n",
        "        # Calcular IoU evitando la división por cero\n",
        "        iou = intersection / (union + 1e-8)\n",
        "\n",
        "        return iou.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "9cea1779-fa58-469d-bd42-f7f31472db56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0005)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=7, gamma=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "64d9fe8e-a736-4161-8717-ae58014efc8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv25.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "070b35c2-ff3a-476c-e77d-c958faa980f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= JaccardIndex,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv27.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X1SfRwQCG09V",
        "outputId": "562722d5-99ff-4b76-aa1c-57433fbed458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.678345\n",
            " 22%|██▏       | 10/46 [00:21<00:44,  1.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.254303\n",
            " 43%|████▎     | 20/46 [00:32<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.135296\n",
            " 65%|██████▌   | 30/46 [00:44<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.183773\n",
            " 87%|████████▋ | 40/46 [00:56<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.132094\n",
            "100%|██████████| 46/46 [01:03<00:00,  1.38s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.2158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2167 (train) | 0.2158 (val)\n",
            "Epoch 2 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.122536\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.141452\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.138610\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.099658\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.102043\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1126 (train) | 0.1827 (val)\n",
            "Epoch 3 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.108344\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.097171\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.104772\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.105836\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.084365\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0977 (train) | 0.1686 (val)\n",
            "Epoch 4 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.093877\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.082529\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.091923\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.084910\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.088918\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0913 (train) | 0.1621 (val)\n",
            "Epoch 5 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.073134\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.084200\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.076355\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.084271\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.090721\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0854 (train) | 0.1500 (val)\n",
            "Epoch 6 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.072749\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.075912\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.067101\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.084091\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.092492\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0839 (train) | 0.1437 (val)\n",
            "Epoch 7 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.078456\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.084516\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.098056\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.079158\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.071056\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0800 (train) | 0.1463 (val)\n",
            "Epoch 8 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.082080\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.079707\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.060763\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.085716\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.068406\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0777 (train) | 0.1408 (val)\n",
            "Epoch 9 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.081088\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.071446\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.086400\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.053065\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.121035\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0773 (train) | 0.1394 (val)\n",
            "Epoch 10 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.089993\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.068102\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.069663\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.110363\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.100567\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0775 (train) | 0.1390 (val)\n",
            "Epoch 11 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.075982\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.074572\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.069879\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.073481\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.084711\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0769 (train) | 0.1349 (val)\n",
            "Epoch 12 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.060898\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.071570\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.079550\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.081015\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.070438\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0760 (train) | 0.1402 (val)\n",
            "Epoch 13 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.060925\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.095560\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.083169\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.084438\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.072036\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0768 (train) | 0.1377 (val)\n",
            "Epoch 14 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.066129\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.061843\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.060931\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.070494\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.064164\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0757 (train) | 0.1375 (val)\n",
            "Epoch 15 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.071975\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.077853\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.074489\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.082838\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.061125\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0754 (train) | 0.1381 (val)\n",
            "Epoch 16 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.082514\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.067925\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.071484\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.096250\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.067694\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0760 (train) | 0.1404 (val)\n",
            "Epoch 17 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.083814\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.074412\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.075628\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.071163\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.088962\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0760 (train) | 0.1378 (val)\n",
            "Epoch 18 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.077295\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.053451\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.068259\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.076103\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.098336\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0763 (train) | 0.1385 (val)\n",
            "Epoch 19 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.083476\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.059799\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.067691\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.075713\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.055668\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0759 (train) | 0.1376 (val)\n",
            "Epoch 20 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.091050\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.066462\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.060556\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.059951\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.079209\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0762 (train) | 0.1370 (val)\n",
            "Epoch 21 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.051473\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.106958\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.058312\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.069786\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.051455\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0757 (train) | 0.1360 (val)\n",
            "Epoch 22 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.064048\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.079245\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.064871\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.059269\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.067381\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0753 (train) | 0.1365 (val)\n",
            "Epoch 23 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.074247\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.077786\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.072139\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.076337\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.078946\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0756 (train) | 0.1367 (val)\n",
            "Epoch 24 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.069007\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.059510\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.062222\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.069259\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.064014\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0762 (train) | 0.1392 (val)\n",
            "Epoch 25 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.077900\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.071916\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.060375\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.065968\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.061723\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0761 (train) | 0.1375 (val)\n",
            "Epoch 26 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.056650\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.074788\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.092033\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.072120\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.093505\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.1415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0751 (train) | 0.1415 (val)\n",
            "Epoch 27 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.087659\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.080377\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.079089\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.077972\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.070549\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0758 (train) | 0.1348 (val)\n",
            "Epoch 28 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.057361\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.084686\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.078927\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.063409\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.073002\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.1383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0766 (train) | 0.1383 (val)\n",
            "Epoch 29 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.070367\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.090237\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.085473\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.077150\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.057411\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.1393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0755 (train) | 0.1393 (val)\n",
            "Epoch 30 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.101143\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.065457\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.067105\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.084468\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.080834\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.1399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0757 (train) | 0.1399 (val)\n",
            "Epoch 31 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.078702\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.075878\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.089132\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.060292\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.070515\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.1383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0756 (train) | 0.1383 (val)\n",
            "Epoch 32 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.057623\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.088494\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.086314\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.101216\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.120586\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.1405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0758 (train) | 0.1405 (val)\n",
            "Epoch 33 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.079395\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.077835\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.089555\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.061147\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.073833\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0750 (train) | 0.1391 (val)\n",
            "Epoch 34 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.067750\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.077960\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.092634\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.074688\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.081654\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.1337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0755 (train) | 0.1337 (val)\n",
            "Epoch 35 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.088816\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.093331\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.078328\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.078100\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.077347\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0758 (train) | 0.1370 (val)\n",
            "Epoch 36 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.051383\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.071866\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.084476\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.088858\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.071531\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.1366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0759 (train) | 0.1366 (val)\n",
            "Epoch 37 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.065863\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.058568\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.075061\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.089588\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.093534\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.1426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0756 (train) | 0.1426 (val)\n",
            "Epoch 38 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.080123\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.064937\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.079624\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.063655\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.074951\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.1383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0767 (train) | 0.1383 (val)\n",
            "Epoch 39 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.097782\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.057414\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.074771\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.079533\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.069653\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.1349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0762 (train) | 0.1349 (val)\n",
            "Epoch 40 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.087099\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.065651\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.075239\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.068964\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.082943\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.1361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0752 (train) | 0.1361 (val)\n",
            "Epoch 41 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [0/1453 (0%)]\tLoss: 0.064462\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [320/1453 (22%)]\tLoss: 0.090517\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [640/1453 (43%)]\tLoss: 0.054589\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [960/1453 (65%)]\tLoss: 0.098166\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [1280/1453 (87%)]\tLoss: 0.073033\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 41\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 41 \tAverage loss: 0.1398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0758 (train) | 0.1398 (val)\n",
            "Epoch 42 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [0/1453 (0%)]\tLoss: 0.083213\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [320/1453 (22%)]\tLoss: 0.064156\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [640/1453 (43%)]\tLoss: 0.071652\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [960/1453 (65%)]\tLoss: 0.063469\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [1280/1453 (87%)]\tLoss: 0.055707\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 42\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 42 \tAverage loss: 0.1368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0763 (train) | 0.1368 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.21670789714115535,\n",
              "   0.11258635416124413,\n",
              "   0.09771864129523943,\n",
              "   0.09126419483261607,\n",
              "   0.08542510169748593,\n",
              "   0.08394338175685177,\n",
              "   0.0799880528493085,\n",
              "   0.07773235197712944,\n",
              "   0.0772806906025326,\n",
              "   0.07754820335018003,\n",
              "   0.07686211326187098,\n",
              "   0.07604733934011938,\n",
              "   0.07675915958548281,\n",
              "   0.07569343907949601,\n",
              "   0.07536968921618221,\n",
              "   0.07598293653682274,\n",
              "   0.0760267057237507,\n",
              "   0.076297091967532,\n",
              "   0.07588083129337715,\n",
              "   0.07617443686137097,\n",
              "   0.07565820965780033,\n",
              "   0.07527185666278076,\n",
              "   0.07562560225078671,\n",
              "   0.07618829333117644,\n",
              "   0.07608401767155752,\n",
              "   0.07512293821130223,\n",
              "   0.07580103730835426,\n",
              "   0.07664796805646365,\n",
              "   0.07554751739716087,\n",
              "   0.07566113997166188,\n",
              "   0.07558609885198858,\n",
              "   0.07579235125433062,\n",
              "   0.07501189595284498,\n",
              "   0.07546983004970052,\n",
              "   0.07581692422802334,\n",
              "   0.07591192666069442,\n",
              "   0.07561585390703152,\n",
              "   0.0767071898424125,\n",
              "   0.07622935734202102,\n",
              "   0.07517772583266578,\n",
              "   0.07576713235683467,\n",
              "   0.0762801263417282]},\n",
              " 'val': {'loss': [0.21584565937519073,\n",
              "   0.18268169462680817,\n",
              "   0.16859149436155954,\n",
              "   0.1621206353108088,\n",
              "   0.15002288420995077,\n",
              "   0.14369962612787882,\n",
              "   0.1462679902712504,\n",
              "   0.14079560339450836,\n",
              "   0.13940252860387167,\n",
              "   0.13895203173160553,\n",
              "   0.13490238785743713,\n",
              "   0.1401525338490804,\n",
              "   0.1376522034406662,\n",
              "   0.13752456506093344,\n",
              "   0.13808568318684897,\n",
              "   0.1404378910859426,\n",
              "   0.137784111003081,\n",
              "   0.13847582042217255,\n",
              "   0.13758058100938797,\n",
              "   0.13701968640089035,\n",
              "   0.13601562877496085,\n",
              "   0.1364592711130778,\n",
              "   0.1366740514834722,\n",
              "   0.13924013574918112,\n",
              "   0.13753694047530493,\n",
              "   0.141494353612264,\n",
              "   0.13478255768616995,\n",
              "   0.1383273055156072,\n",
              "   0.13929789264996847,\n",
              "   0.1398682395617167,\n",
              "   0.13828723629315695,\n",
              "   0.14048108458518982,\n",
              "   0.13908319175243378,\n",
              "   0.13372119516134262,\n",
              "   0.13701790322860083,\n",
              "   0.13664571940898895,\n",
              "   0.14258291820685068,\n",
              "   0.1383452812830607,\n",
              "   0.13488323986530304,\n",
              "   0.13605413337548575,\n",
              "   0.13978493710358939,\n",
              "   0.1367561792333921]}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "184299cb-89d4-4f07-de5a-637ec3e8fac9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "f138e605-723e-4303-fdd4-4497459afd3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kH5xVXQyG09W",
        "outputId": "cbee75d3-28d6-4471-8208-3fea672c3984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_34/unetv27.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_34/unetv27.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "d3654029-a7dd-4d18-9d9b-0d7ca7a7226d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:09<00:00,  1.23it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.2742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.2742\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv27')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libera la caché de la GPU\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CxrtcIqePCUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}