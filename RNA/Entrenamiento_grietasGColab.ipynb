{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "2019b788-9bf2-403b-f793-7ffd1a0aba34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "43a5433c-cca3-46fb-e0a7-c5d852550cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "812d0c57-d26b-42c9-bae5-3df50a247158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "69144044-ce52-4cde-cdf2-7dcf5dedb393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "54271e73-a460-4035-e99f-dd27b33d5bc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv16.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "9a533d61-c10b-4878-996f-be1cca504618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=40,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv18.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "c79062b8-820f-4708-80fb-3a993379744e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.049636\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.051016\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.048325\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.053462\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.037118\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0446 (train) | 0.0859 (val)\n",
            "Epoch 2 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.038719\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.047014\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.036072\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.062651\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.051761\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0851 (val)\n",
            "Epoch 3 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.041677\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.048236\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.035454\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.050481\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.043781\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0852 (val)\n",
            "Epoch 4 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.038254\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.043625\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.061216\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.046637\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.046040\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0443 (train) | 0.0850 (val)\n",
            "Epoch 5 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.046722\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.039653\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.046572\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.063727\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.053863\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0439 (train) | 0.0847 (val)\n",
            "Epoch 6 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.044609\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.041636\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.048340\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.042435\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.039167\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0846 (val)\n",
            "Epoch 7 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.043368\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.042227\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.064165\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.054461\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.033857\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0846 (val)\n",
            "Epoch 8 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.044020\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.044951\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.038498\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.045612\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.037971\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 9 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.049141\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.044873\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.061229\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.038405\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.036692\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0847 (val)\n",
            "Epoch 10 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.053221\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.045286\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.049573\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.035069\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.047238\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 11 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.044600\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.044152\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.042865\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.045187\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.034590\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0843 (val)\n",
            "Epoch 12 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.045576\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.045787\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.033624\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.034043\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.041726\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0845 (val)\n",
            "Epoch 13 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.029343\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.040316\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.044226\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.053594\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.054406\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0845 (val)\n",
            "Epoch 14 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.048764\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.039439\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.054627\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.054386\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.040995\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0845 (val)\n",
            "Epoch 15 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.047402\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.051970\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.030261\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.043735\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.050999\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 16 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.039344\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.049359\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.035139\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.044190\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.047423\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 17 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.032394\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.033819\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.047377\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.050686\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.056464\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 18 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.049293\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.033125\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.042668\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.037357\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.042371\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 19 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.045311\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.050002\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.050748\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.037744\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.051463\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 20 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.032082\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.055345\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.043023\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.046008\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.045696\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0846 (val)\n",
            "Epoch 21 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.032352\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.050145\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.040946\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.050792\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.036847\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 22 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.032189\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.043033\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.041725\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.046418\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.053641\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0844 (val)\n",
            "Epoch 23 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.028516\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.039530\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.041844\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.041691\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.052186\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0845 (val)\n",
            "Epoch 24 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.043403\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.046938\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.036724\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.063693\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.042043\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 25 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.056407\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.049651\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.038384\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.046356\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.030462\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 26 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.042962\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.037425\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.057053\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.043069\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.048223\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0844 (val)\n",
            "Epoch 27 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.052793\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.038600\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.049693\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.057390\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.032489\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0845 (val)\n",
            "Epoch 28 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.036330\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.038734\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.049791\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.033463\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.050588\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0845 (val)\n",
            "Epoch 29 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.038686\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.033521\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.031449\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.048410\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.041853\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 30 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.051452\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.048871\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.048458\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.051235\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.051466\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0845 (val)\n",
            "Epoch 31 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.042199\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.041128\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.045509\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.039771\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.035427\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0843 (val)\n",
            "Epoch 32 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.045042\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.065610\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.038826\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.050875\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.036209\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0845 (val)\n",
            "Epoch 33 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.043198\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.034946\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.043588\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.044334\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.047713\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0845 (val)\n",
            "Epoch 34 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.056623\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.039882\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.045615\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.052337\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.045611\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0433 (train) | 0.0844 (val)\n",
            "Epoch 35 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.037123\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.047716\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.046433\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.035443\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.046915\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 36 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.034757\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.051102\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.052728\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.040539\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.034445\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 37 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.038252\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.034327\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.036203\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.044169\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.043561\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0843 (val)\n",
            "Epoch 38 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.057660\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.057433\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.044078\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.055250\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.045898\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 39 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.032234\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.055820\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.044051\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.063397\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.031237\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 40 / 40\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.040314\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.048737\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.038389\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.041553\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.052365\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0844 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.04458250250751941,\n",
              "   0.04453948617278914,\n",
              "   0.04420363585896026,\n",
              "   0.044292626588388055,\n",
              "   0.04392272425227057,\n",
              "   0.04372939347441411,\n",
              "   0.04361951768562372,\n",
              "   0.04358617202247411,\n",
              "   0.043508815349009806,\n",
              "   0.0435481452974712,\n",
              "   0.043724020139275135,\n",
              "   0.04354279220145239,\n",
              "   0.04344429087255301,\n",
              "   0.04354914594172447,\n",
              "   0.04351874115810834,\n",
              "   0.04361553405298091,\n",
              "   0.04362455591385068,\n",
              "   0.04353892826266889,\n",
              "   0.04346852704205762,\n",
              "   0.04348133830770245,\n",
              "   0.04352003743606687,\n",
              "   0.043390827339350235,\n",
              "   0.04352988946749601,\n",
              "   0.043528382999070005,\n",
              "   0.043449828017910676,\n",
              "   0.04343001501659074,\n",
              "   0.043483911679528205,\n",
              "   0.04361453503293369,\n",
              "   0.04349017762165601,\n",
              "   0.04353443950065972,\n",
              "   0.043637769444187346,\n",
              "   0.04361368744991109,\n",
              "   0.04364357701536711,\n",
              "   0.04334906843367192,\n",
              "   0.04349147296124135,\n",
              "   0.04348154771106455,\n",
              "   0.04362755773123674,\n",
              "   0.04357517718581684,\n",
              "   0.04345374146485362,\n",
              "   0.04341631823175132]},\n",
              " 'val': {'loss': [0.08592314024766286,\n",
              "   0.08507966995239258,\n",
              "   0.08518865456183751,\n",
              "   0.08497264484564464,\n",
              "   0.08465675761302312,\n",
              "   0.08460140476624171,\n",
              "   0.08457365383704503,\n",
              "   0.08439679940541585,\n",
              "   0.08465305467446645,\n",
              "   0.08442538728316624,\n",
              "   0.08434890955686569,\n",
              "   0.08453249931335449,\n",
              "   0.08454634497563045,\n",
              "   0.08453179399172465,\n",
              "   0.08437657604614894,\n",
              "   0.08442043264706929,\n",
              "   0.08443410446246465,\n",
              "   0.08443514009316762,\n",
              "   0.08441868424415588,\n",
              "   0.08461889872948329,\n",
              "   0.08443494141101837,\n",
              "   0.08440386752287547,\n",
              "   0.0844835713505745,\n",
              "   0.08438462267319362,\n",
              "   0.08432379116614659,\n",
              "   0.0843746264775594,\n",
              "   0.08447202791770299,\n",
              "   0.084495243926843,\n",
              "   0.08442572504281998,\n",
              "   0.08454872916142146,\n",
              "   0.08433357377847035,\n",
              "   0.08445195357004802,\n",
              "   0.08445257941881816,\n",
              "   0.08438622454802196,\n",
              "   0.08431460460027058,\n",
              "   0.08434668928384781,\n",
              "   0.08429406086603801,\n",
              "   0.08439235389232635,\n",
              "   0.08439179758230846,\n",
              "   0.08436508476734161]}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "52b7fa1e-644f-4702-f85c-036334d5485c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "b4bbe497-53e2-45ed-8216-f91923348dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "088f9502-2d94-409e-8e9c-24feb2ec857f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_37/unetv18.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_37/unetv18.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "44f4d916-c572-4e35-a0c8-99b22a4b3915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [03:54<00:00, 19.58s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1104\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv16')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}