{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "31855dcb-0e0e-4415-b718-a4be2d8bda04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "b6eb2315-6d36-4c91-d369-b52182ad6dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pv-vision\n",
            "  Downloading pv_vision-0.2.8-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Collecting ipywidgets>=8.1.2 (from pv-vision)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Collecting matplotlib>=3.8.0 (from pv-vision)\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0.post100->pv-vision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n",
            "Downloading pv_vision-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, nvidia-cusolver-cu12, ipywidgets, pv-vision\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.7\n",
            "    Uninstalling widgetsnbextension-3.6.7:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.7\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 matplotlib-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pv-vision-0.2.8 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "907b9e1f-c2a4-4bbf-a817-bc0722c12086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK",
        "outputId": "3bb36ba5-ac28-4289-b1c4-f7a5e45551db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 181MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "d99b7d16-db01-494a-bbed-9e33bf042923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "41911dfe-78db-44fa-8bb4-e751fd8f4067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv10.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "d1a18a23-b411-4619-fef4-95f36ad888ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=30,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv11.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "412865d2-36bd-493d-c89d-bb2d9f6ebb86",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.051203\n",
            " 22%|██▏       | 10/46 [02:16<07:04, 11.80s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.047433\n",
            " 43%|████▎     | 20/46 [04:14<05:05, 11.76s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.058754\n",
            " 65%|██████▌   | 30/46 [06:08<02:59, 11.24s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.052614\n",
            " 87%|████████▋ | 40/46 [08:02<01:07, 11.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.058672\n",
            "100%|██████████| 46/46 [09:06<00:00, 11.89s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [01:06<00:00, 22.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0559 (train) | 0.1046 (val)\n",
            "Epoch 2 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.039077\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.059846\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.051587\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.055895\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.041479\n",
            "100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0535 (train) | 0.1044 (val)\n",
            "Epoch 3 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.054389\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.062981\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.051741\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.048278\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.070484\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0537 (train) | 0.1022 (val)\n",
            "Epoch 4 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.051318\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.058395\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.044620\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.052214\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.046174\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.54it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0527 (train) | 0.1007 (val)\n",
            "Epoch 5 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.060405\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.036272\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.043159\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.066445\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.040111\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0520 (train) | 0.0993 (val)\n",
            "Epoch 6 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.045030\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.057955\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.061220\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.070993\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.053523\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0496 (train) | 0.0957 (val)\n",
            "Epoch 7 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.049247\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.043460\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.058439\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.035516\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.052400\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0486 (train) | 0.0939 (val)\n",
            "Epoch 8 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.034464\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.061619\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.043276\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.046879\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.048772\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0486 (train) | 0.0958 (val)\n",
            "Epoch 9 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.058174\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.039866\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.048249\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.057082\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.047904\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0484 (train) | 0.0933 (val)\n",
            "Epoch 10 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.052511\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.044809\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.049833\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.047458\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.041049\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0481 (train) | 0.0927 (val)\n",
            "Epoch 11 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.044803\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.040014\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.048494\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.049171\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.069130\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0476 (train) | 0.0921 (val)\n",
            "Epoch 12 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.059313\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.050589\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.042843\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.038496\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.048836\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0475 (train) | 0.0924 (val)\n",
            "Epoch 13 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.063193\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.042519\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.046949\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.048975\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.040635\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0474 (train) | 0.0919 (val)\n",
            "Epoch 14 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.038845\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.051932\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.054693\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.043904\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.047050\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0917 (val)\n",
            "Epoch 15 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.053433\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.047711\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.045212\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.062890\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.040348\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0473 (train) | 0.0919 (val)\n",
            "Epoch 16 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.037747\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.045839\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.048688\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.041931\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.047267\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.0918 (val)\n",
            "Epoch 17 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.042023\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.045834\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.040425\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.043900\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.038954\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0916 (val)\n",
            "Epoch 18 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.047481\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.058840\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.059104\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.041007\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.060803\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0473 (train) | 0.0916 (val)\n",
            "Epoch 19 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.042790\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.047954\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.054470\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.027358\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.055708\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0917 (val)\n",
            "Epoch 20 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.036762\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.042008\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.041026\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.049575\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.036114\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.0916 (val)\n",
            "Epoch 21 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.051272\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.047014\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.046366\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.050345\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.046205\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.0914 (val)\n",
            "Epoch 22 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.047951\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.041500\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.040178\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.046967\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.062597\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0915 (val)\n",
            "Epoch 23 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.054209\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.043513\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.054484\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.044113\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.038354\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.0915 (val)\n",
            "Epoch 24 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.055950\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.055625\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.065166\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.023050\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.035444\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0915 (val)\n",
            "Epoch 25 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.041301\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.046311\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.043877\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.037035\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.044008\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0914 (val)\n",
            "Epoch 26 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.049252\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.041630\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.039509\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.036704\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.036023\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0913 (val)\n",
            "Epoch 27 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.038886\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.035354\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.043542\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.057495\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.044578\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0914 (val)\n",
            "Epoch 28 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.044541\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.050871\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.049109\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.050320\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.055245\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0471 (train) | 0.0915 (val)\n",
            "Epoch 29 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.039342\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.031075\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.036596\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.043287\n",
            " 87%|████████▋ | 40/46 [00:47<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.047124\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.18s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0913 (val)\n",
            "Epoch 30 / 30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.046316\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.047465\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.050868\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.045260\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.053176\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.19s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0470 (train) | 0.0914 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.05586174209406683,\n",
              "   0.05353884955807874,\n",
              "   0.053668258269429614,\n",
              "   0.0527499489440068,\n",
              "   0.052003801986831515,\n",
              "   0.04955061190778932,\n",
              "   0.048641305404003125,\n",
              "   0.04855892100645112,\n",
              "   0.04841265393355675,\n",
              "   0.04814012129185369,\n",
              "   0.04763142725597639,\n",
              "   0.047494560059644565,\n",
              "   0.04739022151620242,\n",
              "   0.04706803790286583,\n",
              "   0.047340873512199066,\n",
              "   0.0471573872498127,\n",
              "   0.04704251256498975,\n",
              "   0.04729844668222474,\n",
              "   0.047109839990376115,\n",
              "   0.047185106417042426,\n",
              "   0.04717987562489362,\n",
              "   0.04713930656232263,\n",
              "   0.04715129266719283,\n",
              "   0.047078024808776354,\n",
              "   0.047017127762600544,\n",
              "   0.04707688543912221,\n",
              "   0.04703694441485881,\n",
              "   0.047119340034431204,\n",
              "   0.046998654055702055,\n",
              "   0.04697633129067037]},\n",
              " 'val': {'loss': [0.10464940716822942,\n",
              "   0.10442780951658885,\n",
              "   0.10219150533278783,\n",
              "   0.10072655479113261,\n",
              "   0.0992706095178922,\n",
              "   0.09571796655654907,\n",
              "   0.09394139051437378,\n",
              "   0.09576730181773503,\n",
              "   0.09325826913118362,\n",
              "   0.09267377853393555,\n",
              "   0.09214379886786143,\n",
              "   0.09241230289141338,\n",
              "   0.09191299726565678,\n",
              "   0.09166358411312103,\n",
              "   0.09188986321290334,\n",
              "   0.09175719569126765,\n",
              "   0.09157545864582062,\n",
              "   0.09159195671478908,\n",
              "   0.09165556728839874,\n",
              "   0.09155553827683131,\n",
              "   0.09144043177366257,\n",
              "   0.09146025031805038,\n",
              "   0.09145712107419968,\n",
              "   0.09153470893700917,\n",
              "   0.09144783516724904,\n",
              "   0.09134695430596669,\n",
              "   0.09141725301742554,\n",
              "   0.09145299096902211,\n",
              "   0.09133414427439372,\n",
              "   0.09135772287845612]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "6488edb7-a7ed-4dae-fb8e-667eb46cb84b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "13da4838-cd06-4313-b056-88c7e1ccfd67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "aec1cfbb-5726-4377-abe6-7681b5412a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv11.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_30/unetv11.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "2dbbfcbe-da9f-415e-a87d-98392575059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:18<00:00, 21.52s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1105\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv11')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}