{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "329356a9-8898-410c-9fea-b24700d5e5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "66170913-b52b-42da-9a67-221ea1fb25b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "324d2538-e20c-4054-fbd2-d764d2c3c640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "#transformers = Compose([transforms.RandomRotation(degrees=30), FixResize(256), ToTensor(), Normalize()])\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "42e9b3e6-fafe-4a6e-9b47-d31ef333a16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=6, gamma=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "b844e0ed-08cc-439d-989e-804184c1eca7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv16.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "62698cc7-4692-4f18-88fe-8142044a0828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=32,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv21.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "0a2f4d58-a687-4ef3-98f7-973be71db1d3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.041150\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.040154\n",
            " 43%|████▎     | 20/46 [00:23<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.045543\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.040178\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.052599\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0443 (train) | 0.0861 (val)\n",
            "Epoch 2 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.049224\n",
            " 22%|██▏       | 10/46 [00:11<00:40,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.037014\n",
            " 43%|████▎     | 20/46 [00:22<00:29,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.042292\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.043849\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.038733\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.16s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0443 (train) | 0.0869 (val)\n",
            "Epoch 3 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.050515\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.030199\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.037617\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.045930\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.039127\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0445 (train) | 0.0853 (val)\n",
            "Epoch 4 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.033534\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.052252\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.038170\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.051348\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.055627\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0442 (train) | 0.0850 (val)\n",
            "Epoch 5 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.034093\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.047321\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.046754\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.051956\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.047536\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0440 (train) | 0.0847 (val)\n",
            "Epoch 6 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.051250\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.033304\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.034722\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.035765\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.048256\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0849 (val)\n",
            "Epoch 7 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.042558\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.039790\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.032167\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.045161\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.058228\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0438 (train) | 0.0849 (val)\n",
            "Epoch 8 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.043811\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.040988\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.039654\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.039972\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.038238\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0845 (val)\n",
            "Epoch 9 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.049730\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.043938\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.036289\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.060390\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.038832\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0845 (val)\n",
            "Epoch 10 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.038525\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.049910\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.034728\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.038923\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.043992\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0845 (val)\n",
            "Epoch 11 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.058757\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.044821\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.038300\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.037185\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.047265\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 12 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.036739\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.034573\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.053773\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.046679\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.033070\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 13 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.052038\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.037596\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.048862\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.049839\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.051303\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0845 (val)\n",
            "Epoch 14 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.028840\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.035036\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.039152\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.052984\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.038940\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 15 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.028754\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.039888\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.052609\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.048560\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.047805\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 16 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.058695\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.044023\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.038266\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.039048\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.055967\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 17 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.039802\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.046831\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.045563\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.032937\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.040263\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 18 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.053068\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.050638\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.049707\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.045575\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.038333\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 19 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.042044\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.044587\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.053293\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.033312\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.041477\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0843 (val)\n",
            "Epoch 20 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.048072\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.039467\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.045061\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.041461\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.056412\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 21 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.047656\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.052256\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.046471\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.048149\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.038748\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0844 (val)\n",
            "Epoch 22 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.044447\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.045249\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.052238\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.046507\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.032585\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 23 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.056849\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.033574\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.041424\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.053813\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.039059\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0844 (val)\n",
            "Epoch 24 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.028555\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.033326\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.036136\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.035642\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.029937\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 25 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.047610\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.050198\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.043345\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.038217\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.044376\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0844 (val)\n",
            "Epoch 26 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.042751\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.038566\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.041873\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.048089\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.055368\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 27 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.042532\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.040751\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.046999\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.036441\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.059133\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0437 (train) | 0.0843 (val)\n",
            "Epoch 28 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.038234\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.042398\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.044064\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.036854\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.053448\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0843 (val)\n",
            "Epoch 29 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.044878\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.043265\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.039209\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.052644\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.043830\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0843 (val)\n",
            "Epoch 30 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.051846\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.044653\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.039734\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.038521\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.050190\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0435 (train) | 0.0844 (val)\n",
            "Epoch 31 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.043062\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.036307\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.047810\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.042570\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.051687\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0844 (val)\n",
            "Epoch 32 / 32\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.036568\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.048221\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.049955\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.039312\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.051504\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0843 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.04434206774131397,\n",
              "   0.04431256294476108,\n",
              "   0.04446431360523494,\n",
              "   0.04416384421294095,\n",
              "   0.04399619871174887,\n",
              "   0.044128571154327945,\n",
              "   0.043753535019494055,\n",
              "   0.04357320087188207,\n",
              "   0.04365377727554982,\n",
              "   0.04364194015152521,\n",
              "   0.04345084065847042,\n",
              "   0.043532721595729705,\n",
              "   0.04366633238582388,\n",
              "   0.043488302177711755,\n",
              "   0.04356175299582609,\n",
              "   0.04349578270933502,\n",
              "   0.043536139730330756,\n",
              "   0.04354916024806987,\n",
              "   0.04355818031936453,\n",
              "   0.043473464000331724,\n",
              "   0.04338183653965869,\n",
              "   0.043522198365953814,\n",
              "   0.04365002843105867,\n",
              "   0.043621091234913714,\n",
              "   0.043406588906718384,\n",
              "   0.04344606003804159,\n",
              "   0.04369735179106203,\n",
              "   0.04359848766298599,\n",
              "   0.043466793233496684,\n",
              "   0.0435307160307027,\n",
              "   0.04360041427134401,\n",
              "   0.043641892153480015]},\n",
              " 'val': {'loss': [0.08613547434409459,\n",
              "   0.08689124633868535,\n",
              "   0.08532874286174774,\n",
              "   0.08498364686965942,\n",
              "   0.08471317092577617,\n",
              "   0.08494526892900467,\n",
              "   0.08485198765993118,\n",
              "   0.08447715143362682,\n",
              "   0.08448299517234166,\n",
              "   0.08448420216639836,\n",
              "   0.08443128069241841,\n",
              "   0.08435819546381633,\n",
              "   0.08447287231683731,\n",
              "   0.08435446520646413,\n",
              "   0.08436600863933563,\n",
              "   0.08431900789340337,\n",
              "   0.08433992664019267,\n",
              "   0.08437657356262207,\n",
              "   0.08430335422356923,\n",
              "   0.08431828270355861,\n",
              "   0.08443105469147365,\n",
              "   0.08441958824793498,\n",
              "   0.08435411502917607,\n",
              "   0.08439124872287114,\n",
              "   0.0844498947262764,\n",
              "   0.08427034070094426,\n",
              "   0.08434487382570903,\n",
              "   0.08425454795360565,\n",
              "   0.08434820423523585,\n",
              "   0.08442860841751099,\n",
              "   0.0844367394844691,\n",
              "   0.08425827324390411]}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "497408bb-779c-4ee5-cdf6-24d5ff48e8fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "6ef78063-e924-4950-a1cf-33b7a221edb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "fc9b9a2a-c035-48ed-9111-e9b9ce146bec",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_28/unetv21.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_28/unetv21.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "32f6230c-3382-433d-9860-bc7bd3626339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:27<00:00, 22.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1090\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv19')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}