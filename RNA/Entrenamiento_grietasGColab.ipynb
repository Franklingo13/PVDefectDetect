{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "6c5ba2bb-46ef-4bc7-b347-f7baa81361a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "29b6028f-8ec8-4ac7-bf8d-2a301015fa95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "6674f8ee-71b0-4669-998c-4dd80478c6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "bfc51566-a78a-4f6c-d50c-b028fe33c519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "90182e98-7970-45cf-a9d1-1f9a93f36ef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv8.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "115a4677-ca21-4082-eca7-773f04704a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=25,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv9.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "e7690a60-84d7-4379-b5f4-5b04f16de9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.082220\n",
            " 11%|█         | 10/91 [00:22<01:38,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1453 (11%)]\tLoss: 0.071283\n",
            " 22%|██▏       | 20/91 [00:33<01:19,  1.12s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.055458\n",
            " 33%|███▎      | 30/91 [00:44<01:05,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1453 (33%)]\tLoss: 0.074155\n",
            " 44%|████▍     | 40/91 [00:55<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (44%)]\tLoss: 0.074561\n",
            " 55%|█████▍    | 50/91 [01:05<00:42,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1453 (55%)]\tLoss: 0.063991\n",
            " 66%|██████▌   | 60/91 [01:16<00:31,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (66%)]\tLoss: 0.063718\n",
            " 77%|███████▋  | 70/91 [01:26<00:21,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1120/1453 (77%)]\tLoss: 0.076819\n",
            " 88%|████████▊ | 80/91 [01:37<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (88%)]\tLoss: 0.047628\n",
            " 99%|█████████▉| 90/91 [01:48<00:01,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1170/1453 (99%)]\tLoss: 0.068965\n",
            "100%|██████████| 91/91 [01:49<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.1303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0651 (train) | 0.1303 (val)\n",
            "Epoch 2 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.081470\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1453 (11%)]\tLoss: 0.043137\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.051466\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1453 (33%)]\tLoss: 0.061926\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (44%)]\tLoss: 0.064473\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1453 (55%)]\tLoss: 0.079915\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (66%)]\tLoss: 0.083253\n",
            " 77%|███████▋  | 70/91 [01:13<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1120/1453 (77%)]\tLoss: 0.061940\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (88%)]\tLoss: 0.057524\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1170/1453 (99%)]\tLoss: 0.057089\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.1227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0632 (train) | 0.1227 (val)\n",
            "Epoch 3 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.045266\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1453 (11%)]\tLoss: 0.079521\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.107514\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1453 (33%)]\tLoss: 0.100269\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (44%)]\tLoss: 0.087835\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1453 (55%)]\tLoss: 0.095304\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (66%)]\tLoss: 0.061477\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1120/1453 (77%)]\tLoss: 0.054234\n",
            " 88%|████████▊ | 80/91 [01:25<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (88%)]\tLoss: 0.048410\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1170/1453 (99%)]\tLoss: 0.062192\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.1258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0646 (train) | 0.1258 (val)\n",
            "Epoch 4 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.090481\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1453 (11%)]\tLoss: 0.054991\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.045628\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1453 (33%)]\tLoss: 0.042644\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (44%)]\tLoss: 0.046526\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1453 (55%)]\tLoss: 0.064801\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (66%)]\tLoss: 0.064048\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1120/1453 (77%)]\tLoss: 0.078728\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (88%)]\tLoss: 0.071315\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1170/1453 (99%)]\tLoss: 0.042153\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0630 (train) | 0.1297 (val)\n",
            "Epoch 5 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.081527\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1453 (11%)]\tLoss: 0.077672\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.050754\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1453 (33%)]\tLoss: 0.037668\n",
            " 44%|████▍     | 40/91 [00:41<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (44%)]\tLoss: 0.055557\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1453 (55%)]\tLoss: 0.044878\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (66%)]\tLoss: 0.078889\n",
            " 77%|███████▋  | 70/91 [01:13<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1120/1453 (77%)]\tLoss: 0.067499\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (88%)]\tLoss: 0.066052\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1170/1453 (99%)]\tLoss: 0.055331\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0625 (train) | 0.1165 (val)\n",
            "Epoch 6 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.041620\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1453 (11%)]\tLoss: 0.066429\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.050901\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1453 (33%)]\tLoss: 0.048513\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (44%)]\tLoss: 0.055007\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1453 (55%)]\tLoss: 0.053923\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (66%)]\tLoss: 0.045169\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1120/1453 (77%)]\tLoss: 0.066702\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (88%)]\tLoss: 0.068442\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1170/1453 (99%)]\tLoss: 0.048945\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0575 (train) | 0.1098 (val)\n",
            "Epoch 7 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.054885\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1453 (11%)]\tLoss: 0.077987\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.045421\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1453 (33%)]\tLoss: 0.043081\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (44%)]\tLoss: 0.052527\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1453 (55%)]\tLoss: 0.090304\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (66%)]\tLoss: 0.049326\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1120/1453 (77%)]\tLoss: 0.073939\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (88%)]\tLoss: 0.055602\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1170/1453 (99%)]\tLoss: 0.047397\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0568 (train) | 0.1089 (val)\n",
            "Epoch 8 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.045961\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1453 (11%)]\tLoss: 0.059135\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.053300\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1453 (33%)]\tLoss: 0.060402\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (44%)]\tLoss: 0.034601\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1453 (55%)]\tLoss: 0.071797\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (66%)]\tLoss: 0.032223\n",
            " 77%|███████▋  | 70/91 [01:13<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1120/1453 (77%)]\tLoss: 0.040193\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (88%)]\tLoss: 0.053211\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1170/1453 (99%)]\tLoss: 0.056357\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0564 (train) | 0.1060 (val)\n",
            "Epoch 9 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.052054\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1453 (11%)]\tLoss: 0.042789\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.047193\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1453 (33%)]\tLoss: 0.055672\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (44%)]\tLoss: 0.052060\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1453 (55%)]\tLoss: 0.030201\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (66%)]\tLoss: 0.047953\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1120/1453 (77%)]\tLoss: 0.049605\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (88%)]\tLoss: 0.041144\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1170/1453 (99%)]\tLoss: 0.071087\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.99it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0555 (train) | 0.1059 (val)\n",
            "Epoch 10 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.102906\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1453 (11%)]\tLoss: 0.089194\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.060761\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1453 (33%)]\tLoss: 0.053801\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (44%)]\tLoss: 0.047510\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1453 (55%)]\tLoss: 0.074164\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (66%)]\tLoss: 0.040150\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1120/1453 (77%)]\tLoss: 0.048459\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (88%)]\tLoss: 0.040233\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1170/1453 (99%)]\tLoss: 0.043699\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0554 (train) | 0.1053 (val)\n",
            "Epoch 11 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.039184\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1453 (11%)]\tLoss: 0.048654\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.077870\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1453 (33%)]\tLoss: 0.053980\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (44%)]\tLoss: 0.051401\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1453 (55%)]\tLoss: 0.044153\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (66%)]\tLoss: 0.052782\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1120/1453 (77%)]\tLoss: 0.047543\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (88%)]\tLoss: 0.059044\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1170/1453 (99%)]\tLoss: 0.038601\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0546 (train) | 0.1042 (val)\n",
            "Epoch 12 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.081850\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1453 (11%)]\tLoss: 0.040644\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.045570\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1453 (33%)]\tLoss: 0.062810\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (44%)]\tLoss: 0.039756\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1453 (55%)]\tLoss: 0.045028\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (66%)]\tLoss: 0.060033\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1120/1453 (77%)]\tLoss: 0.062134\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (88%)]\tLoss: 0.067069\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1170/1453 (99%)]\tLoss: 0.052239\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0546 (train) | 0.1049 (val)\n",
            "Epoch 13 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.050393\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1453 (11%)]\tLoss: 0.063578\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.068075\n",
            " 33%|███▎      | 30/91 [00:31<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1453 (33%)]\tLoss: 0.059768\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (44%)]\tLoss: 0.057558\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1453 (55%)]\tLoss: 0.052171\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (66%)]\tLoss: 0.045120\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1120/1453 (77%)]\tLoss: 0.064350\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (88%)]\tLoss: 0.081217\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1170/1453 (99%)]\tLoss: 0.065095\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0541 (train) | 0.1041 (val)\n",
            "Epoch 14 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.049681\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1453 (11%)]\tLoss: 0.049923\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.049822\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1453 (33%)]\tLoss: 0.047920\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (44%)]\tLoss: 0.060900\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1453 (55%)]\tLoss: 0.084886\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (66%)]\tLoss: 0.066816\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1120/1453 (77%)]\tLoss: 0.034292\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (88%)]\tLoss: 0.039132\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1170/1453 (99%)]\tLoss: 0.081772\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0543 (train) | 0.1040 (val)\n",
            "Epoch 15 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.057696\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1453 (11%)]\tLoss: 0.045904\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.066850\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1453 (33%)]\tLoss: 0.043769\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (44%)]\tLoss: 0.031269\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1453 (55%)]\tLoss: 0.037936\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (66%)]\tLoss: 0.095104\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1120/1453 (77%)]\tLoss: 0.044801\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (88%)]\tLoss: 0.081440\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1170/1453 (99%)]\tLoss: 0.046346\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0544 (train) | 0.1032 (val)\n",
            "Epoch 16 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.040156\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [160/1453 (11%)]\tLoss: 0.099946\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.048207\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [480/1453 (33%)]\tLoss: 0.062417\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (44%)]\tLoss: 0.050135\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [800/1453 (55%)]\tLoss: 0.078861\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (66%)]\tLoss: 0.063186\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1120/1453 (77%)]\tLoss: 0.048275\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (88%)]\tLoss: 0.051975\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1170/1453 (99%)]\tLoss: 0.065545\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0540 (train) | 0.1031 (val)\n",
            "Epoch 17 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.058389\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [160/1453 (11%)]\tLoss: 0.069055\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.062770\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [480/1453 (33%)]\tLoss: 0.045156\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (44%)]\tLoss: 0.070953\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [800/1453 (55%)]\tLoss: 0.046508\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (66%)]\tLoss: 0.054845\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1120/1453 (77%)]\tLoss: 0.062104\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (88%)]\tLoss: 0.054841\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1170/1453 (99%)]\tLoss: 0.044325\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.1032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0541 (train) | 0.1032 (val)\n",
            "Epoch 18 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.053405\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [160/1453 (11%)]\tLoss: 0.029980\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.072997\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [480/1453 (33%)]\tLoss: 0.055677\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (44%)]\tLoss: 0.046371\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [800/1453 (55%)]\tLoss: 0.072555\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (66%)]\tLoss: 0.057302\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1120/1453 (77%)]\tLoss: 0.075245\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (88%)]\tLoss: 0.038066\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1170/1453 (99%)]\tLoss: 0.037214\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.1034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0539 (train) | 0.1034 (val)\n",
            "Epoch 19 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.056608\n",
            " 11%|█         | 10/91 [00:10<01:23,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [160/1453 (11%)]\tLoss: 0.075441\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.023149\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [480/1453 (33%)]\tLoss: 0.060204\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (44%)]\tLoss: 0.049473\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [800/1453 (55%)]\tLoss: 0.035471\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (66%)]\tLoss: 0.048568\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1120/1453 (77%)]\tLoss: 0.052686\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (88%)]\tLoss: 0.058311\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1170/1453 (99%)]\tLoss: 0.058149\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0540 (train) | 0.1031 (val)\n",
            "Epoch 20 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.061494\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [160/1453 (11%)]\tLoss: 0.053898\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.052248\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [480/1453 (33%)]\tLoss: 0.052559\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (44%)]\tLoss: 0.117245\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [800/1453 (55%)]\tLoss: 0.072852\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (66%)]\tLoss: 0.048932\n",
            " 77%|███████▋  | 70/91 [01:14<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1120/1453 (77%)]\tLoss: 0.067260\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (88%)]\tLoss: 0.060865\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1170/1453 (99%)]\tLoss: 0.056288\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.1034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0541 (train) | 0.1034 (val)\n",
            "Epoch 21 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.059908\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [160/1453 (11%)]\tLoss: 0.034433\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.051769\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [480/1453 (33%)]\tLoss: 0.051715\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (44%)]\tLoss: 0.062990\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [800/1453 (55%)]\tLoss: 0.029616\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (66%)]\tLoss: 0.053937\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1120/1453 (77%)]\tLoss: 0.046791\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (88%)]\tLoss: 0.043942\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1170/1453 (99%)]\tLoss: 0.065491\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.1030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0539 (train) | 0.1030 (val)\n",
            "Epoch 22 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.052791\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [160/1453 (11%)]\tLoss: 0.043135\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.064995\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [480/1453 (33%)]\tLoss: 0.056400\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (44%)]\tLoss: 0.051950\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [800/1453 (55%)]\tLoss: 0.028248\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (66%)]\tLoss: 0.041016\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1120/1453 (77%)]\tLoss: 0.058132\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (88%)]\tLoss: 0.056537\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1170/1453 (99%)]\tLoss: 0.069315\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.79it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0540 (train) | 0.1031 (val)\n",
            "Epoch 23 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.055175\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [160/1453 (11%)]\tLoss: 0.063002\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.036907\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [480/1453 (33%)]\tLoss: 0.047235\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (44%)]\tLoss: 0.046424\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [800/1453 (55%)]\tLoss: 0.067271\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (66%)]\tLoss: 0.047932\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1120/1453 (77%)]\tLoss: 0.065719\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (88%)]\tLoss: 0.038517\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1170/1453 (99%)]\tLoss: 0.042465\n",
            "100%|██████████| 91/91 [01:37<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.1028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0538 (train) | 0.1028 (val)\n",
            "Epoch 24 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.064558\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [160/1453 (11%)]\tLoss: 0.069063\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.028827\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [480/1453 (33%)]\tLoss: 0.041221\n",
            " 44%|████▍     | 40/91 [00:41<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (44%)]\tLoss: 0.065200\n",
            " 55%|█████▍    | 50/91 [00:52<00:42,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [800/1453 (55%)]\tLoss: 0.043154\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (66%)]\tLoss: 0.058085\n",
            " 77%|███████▋  | 70/91 [01:13<00:22,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1120/1453 (77%)]\tLoss: 0.081031\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (88%)]\tLoss: 0.048963\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1170/1453 (99%)]\tLoss: 0.035453\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.1029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0535 (train) | 0.1029 (val)\n",
            "Epoch 25 / 25\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/91 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.126149\n",
            " 11%|█         | 10/91 [00:10<01:24,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [160/1453 (11%)]\tLoss: 0.052789\n",
            " 22%|██▏       | 20/91 [00:20<01:14,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.050040\n",
            " 33%|███▎      | 30/91 [00:31<01:04,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [480/1453 (33%)]\tLoss: 0.075785\n",
            " 44%|████▍     | 40/91 [00:42<00:53,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (44%)]\tLoss: 0.092912\n",
            " 55%|█████▍    | 50/91 [00:52<00:43,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [800/1453 (55%)]\tLoss: 0.037570\n",
            " 66%|██████▌   | 60/91 [01:03<00:32,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (66%)]\tLoss: 0.075326\n",
            " 77%|███████▋  | 70/91 [01:14<00:21,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1120/1453 (77%)]\tLoss: 0.042101\n",
            " 88%|████████▊ | 80/91 [01:24<00:11,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (88%)]\tLoss: 0.043353\n",
            " 99%|█████████▉| 90/91 [01:35<00:01,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1170/1453 (99%)]\tLoss: 0.023902\n",
            "100%|██████████| 91/91 [01:36<00:00,  1.06s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.99it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0541 (train) | 0.1036 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.06506345381592359,\n",
              "   0.06323101999929094,\n",
              "   0.06462480072432031,\n",
              "   0.06297557277724157,\n",
              "   0.062459758545047074,\n",
              "   0.057498915440159996,\n",
              "   0.05684300380805732,\n",
              "   0.05642042686702544,\n",
              "   0.05554848411988982,\n",
              "   0.055439568917585585,\n",
              "   0.05459085949078069,\n",
              "   0.05457438641347642,\n",
              "   0.05408394089031449,\n",
              "   0.054251061453748715,\n",
              "   0.05435480987839016,\n",
              "   0.05402273016597842,\n",
              "   0.05407781299031855,\n",
              "   0.053917983786574086,\n",
              "   0.05398494203646102,\n",
              "   0.054067055146733566,\n",
              "   0.05387796799499088,\n",
              "   0.05399371314401554,\n",
              "   0.05384490754088696,\n",
              "   0.05349561427729506,\n",
              "   0.05411389980052392]},\n",
              " 'val': {'loss': [0.13026689489682516,\n",
              "   0.12268233795960744,\n",
              "   0.1258135475218296,\n",
              "   0.1297064038614432,\n",
              "   0.11647771919767062,\n",
              "   0.10978991414109866,\n",
              "   0.10893918077150981,\n",
              "   0.10601378108064334,\n",
              "   0.10587071875731151,\n",
              "   0.10528535271684329,\n",
              "   0.10419369985659917,\n",
              "   0.1049158622821172,\n",
              "   0.10408888260523479,\n",
              "   0.10401115193963051,\n",
              "   0.10320718338092168,\n",
              "   0.10310516878962517,\n",
              "   0.10320875296990077,\n",
              "   0.10337516044576962,\n",
              "   0.10309657206137975,\n",
              "   0.10342953602472942,\n",
              "   0.10298039143284161,\n",
              "   0.10305670648813248,\n",
              "   0.10279994085431099,\n",
              "   0.10289797559380531,\n",
              "   0.10355561599135399]}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "63e91d5f-0a1a-4b0f-b5af-52994386df1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "fde61c25-5901-4a2a-db78-4ac6685b1b9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "e99d30c6-9da0-40f5-d6cf-220d10ba0246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_23/unetv9.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_23/unetv9.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "92fae68f-43d1-44ed-9d7c-512e1b42ce84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [00:12<00:00,  1.89it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1224\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv8')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}