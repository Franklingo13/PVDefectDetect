{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "07d069c0-b8dd-46e8-c638-60288d0b7e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "09f4ef5a-aeb3-42c2-ccd4-7aafd6297a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "f8db28f7-b2c3-4a3f-ebb7-11ccefa4d4b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "#transformers = Compose([transforms.RandomRotation(degrees=30), FixResize(256), ToTensor(), Normalize()])\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "932cd674-ea27-46fe-c42f-815bea547f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=6, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "c0c82c35-6c93-4e39-9962-70f1bfff4de4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv16.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "c1f15ecb-ad58-452a-c0e3-df1b06b52132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv22.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "3b8475b4-6cba-4296-919e-3355a9ed5dc4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.035946\n",
            " 22%|██▏       | 10/46 [00:22<00:45,  1.26s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.048053\n",
            " 43%|████▎     | 20/46 [00:33<00:29,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.058276\n",
            " 65%|██████▌   | 30/46 [00:45<00:18,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.054401\n",
            " 87%|████████▋ | 40/46 [00:57<00:06,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.041192\n",
            "100%|██████████| 46/46 [01:04<00:00,  1.39s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0509 (train) | 0.0958 (val)\n",
            "Epoch 2 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.048074\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.043786\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.036172\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.046866\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.063061\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0476 (train) | 0.0945 (val)\n",
            "Epoch 3 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.052623\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.047276\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.038135\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.037776\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.069020\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0487 (train) | 0.0938 (val)\n",
            "Epoch 4 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.045634\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.047479\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.030152\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.041076\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.068747\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.1055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.1055 (val)\n",
            "Epoch 5 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.048480\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.066415\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.035406\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.042325\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.045646\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0472 (train) | 0.0903 (val)\n",
            "Epoch 6 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.042787\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.034355\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.058598\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.040079\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.039163\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0482 (train) | 0.0918 (val)\n",
            "Epoch 7 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.042038\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.039447\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.059868\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.034895\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.038616\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0451 (train) | 0.0867 (val)\n",
            "Epoch 8 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.046220\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.042250\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.051493\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.034156\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.051245\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0441 (train) | 0.0858 (val)\n",
            "Epoch 9 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.042188\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.036863\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.040885\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.042847\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.045056\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0436 (train) | 0.0855 (val)\n",
            "Epoch 10 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.051153\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.032003\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.038332\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.031406\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.061657\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0843 (val)\n",
            "Epoch 11 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.038604\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.047524\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.041342\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.042069\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.030477\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0434 (train) | 0.0839 (val)\n",
            "Epoch 12 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.045835\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.046433\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.035697\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.034503\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.043855\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0432 (train) | 0.0842 (val)\n",
            "Epoch 13 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.035140\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.041434\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.041284\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.048203\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.037261\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0429 (train) | 0.0836 (val)\n",
            "Epoch 14 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.036193\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.040453\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.048597\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.042293\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.049685\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0835 (val)\n",
            "Epoch 15 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.044113\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.038648\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.033250\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.031736\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.048280\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0834 (val)\n",
            "Epoch 16 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.043088\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.045769\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.046415\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.036946\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.046457\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0834 (val)\n",
            "Epoch 17 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.038550\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.037716\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.034190\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.031245\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.042063\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0428 (train) | 0.0833 (val)\n",
            "Epoch 18 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.034032\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.038296\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.055603\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.039417\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.050983\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0833 (val)\n",
            "Epoch 19 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.041367\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.035457\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.051609\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.044737\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.048808\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 20 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.055395\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.047411\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.039804\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.035667\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.047066\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0833 (val)\n",
            "Epoch 21 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.039301\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.035479\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.028562\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.039696\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.031371\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0833 (val)\n",
            "Epoch 22 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.037787\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.045383\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.026707\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.058882\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.042781\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 23 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.050681\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.046965\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.049352\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.031025\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.036172\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 24 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.052713\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.039405\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.052113\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.047889\n",
            " 87%|████████▋ | 40/46 [00:46<00:07,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.046796\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0428 (train) | 0.0833 (val)\n",
            "Epoch 25 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.049688\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.047447\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.046105\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.034731\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.041338\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0833 (val)\n",
            "Epoch 26 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.033979\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.056030\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.039393\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.054324\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.038527\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 27 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.042310\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.057949\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.047476\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.039526\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.047829\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 28 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.051919\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.033943\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.043966\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.036280\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.044380\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 29 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.041320\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.034135\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.037702\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.040729\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.059440\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0834 (val)\n",
            "Epoch 30 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.040613\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.036989\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.039156\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.028106\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.037789\n",
            "100%|██████████| 46/46 [00:54<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0428 (train) | 0.0833 (val)\n",
            "Epoch 31 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.039591\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.034257\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.034686\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.052591\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.039118\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 32 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.037904\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.034983\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.047018\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.043581\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.033980\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 33 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.042731\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.052138\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.039035\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.042129\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.053152\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 34 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.035221\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.041738\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.044081\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.048295\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.039186\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0832 (val)\n",
            "Epoch 35 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.044063\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.044146\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.033818\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.032095\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.046945\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 36 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.046922\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.043914\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.035629\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.043216\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.038803\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0834 (val)\n",
            "Epoch 37 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.050539\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.047068\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.048542\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.048110\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.045534\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0428 (train) | 0.0831 (val)\n",
            "Epoch 38 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.041873\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.047027\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.032932\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.048052\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.038703\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0427 (train) | 0.0831 (val)\n",
            "Epoch 39 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.050836\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.057672\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.045757\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.043870\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.032678\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0425 (train) | 0.0833 (val)\n",
            "Epoch 40 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.035119\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.041785\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.031823\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.054620\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.029502\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0833 (val)\n",
            "Epoch 41 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [0/1453 (0%)]\tLoss: 0.045594\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [320/1453 (22%)]\tLoss: 0.039608\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [640/1453 (43%)]\tLoss: 0.028914\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [960/1453 (65%)]\tLoss: 0.058077\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [1280/1453 (87%)]\tLoss: 0.037776\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 41\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 41 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n",
            "Epoch 42 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [0/1453 (0%)]\tLoss: 0.039121\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [320/1453 (22%)]\tLoss: 0.032340\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [640/1453 (43%)]\tLoss: 0.044056\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [960/1453 (65%)]\tLoss: 0.042237\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [1280/1453 (87%)]\tLoss: 0.039941\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 42\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 42 \tAverage loss: 0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0426 (train) | 0.0832 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.050928885100508095,\n",
              "   0.04760130350231222,\n",
              "   0.048704312500240717,\n",
              "   0.04719368192249959,\n",
              "   0.04717479251884052,\n",
              "   0.048234398820977825,\n",
              "   0.04511258626293906,\n",
              "   0.04409068543399849,\n",
              "   0.043632390035261225,\n",
              "   0.043418252993187904,\n",
              "   0.043398848312399915,\n",
              "   0.043243282820057724,\n",
              "   0.04289464375641292,\n",
              "   0.04268944600605998,\n",
              "   0.04270544793285014,\n",
              "   0.04270745898197621,\n",
              "   0.042767661603786825,\n",
              "   0.042630105815873995,\n",
              "   0.042594687719633886,\n",
              "   0.042592354341879926,\n",
              "   0.042607933755884564,\n",
              "   0.04261687967646803,\n",
              "   0.042732277019776235,\n",
              "   0.04276834208843877,\n",
              "   0.04263627419923801,\n",
              "   0.042654561364724564,\n",
              "   0.04270758696736259,\n",
              "   0.04263419746398844,\n",
              "   0.04260668627205013,\n",
              "   0.042779213962313725,\n",
              "   0.042664748862006295,\n",
              "   0.042594241344992324,\n",
              "   0.04271932990794664,\n",
              "   0.042668537207906684,\n",
              "   0.04255306101048395,\n",
              "   0.04255671747392896,\n",
              "   0.042751064240747864,\n",
              "   0.04274474886865839,\n",
              "   0.042542430883079914,\n",
              "   0.04256856764544312,\n",
              "   0.04263048148306993,\n",
              "   0.04261904917734291]},\n",
              " 'val': {'loss': [0.09575276325146358,\n",
              "   0.09454840173323949,\n",
              "   0.09379288305838902,\n",
              "   0.10545267413059871,\n",
              "   0.09028033912181854,\n",
              "   0.09175146371126175,\n",
              "   0.08666990200678508,\n",
              "   0.08579191317160924,\n",
              "   0.08552441497643788,\n",
              "   0.08426832904418309,\n",
              "   0.08385421832402547,\n",
              "   0.08421310534079869,\n",
              "   0.08361809452374776,\n",
              "   0.08345964550971985,\n",
              "   0.08336548258860906,\n",
              "   0.0833972841501236,\n",
              "   0.08330785483121872,\n",
              "   0.08327536284923553,\n",
              "   0.08319810529549916,\n",
              "   0.08330588539441426,\n",
              "   0.08327794075012207,\n",
              "   0.08319247514009476,\n",
              "   0.0831701507170995,\n",
              "   0.08334362010161082,\n",
              "   0.08327304571866989,\n",
              "   0.08323115358750026,\n",
              "   0.08320402105649312,\n",
              "   0.08316775411367416,\n",
              "   0.08341512580712636,\n",
              "   0.08328910668690999,\n",
              "   0.08321021248896916,\n",
              "   0.0832121695081393,\n",
              "   0.08320437123378117,\n",
              "   0.08319972455501556,\n",
              "   0.083233709136645,\n",
              "   0.08336166789134343,\n",
              "   0.08314037322998047,\n",
              "   0.08311191697915395,\n",
              "   0.08333371082941692,\n",
              "   0.08326634516318639,\n",
              "   0.08317262182633083,\n",
              "   0.08323124299446742]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "2bd5ff6c-f742-45e8-c24f-64142d8aa3bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "fb1a716e-67c2-426c-993a-9a6b4a115c18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "fc9b9a2a-c035-48ed-9111-e9b9ce146bec",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_28/unetv21.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_38/unetv22.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "32f6230c-3382-433d-9860-bc7bd3626339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:27<00:00, 22.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1090\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv19')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}