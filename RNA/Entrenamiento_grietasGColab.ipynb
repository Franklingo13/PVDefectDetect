{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "2dca7389-68a6-4749-a851-7f566f3abc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "e1550715-e8e1-4a72-bdab-0d1e8b09e5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "b74f50ec-8161-46c3-9392-00755926c685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "#transformers = Compose([transforms.RandomRotation(degrees=30), FixResize(256), ToTensor(), Normalize()])\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "5e90deeb-3a89-410c-9285-17ec915921e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=6, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "30060c78-9c09-4429-af79-d225c8a89417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/unetv22.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "00c00111-eb1c-4470-d512-ffc1d390eebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=42,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv23.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "cd0e389c-0003-4b8a-9513-d8f1877427a7",
        "collapsed": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 42\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.036280\n",
            " 22%|██▏       | 10/46 [00:20<00:45,  1.26s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.062527\n",
            " 43%|████▎     | 20/46 [00:32<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.052048\n",
            " 65%|██████▌   | 30/46 [00:44<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.043096\n",
            " 87%|████████▋ | 40/46 [00:55<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.049710\n",
            "100%|██████████| 46/46 [01:03<00:00,  1.37s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0917\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0486 (train) | 0.0917 (val)\n",
            "Epoch 2 / 42\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.043174\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.14s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.051762\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.032386\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.043134\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.042010\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0460 (train) | 0.0886 (val)\n",
            "Epoch 3 / 42\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.050661\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.040103\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.036942\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.057876\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.055444\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0931\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0477 (train) | 0.0931 (val)\n",
            "Epoch 4 / 42\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.047087\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.039061\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.043214\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.046021\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.045060\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0475 (train) | 0.0874 (val)\n",
            "Epoch 5 / 42\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.043058\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.033002\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.050602\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.049084\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.046762\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0873\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0465 (train) | 0.0873 (val)\n",
            "Epoch 6 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.028499\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.041892\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.051269\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.044571\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.048033\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0450 (train) | 0.0898 (val)\n",
            "Epoch 7 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.045569\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.044355\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.051822\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.039648\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.044193\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0429 (train) | 0.0821 (val)\n",
            "Epoch 8 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.047576\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.037101\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.043380\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.050903\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.040665\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0423 (train) | 0.0814 (val)\n",
            "Epoch 9 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.048498\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.038407\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.038908\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.038021\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.027847\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0418 (train) | 0.0811 (val)\n",
            "Epoch 10 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.035169\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.054716\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.036580\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.032517\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.035843\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0417 (train) | 0.0807 (val)\n",
            "Epoch 11 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.040173\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.047620\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.045288\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.047192\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.040349\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0417 (train) | 0.0801 (val)\n",
            "Epoch 12 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.049161\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.048333\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.049384\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.044222\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.042764\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0416 (train) | 0.0803 (val)\n",
            "Epoch 13 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.040165\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.043602\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.035813\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.041352\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.035085\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0413 (train) | 0.0800 (val)\n",
            "Epoch 14 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.040692\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.040017\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.040971\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.028812\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.036883\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0799 (val)\n",
            "Epoch 15 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.035463\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.042851\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.046822\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.042120\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.054633\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0413 (train) | 0.0798 (val)\n",
            "Epoch 16 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.038385\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.054937\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.035226\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.036181\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.056248\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0799 (val)\n",
            "Epoch 17 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.034777\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.037883\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.049338\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.045896\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.044956\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0797 (val)\n",
            "Epoch 18 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.041898\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.029167\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.044930\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.034820\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.054755\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0799 (val)\n",
            "Epoch 19 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.035079\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.036582\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.042289\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.049869\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.050320\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0798 (val)\n",
            "Epoch 20 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.039083\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.032464\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.042950\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.044241\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.039455\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0798 (val)\n",
            "Epoch 21 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.032557\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.046055\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.039195\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.039503\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.040878\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0797 (val)\n",
            "Epoch 22 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.043100\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.034716\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.040232\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.044750\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.049021\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0797 (val)\n",
            "Epoch 23 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.045039\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.034604\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.038436\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.035337\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.044966\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0796 (val)\n",
            "Epoch 24 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.034101\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.048094\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.028877\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.034030\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.046308\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0797 (val)\n",
            "Epoch 25 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.039394\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.052056\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.035554\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.032042\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.039292\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0798 (val)\n",
            "Epoch 26 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.042560\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.048527\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.042037\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.028925\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.043237\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0796 (val)\n",
            "Epoch 27 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.027283\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.038078\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.043764\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.036972\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.032197\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0798 (val)\n",
            "Epoch 28 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.045092\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.032005\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.046385\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.040532\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.039938\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0798 (val)\n",
            "Epoch 29 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.044289\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.036858\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.050193\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.048840\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.039096\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0798 (val)\n",
            "Epoch 30 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.042728\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.045215\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.048630\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.047195\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.043119\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0409 (train) | 0.0796 (val)\n",
            "Epoch 31 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.040381\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.043949\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.039003\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.031012\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.044154\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0797 (val)\n",
            "Epoch 32 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.045367\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.047506\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.053088\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.041695\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.045814\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0798 (val)\n",
            "Epoch 33 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.048548\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.045781\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.034565\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.033087\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.031656\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0409 (train) | 0.0797 (val)\n",
            "Epoch 34 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.040982\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.045461\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.042222\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.046416\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.046479\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0796 (val)\n",
            "Epoch 35 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.040031\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.036354\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.041460\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.022945\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.040113\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0797 (val)\n",
            "Epoch 36 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [0/1453 (0%)]\tLoss: 0.036161\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [320/1453 (22%)]\tLoss: 0.049016\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [640/1453 (43%)]\tLoss: 0.048651\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [960/1453 (65%)]\tLoss: 0.027460\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 36 [1280/1453 (87%)]\tLoss: 0.049067\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 36\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 36 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0797 (val)\n",
            "Epoch 37 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [0/1453 (0%)]\tLoss: 0.043744\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [320/1453 (22%)]\tLoss: 0.033178\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [640/1453 (43%)]\tLoss: 0.052045\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [960/1453 (65%)]\tLoss: 0.029444\n",
            " 87%|████████▋ | 40/46 [00:47<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 37 [1280/1453 (87%)]\tLoss: 0.037579\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 37\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 37 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0797 (val)\n",
            "Epoch 38 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [0/1453 (0%)]\tLoss: 0.039788\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [320/1453 (22%)]\tLoss: 0.044718\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [640/1453 (43%)]\tLoss: 0.039681\n",
            " 65%|██████▌   | 30/46 [00:34<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [960/1453 (65%)]\tLoss: 0.041768\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 38 [1280/1453 (87%)]\tLoss: 0.041217\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 38\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 38 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0411 (train) | 0.0798 (val)\n",
            "Epoch 39 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [0/1453 (0%)]\tLoss: 0.048059\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [320/1453 (22%)]\tLoss: 0.056456\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [640/1453 (43%)]\tLoss: 0.062033\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [960/1453 (65%)]\tLoss: 0.031606\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 39 [1280/1453 (87%)]\tLoss: 0.030088\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 39\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 39 \tAverage loss: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0412 (train) | 0.0798 (val)\n",
            "Epoch 40 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [0/1453 (0%)]\tLoss: 0.043905\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [320/1453 (22%)]\tLoss: 0.063683\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [640/1453 (43%)]\tLoss: 0.024152\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [960/1453 (65%)]\tLoss: 0.044275\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 40 [1280/1453 (87%)]\tLoss: 0.057442\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 40\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 40 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0797 (val)\n",
            "Epoch 41 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [0/1453 (0%)]\tLoss: 0.042872\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [320/1453 (22%)]\tLoss: 0.039995\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [640/1453 (43%)]\tLoss: 0.038742\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [960/1453 (65%)]\tLoss: 0.036195\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 41 [1280/1453 (87%)]\tLoss: 0.032423\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 41\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 41 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0797 (val)\n",
            "Epoch 42 / 42\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [0/1453 (0%)]\tLoss: 0.042040\n",
            " 22%|██▏       | 10/46 [00:11<00:41,  1.15s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [320/1453 (22%)]\tLoss: 0.037277\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [640/1453 (43%)]\tLoss: 0.038535\n",
            " 65%|██████▌   | 30/46 [00:35<00:18,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [960/1453 (65%)]\tLoss: 0.039130\n",
            " 87%|████████▋ | 40/46 [00:46<00:06,  1.16s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 42 [1280/1453 (87%)]\tLoss: 0.043649\n",
            "100%|██████████| 46/46 [00:53<00:00,  1.17s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 42\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 42 \tAverage loss: 0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0410 (train) | 0.0797 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.048623912338954536,\n",
              "   0.046001487287852326,\n",
              "   0.047733136887949904,\n",
              "   0.047475682185669235,\n",
              "   0.04648127044818357,\n",
              "   0.045031913565773025,\n",
              "   0.042861757990990686,\n",
              "   0.042262904348553086,\n",
              "   0.0417947657149944,\n",
              "   0.041695357179198686,\n",
              "   0.04171329892335968,\n",
              "   0.04155628388543746,\n",
              "   0.04129416487870016,\n",
              "   0.04107516246135696,\n",
              "   0.041266107312560654,\n",
              "   0.04112187269959709,\n",
              "   0.04102434651735152,\n",
              "   0.04109605388935073,\n",
              "   0.04097287706820536,\n",
              "   0.04110678822232868,\n",
              "   0.040958517584219034,\n",
              "   0.041050762179098046,\n",
              "   0.040975030853893125,\n",
              "   0.04117087204540014,\n",
              "   0.041058823302213845,\n",
              "   0.041106866261135355,\n",
              "   0.041156789543028954,\n",
              "   0.04100755173443763,\n",
              "   0.041095523003434935,\n",
              "   0.04094565856922354,\n",
              "   0.04105677093646482,\n",
              "   0.041092548055314065,\n",
              "   0.04094101410392474,\n",
              "   0.041076600854140846,\n",
              "   0.04118611663836327,\n",
              "   0.04122849709962617,\n",
              "   0.04121119880257847,\n",
              "   0.04106252506139438,\n",
              "   0.04118868165071964,\n",
              "   0.041003779628033976,\n",
              "   0.04100529450079694,\n",
              "   0.04098020351177155]},\n",
              " 'val': {'loss': [0.09171258906523387,\n",
              "   0.08863407125075658,\n",
              "   0.09309987723827362,\n",
              "   0.08743981023629506,\n",
              "   0.08731190860271454,\n",
              "   0.08976935843626659,\n",
              "   0.08213720470666885,\n",
              "   0.08142667512098949,\n",
              "   0.08107278496026993,\n",
              "   0.08068427195151646,\n",
              "   0.08011914292971294,\n",
              "   0.08028536289930344,\n",
              "   0.07999335477749507,\n",
              "   0.07989779611428578,\n",
              "   0.07983067631721497,\n",
              "   0.07989109059174855,\n",
              "   0.07968095690011978,\n",
              "   0.079876609146595,\n",
              "   0.07978904495636623,\n",
              "   0.0797540694475174,\n",
              "   0.079742598036925,\n",
              "   0.07974045972029369,\n",
              "   0.07964262614647548,\n",
              "   0.07974155247211456,\n",
              "   0.07981881002585094,\n",
              "   0.07964127510786057,\n",
              "   0.0797559122244517,\n",
              "   0.07975773513317108,\n",
              "   0.07978644967079163,\n",
              "   0.07964720577001572,\n",
              "   0.07974204421043396,\n",
              "   0.07981111109256744,\n",
              "   0.07971688359975815,\n",
              "   0.07962621251742046,\n",
              "   0.07972398151954015,\n",
              "   0.07974231243133545,\n",
              "   0.07968210428953171,\n",
              "   0.07979914297660191,\n",
              "   0.07977252701918285,\n",
              "   0.07972074300050735,\n",
              "   0.07974965373675029,\n",
              "   0.07974530508120854]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "13921516-b1e4-472e-da97-1875eb0ec027"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "bf03b610-29ae-47da-95ae-a5ff84e5c374"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "fc9b9a2a-c035-48ed-9111-e9b9ce146bec",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_28/unetv21.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_34/unetv23.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "32f6230c-3382-433d-9860-bc7bd3626339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:27<00:00, 22.25s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1090\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv23')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}