{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "238839ea-6492-4f12-b0e3-892036756537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CffxGlC2G09S",
        "outputId": "fef38e2b-af26-49bf-9452-2d7b7d1d85e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.1.0)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "042d0a13-5546-4b8f-c65d-cd31325e9e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1012 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/images\",\n",
        "        mask_folder=\"train/annotations\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida. \n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel. \n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "27d1baba-45ae-475b-8ef9-3160bfd47b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "0b8243b5-e827-412e-bfbc-530ce53ac11b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    model=model,\n",
        "    #model = unet,\n",
        "\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    model_output='out',\n",
        "\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=10,\n",
        "\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/deeplab.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "dffb47b3-43ee-48b9-ac9d-6691de51aac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1012 (0%)]\tLoss: 1.511699\n",
            " 31%|███▏      | 10/32 [00:27<00:53,  2.44s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1012 (31%)]\tLoss: 0.291932\n",
            " 62%|██████▎   | 20/32 [00:51<00:28,  2.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1012 (62%)]\tLoss: 0.264256\n",
            " 94%|█████████▍| 30/32 [01:14<00:04,  2.30s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1012 (94%)]\tLoss: 0.252998\n",
            "100%|██████████| 32/32 [01:19<00:00,  2.48s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 5/5 [02:07<00:00, 25.54s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 111.4832\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.3783 (train) | 111.4832 (val)\n",
            "Epoch 2 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1012 (0%)]\tLoss: 0.223159\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1012 (31%)]\tLoss: 0.173876\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.37s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1012 (62%)]\tLoss: 0.162585\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.32s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1012 (94%)]\tLoss: 0.136119\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.6289\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1649 (train) | 0.6289 (val)\n",
            "Epoch 3 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1012 (0%)]\tLoss: 0.114521\n",
            " 31%|███▏      | 10/32 [00:22<00:50,  2.31s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1012 (31%)]\tLoss: 0.169463\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1012 (62%)]\tLoss: 0.120429\n",
            " 94%|█████████▍| 30/32 [01:09<00:04,  2.33s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1012 (94%)]\tLoss: 0.100510\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.33s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.6987\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1306 (train) | 0.6987 (val)\n",
            "Epoch 4 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1012 (0%)]\tLoss: 0.097433\n",
            " 31%|███▏      | 10/32 [00:22<00:50,  2.31s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1012 (31%)]\tLoss: 0.091950\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1012 (62%)]\tLoss: 0.079243\n",
            " 94%|█████████▍| 30/32 [01:09<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1012 (94%)]\tLoss: 0.099962\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.33s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.7137\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1096 (train) | 0.7137 (val)\n",
            "Epoch 5 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1012 (0%)]\tLoss: 0.100738\n",
            " 31%|███▏      | 10/32 [00:22<00:50,  2.32s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1012 (31%)]\tLoss: 0.098369\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1012 (62%)]\tLoss: 0.111509\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1012 (94%)]\tLoss: 0.091523\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.5641\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1003 (train) | 0.5641 (val)\n",
            "Epoch 6 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1012 (0%)]\tLoss: 0.086387\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.32s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1012 (31%)]\tLoss: 0.125625\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1012 (62%)]\tLoss: 0.089156\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1012 (94%)]\tLoss: 0.084781\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.4972\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0928 (train) | 0.4972 (val)\n",
            "Epoch 7 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1012 (0%)]\tLoss: 0.082002\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.32s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1012 (31%)]\tLoss: 0.071333\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1012 (62%)]\tLoss: 0.099527\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1012 (94%)]\tLoss: 0.088707\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.5285\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0895 (train) | 0.5285 (val)\n",
            "Epoch 8 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1012 (0%)]\tLoss: 0.094246\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.33s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1012 (31%)]\tLoss: 0.086489\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1012 (62%)]\tLoss: 0.090832\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.35s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1012 (94%)]\tLoss: 0.085356\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.5870\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0885 (train) | 0.5870 (val)\n",
            "Epoch 9 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1012 (0%)]\tLoss: 0.102583\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.32s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1012 (31%)]\tLoss: 0.069011\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1012 (62%)]\tLoss: 0.097902\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1012 (94%)]\tLoss: 0.084939\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.4963\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0875 (train) | 0.4963 (val)\n",
            "Epoch 10 / 10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/32 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1012 (0%)]\tLoss: 0.078549\n",
            " 31%|███▏      | 10/32 [00:22<00:51,  2.33s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1012 (31%)]\tLoss: 0.089224\n",
            " 62%|██████▎   | 20/32 [00:46<00:28,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1012 (62%)]\tLoss: 0.087580\n",
            " 94%|█████████▍| 30/32 [01:10<00:04,  2.34s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1012 (94%)]\tLoss: 0.094776\n",
            "100%|██████████| 32/32 [01:14<00:00,  2.34s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.5313\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0842 (train) | 0.5313 (val)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.3782583598798443,\n",
              "   0.16494650331881677,\n",
              "   0.13056544591433447,\n",
              "   0.10956556762277844,\n",
              "   0.10028134943114911,\n",
              "   0.0927873694672886,\n",
              "   0.08946803391804337,\n",
              "   0.0884781297841091,\n",
              "   0.08754022490130112,\n",
              "   0.08418355469882724]},\n",
              " 'val': {'loss': [111.48318314090852,\n",
              "   0.6289276903675448,\n",
              "   0.6987484693527222,\n",
              "   0.7136992989047881,\n",
              "   0.5641312341536245,\n",
              "   0.4972194738926426,\n",
              "   0.5285360715081615,\n",
              "   0.5870297008945096,\n",
              "   0.4963371607565111,\n",
              "   0.5312513086103624]}}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "c9d643b6-195c-45d3-cd95-84e6f25533b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "4c0dee9c-5f66-445f-a913-4819de9fb08c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "520af2c4-74e6-4ec6-dea6-999bdd964973"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/deeplab.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/deeplab.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "11fcd4ad-e495-4f81-9434-499fce2ebab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [04:26<00:00, 24.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 1.1086\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.1086\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
