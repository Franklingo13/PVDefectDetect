{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "6f838aff-2157-45d2-a668-3ace1b6ca42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "1063671a-610e-45d4-aa7f-92dc1de35c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "256cea06-7a04-4e10-e5c9-567ede77b633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1453 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "# root = Path(\n",
        "#     '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/img\",\n",
        "        mask_folder=\"val/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "255df7fc-9121-4fc6-bd0a-8c37109a04eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.0001)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qouTmOWmA8ng",
        "outputId": "f03043f0-3405-460c-a726-11f4a94e08c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Entrenamiento/Copia de unetv14.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "4c28f982-aa43-49f2-b764-9a0de54cb39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=32,\n",
        "    batch_size_val=32,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=35,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Entrenamiento/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv15.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "67baa712-6093-4601-c6e8-718b38ac3aab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1453 (0%)]\tLoss: 0.043705\n",
            " 22%|██▏       | 10/46 [00:20<00:45,  1.26s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1453 (22%)]\tLoss: 0.041891\n",
            " 43%|████▎     | 20/46 [00:32<00:30,  1.17s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1453 (43%)]\tLoss: 0.050742\n",
            " 65%|██████▌   | 30/46 [00:44<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1453 (65%)]\tLoss: 0.047964\n",
            " 87%|████████▋ | 40/46 [00:56<00:07,  1.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [1280/1453 (87%)]\tLoss: 0.047138\n",
            "100%|██████████| 46/46 [01:04<00:00,  1.39s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 0.0903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0469 (train) | 0.0903 (val)\n",
            "Epoch 2 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1453 (0%)]\tLoss: 0.082118\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1453 (22%)]\tLoss: 0.047747\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1453 (43%)]\tLoss: 0.052832\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1453 (65%)]\tLoss: 0.047631\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [1280/1453 (87%)]\tLoss: 0.052037\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.0901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0468 (train) | 0.0901 (val)\n",
            "Epoch 3 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1453 (0%)]\tLoss: 0.045678\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1453 (22%)]\tLoss: 0.042256\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1453 (43%)]\tLoss: 0.026118\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1453 (65%)]\tLoss: 0.060245\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [1280/1453 (87%)]\tLoss: 0.038717\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.0900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0464 (train) | 0.0900 (val)\n",
            "Epoch 4 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1453 (0%)]\tLoss: 0.038021\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1453 (22%)]\tLoss: 0.056904\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1453 (43%)]\tLoss: 0.040815\n",
            " 65%|██████▌   | 30/46 [00:35<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1453 (65%)]\tLoss: 0.032682\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [1280/1453 (87%)]\tLoss: 0.038664\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.0895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0463 (train) | 0.0895 (val)\n",
            "Epoch 5 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1453 (0%)]\tLoss: 0.056824\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1453 (22%)]\tLoss: 0.047730\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1453 (43%)]\tLoss: 0.049431\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1453 (65%)]\tLoss: 0.061507\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [1280/1453 (87%)]\tLoss: 0.029859\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.0892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0461 (train) | 0.0892 (val)\n",
            "Epoch 6 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1453 (0%)]\tLoss: 0.063601\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1453 (22%)]\tLoss: 0.053743\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1453 (43%)]\tLoss: 0.058774\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1453 (65%)]\tLoss: 0.045532\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [1280/1453 (87%)]\tLoss: 0.038088\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.0889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0462 (train) | 0.0889 (val)\n",
            "Epoch 7 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1453 (0%)]\tLoss: 0.048514\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1453 (22%)]\tLoss: 0.036919\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1453 (43%)]\tLoss: 0.044010\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1453 (65%)]\tLoss: 0.047964\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [1280/1453 (87%)]\tLoss: 0.052147\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.20s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0461 (train) | 0.0888 (val)\n",
            "Epoch 8 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1453 (0%)]\tLoss: 0.038032\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1453 (22%)]\tLoss: 0.061177\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1453 (43%)]\tLoss: 0.033079\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1453 (65%)]\tLoss: 0.042628\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [1280/1453 (87%)]\tLoss: 0.037313\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.0890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0890 (val)\n",
            "Epoch 9 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1453 (0%)]\tLoss: 0.040991\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1453 (22%)]\tLoss: 0.044540\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1453 (43%)]\tLoss: 0.040556\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1453 (65%)]\tLoss: 0.043230\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [1280/1453 (87%)]\tLoss: 0.037684\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0888 (val)\n",
            "Epoch 10 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1453 (0%)]\tLoss: 0.030198\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1453 (22%)]\tLoss: 0.056167\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1453 (43%)]\tLoss: 0.046166\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1453 (65%)]\tLoss: 0.036764\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [1280/1453 (87%)]\tLoss: 0.047934\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0886 (val)\n",
            "Epoch 11 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1453 (0%)]\tLoss: 0.038939\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1453 (22%)]\tLoss: 0.049973\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1453 (43%)]\tLoss: 0.031468\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1453 (65%)]\tLoss: 0.044426\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [1280/1453 (87%)]\tLoss: 0.040143\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0888 (val)\n",
            "Epoch 12 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1453 (0%)]\tLoss: 0.046869\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1453 (22%)]\tLoss: 0.045496\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1453 (43%)]\tLoss: 0.042062\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1453 (65%)]\tLoss: 0.045267\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [1280/1453 (87%)]\tLoss: 0.061485\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0888 (val)\n",
            "Epoch 13 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1453 (0%)]\tLoss: 0.044126\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1453 (22%)]\tLoss: 0.058495\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1453 (43%)]\tLoss: 0.041151\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1453 (65%)]\tLoss: 0.041994\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [1280/1453 (87%)]\tLoss: 0.028177\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0887 (val)\n",
            "Epoch 14 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1453 (0%)]\tLoss: 0.043350\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1453 (22%)]\tLoss: 0.039915\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1453 (43%)]\tLoss: 0.060523\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1453 (65%)]\tLoss: 0.040729\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [1280/1453 (87%)]\tLoss: 0.041845\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0887 (val)\n",
            "Epoch 15 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1453 (0%)]\tLoss: 0.041073\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1453 (22%)]\tLoss: 0.043051\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1453 (43%)]\tLoss: 0.038293\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1453 (65%)]\tLoss: 0.050178\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [1280/1453 (87%)]\tLoss: 0.046292\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0888 (val)\n",
            "Epoch 16 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [0/1453 (0%)]\tLoss: 0.070452\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [320/1453 (22%)]\tLoss: 0.041753\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [640/1453 (43%)]\tLoss: 0.042965\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [960/1453 (65%)]\tLoss: 0.047948\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 16 [1280/1453 (87%)]\tLoss: 0.043643\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 16\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 16 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0886 (val)\n",
            "Epoch 17 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [0/1453 (0%)]\tLoss: 0.057811\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [320/1453 (22%)]\tLoss: 0.048737\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [640/1453 (43%)]\tLoss: 0.039511\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [960/1453 (65%)]\tLoss: 0.051540\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 17 [1280/1453 (87%)]\tLoss: 0.032679\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 17\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 17 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0887 (val)\n",
            "Epoch 18 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [0/1453 (0%)]\tLoss: 0.034274\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [320/1453 (22%)]\tLoss: 0.043788\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [640/1453 (43%)]\tLoss: 0.049191\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [960/1453 (65%)]\tLoss: 0.047311\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 18 [1280/1453 (87%)]\tLoss: 0.054617\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 18\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 18 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0886 (val)\n",
            "Epoch 19 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [0/1453 (0%)]\tLoss: 0.047580\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [320/1453 (22%)]\tLoss: 0.044703\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [640/1453 (43%)]\tLoss: 0.041271\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [960/1453 (65%)]\tLoss: 0.045518\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 19 [1280/1453 (87%)]\tLoss: 0.039339\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 19\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 19 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0887 (val)\n",
            "Epoch 20 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [0/1453 (0%)]\tLoss: 0.050746\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [320/1453 (22%)]\tLoss: 0.049615\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [640/1453 (43%)]\tLoss: 0.043147\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [960/1453 (65%)]\tLoss: 0.040955\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 20 [1280/1453 (87%)]\tLoss: 0.042620\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 20\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 20 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0457 (train) | 0.0886 (val)\n",
            "Epoch 21 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [0/1453 (0%)]\tLoss: 0.047413\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [320/1453 (22%)]\tLoss: 0.048773\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [640/1453 (43%)]\tLoss: 0.053051\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [960/1453 (65%)]\tLoss: 0.033417\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 21 [1280/1453 (87%)]\tLoss: 0.046779\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 21\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 21 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0886 (val)\n",
            "Epoch 22 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [0/1453 (0%)]\tLoss: 0.041897\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [320/1453 (22%)]\tLoss: 0.049477\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [640/1453 (43%)]\tLoss: 0.053633\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [960/1453 (65%)]\tLoss: 0.035160\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 22 [1280/1453 (87%)]\tLoss: 0.039713\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 22\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 22 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0888 (val)\n",
            "Epoch 23 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [0/1453 (0%)]\tLoss: 0.048587\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [320/1453 (22%)]\tLoss: 0.044948\n",
            " 43%|████▎     | 20/46 [00:23<00:30,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [640/1453 (43%)]\tLoss: 0.042787\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [960/1453 (65%)]\tLoss: 0.045589\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 23 [1280/1453 (87%)]\tLoss: 0.032927\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 23\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 23 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0887 (val)\n",
            "Epoch 24 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [0/1453 (0%)]\tLoss: 0.053001\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [320/1453 (22%)]\tLoss: 0.053236\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [640/1453 (43%)]\tLoss: 0.038122\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [960/1453 (65%)]\tLoss: 0.052244\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 24 [1280/1453 (87%)]\tLoss: 0.041911\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 24\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 24 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0456 (train) | 0.0887 (val)\n",
            "Epoch 25 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [0/1453 (0%)]\tLoss: 0.060009\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [320/1453 (22%)]\tLoss: 0.055247\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [640/1453 (43%)]\tLoss: 0.043369\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [960/1453 (65%)]\tLoss: 0.049907\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 25 [1280/1453 (87%)]\tLoss: 0.035410\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 25\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 25 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0886 (val)\n",
            "Epoch 26 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [0/1453 (0%)]\tLoss: 0.037782\n",
            " 22%|██▏       | 10/46 [00:11<00:43,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [320/1453 (22%)]\tLoss: 0.038426\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [640/1453 (43%)]\tLoss: 0.032058\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [960/1453 (65%)]\tLoss: 0.048112\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 26 [1280/1453 (87%)]\tLoss: 0.062573\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 26\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 26 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0457 (train) | 0.0888 (val)\n",
            "Epoch 27 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [0/1453 (0%)]\tLoss: 0.061492\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [320/1453 (22%)]\tLoss: 0.044886\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [640/1453 (43%)]\tLoss: 0.047864\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [960/1453 (65%)]\tLoss: 0.034090\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 27 [1280/1453 (87%)]\tLoss: 0.050125\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 27\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 27 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0457 (train) | 0.0887 (val)\n",
            "Epoch 28 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [0/1453 (0%)]\tLoss: 0.046342\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [320/1453 (22%)]\tLoss: 0.054636\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [640/1453 (43%)]\tLoss: 0.035177\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [960/1453 (65%)]\tLoss: 0.040486\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 28 [1280/1453 (87%)]\tLoss: 0.046809\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 28\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 28 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0888 (val)\n",
            "Epoch 29 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [0/1453 (0%)]\tLoss: 0.057946\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [320/1453 (22%)]\tLoss: 0.047961\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [640/1453 (43%)]\tLoss: 0.044618\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [960/1453 (65%)]\tLoss: 0.040903\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 29 [1280/1453 (87%)]\tLoss: 0.047586\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 29\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 29 \tAverage loss: 0.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0457 (train) | 0.0886 (val)\n",
            "Epoch 30 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [0/1453 (0%)]\tLoss: 0.044669\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [320/1453 (22%)]\tLoss: 0.042001\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [640/1453 (43%)]\tLoss: 0.040656\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [960/1453 (65%)]\tLoss: 0.055641\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 30 [1280/1453 (87%)]\tLoss: 0.053398\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 30\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 30 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0887 (val)\n",
            "Epoch 31 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [0/1453 (0%)]\tLoss: 0.044074\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.18s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [320/1453 (22%)]\tLoss: 0.032305\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [640/1453 (43%)]\tLoss: 0.042346\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [960/1453 (65%)]\tLoss: 0.038371\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 31 [1280/1453 (87%)]\tLoss: 0.045942\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 31\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 31 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0887 (val)\n",
            "Epoch 32 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [0/1453 (0%)]\tLoss: 0.059785\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [320/1453 (22%)]\tLoss: 0.049806\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [640/1453 (43%)]\tLoss: 0.050382\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [960/1453 (65%)]\tLoss: 0.080799\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 32 [1280/1453 (87%)]\tLoss: 0.048332\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 32\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 32 \tAverage loss: 0.0889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0459 (train) | 0.0889 (val)\n",
            "Epoch 33 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [0/1453 (0%)]\tLoss: 0.044200\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [320/1453 (22%)]\tLoss: 0.056356\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [640/1453 (43%)]\tLoss: 0.042726\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [960/1453 (65%)]\tLoss: 0.060902\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 33 [1280/1453 (87%)]\tLoss: 0.045999\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 33\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 33 \tAverage loss: 0.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0888 (val)\n",
            "Epoch 34 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [0/1453 (0%)]\tLoss: 0.032347\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [320/1453 (22%)]\tLoss: 0.051429\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [640/1453 (43%)]\tLoss: 0.041433\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.21s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [960/1453 (65%)]\tLoss: 0.052658\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 34 [1280/1453 (87%)]\tLoss: 0.060711\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 34\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 34 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0457 (train) | 0.0887 (val)\n",
            "Epoch 35 / 35\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/46 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [0/1453 (0%)]\tLoss: 0.043583\n",
            " 22%|██▏       | 10/46 [00:11<00:42,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [320/1453 (22%)]\tLoss: 0.044890\n",
            " 43%|████▎     | 20/46 [00:23<00:31,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [640/1453 (43%)]\tLoss: 0.039677\n",
            " 65%|██████▌   | 30/46 [00:36<00:19,  1.20s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [960/1453 (65%)]\tLoss: 0.042454\n",
            " 87%|████████▋ | 40/46 [00:48<00:07,  1.19s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 35 [1280/1453 (87%)]\tLoss: 0.050199\n",
            "100%|██████████| 46/46 [00:55<00:00,  1.21s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 35\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 35 \tAverage loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0458 (train) | 0.0887 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.04685297049966584,\n",
              "   0.046847795258697277,\n",
              "   0.046404783538986874,\n",
              "   0.04630313036836432,\n",
              "   0.04610951354564344,\n",
              "   0.04618829503368281,\n",
              "   0.04605163900721344,\n",
              "   0.04591700026005281,\n",
              "   0.04561746944990637,\n",
              "   0.04591209251184916,\n",
              "   0.04588270102770511,\n",
              "   0.045795228943762006,\n",
              "   0.04593016558467152,\n",
              "   0.0458595563580025,\n",
              "   0.045822237281760755,\n",
              "   0.04581188514613318,\n",
              "   0.04557210586949701,\n",
              "   0.04563950738790769,\n",
              "   0.04592150795361295,\n",
              "   0.0456939962707301,\n",
              "   0.04580333635098181,\n",
              "   0.0456169470298602,\n",
              "   0.04580053447374621,\n",
              "   0.04564548655062483,\n",
              "   0.04584959125773134,\n",
              "   0.04567482948036581,\n",
              "   0.04568564422628589,\n",
              "   0.04584924536209146,\n",
              "   0.0457002272430733,\n",
              "   0.045863578040909125,\n",
              "   0.045754765739173454,\n",
              "   0.04587459505496563,\n",
              "   0.04578222555646138,\n",
              "   0.045680802761585405,\n",
              "   0.04579646163155355]},\n",
              " 'val': {'loss': [0.0903305634856224,\n",
              "   0.09009532630443573,\n",
              "   0.08995706091324489,\n",
              "   0.08952157696088155,\n",
              "   0.0892355814576149,\n",
              "   0.08889644344647725,\n",
              "   0.08880293369293213,\n",
              "   0.08904011795918147,\n",
              "   0.08875984946886699,\n",
              "   0.08858151982227962,\n",
              "   0.08884311964114507,\n",
              "   0.08879861732323964,\n",
              "   0.08874783664941788,\n",
              "   0.08869397391875584,\n",
              "   0.0887824942668279,\n",
              "   0.0886443555355072,\n",
              "   0.08869959662357967,\n",
              "   0.08863106618324916,\n",
              "   0.08867140859365463,\n",
              "   0.08858756224314372,\n",
              "   0.08859119564294815,\n",
              "   0.08879305670658748,\n",
              "   0.08868750433127086,\n",
              "   0.08865838994582494,\n",
              "   0.08864845832188924,\n",
              "   0.08876257886489232,\n",
              "   0.0887289543946584,\n",
              "   0.0888084148367246,\n",
              "   0.08863430966933568,\n",
              "   0.08874485393365224,\n",
              "   0.08865993718306224,\n",
              "   0.08891940613587697,\n",
              "   0.0887685293952624,\n",
              "   0.08866821726163228,\n",
              "   0.08872733265161514]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k55JhgMyG09V",
        "outputId": "129b1bbe-7ed0-422b-f70d-fc05be758d02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E52bTEXnG09W",
        "outputId": "e28d54a0-b9fe-418d-9786-264938829075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5xVXQyG09W",
        "outputId": "4ac21d98-e347-46fe-9a23-3f58eac0a0ac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Entrenamiento/checkpoints/epoch_10/unetv15.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Entrenamiento/checkpoints/epoch_10/unetv15.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3LEUNaG09W",
        "outputId": "ca76ae45-4464-447f-b578-bb0e75ec0909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [04:05<00:00, 20.48s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1089\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_outputv14')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}