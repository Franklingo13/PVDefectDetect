{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklingo13/PVDefectDetect/blob/main/RNA/Entrenamiento_grietasGColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMYf9fJG09O"
      },
      "source": [
        "Notebook para entrenamiento de redes neuronales convolucionales para clasificación de defectos en imágenes de celdas fotovoltaicas.\n",
        "Pensado para correr en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbQ5zjRCG09Q",
        "outputId": "64994f7a-c372-4332-c11d-cc81a025b649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OhRFEtnDGxpJ"
      },
      "outputs": [],
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "# Copyright (C) 2021 Supervisely\n",
        "#\n",
        "# This file is part of the Supervisely project and has been taken\n",
        "# from the Supervisely repository (https://github.com/supervisely/supervisely/blob/master/plugins/nn/unet_v2/src/unet.py).\n",
        "# It is being redistributed under the Apache License 2.0.\n",
        "#\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "\n",
        "\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels,\n",
        "                      kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.seq(inputs)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, src_channels, dst_channels):\n",
        "        super().__init__()\n",
        "        self.seq1 = ConvBNAct(src_channels, dst_channels)\n",
        "        self.seq2 = ConvBNAct(dst_channels, dst_channels)\n",
        "        self.seq3 = ConvBNAct(dst_channels, dst_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = self.seq1(x)\n",
        "        result = self.seq2(result)\n",
        "        result = self.seq3(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, down_channels,  right_channels):\n",
        "        super().__init__()\n",
        "        self.bottom_up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv = nn.Conv2d(down_channels, right_channels, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, left, bottom):\n",
        "        from_bottom = self.bottom_up(bottom)\n",
        "        from_bottom = self.conv(from_bottom)\n",
        "        result = torch.cat([left, from_bottom], 1)\n",
        "        return result\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), dilation=2, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.conv2(self.relu(out))\n",
        "        out = self.bn2(out)\n",
        "        return torch.cat((x, self.relu2(out)), dim=1)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_blocks,  encoder_channels, n_cls):\n",
        "        self.encoder_channels = encoder_channels\n",
        "        self.depth = len(self.encoder_channels)\n",
        "        assert len(encoder_blocks) == self.depth\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        # add bottleneck\n",
        "        self.blocks.append(Block(\n",
        "            self.encoder_channels[-1],\n",
        "            self.encoder_channels[-1]\n",
        "        ))\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(1, self.depth):\n",
        "            bottom_channels = self.encoder_channels[self.depth - i]\n",
        "            left_channels = self.encoder_channels[self.depth - i - 1]\n",
        "            right_channels = left_channels\n",
        "            self.ups.append(UNetUp(bottom_channels,  right_channels))\n",
        "            self.blocks.append(Block(\n",
        "                left_channels + right_channels,\n",
        "                right_channels\n",
        "            ))\n",
        "        self.last_conv = nn.Conv2d(encoder_channels[0], n_cls, 1)\n",
        "        # self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.bottle = Bottleneck(512, 512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            encoder_outputs.append(x)\n",
        "        x = self.bottle(encoder_outputs[self.depth - 1])\n",
        "        for i in range(self.depth):\n",
        "            if i > 0:\n",
        "                encoder_output = encoder_outputs[self.depth - i - 1]\n",
        "                x = self.ups[i - 1](encoder_output, x)\n",
        "                x = self.blocks[i](x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.last_conv(x)\n",
        "        return x  # no softmax or log_softmax\n",
        "\n",
        "\n",
        "def _get_encoder_blocks(model):\n",
        "    # last modules (ReLUs) of VGG blocks\n",
        "    layers_last_module_names = ['5', '12', '22', '32', '42']\n",
        "    result = []\n",
        "    cur_block = nn.Sequential()\n",
        "    for name, child in model.named_children():\n",
        "        if name == 'features':\n",
        "            for name2, child2 in child.named_children():\n",
        "                cur_block.add_module(name2, child2)\n",
        "                if name2 in layers_last_module_names:\n",
        "                    result.append(cur_block)\n",
        "                    cur_block = nn.Sequential()\n",
        "            break\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def construct_unet(n_cls, pretrain=False):  # no weights inited\n",
        "    model = vgg16_bn(weights='DEFAULT')\n",
        "    encoder_blocks = _get_encoder_blocks(model)\n",
        "    encoder_channels = [64, 128, 256, 512, 1024]  # vgg16 channels\n",
        "    # prev_channels = encoder_channels[-1]\n",
        "\n",
        "    return UNet(encoder_blocks, encoder_channels, n_cls)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_8l2-gnG09S"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import copy\n",
        "#from unet_model import construct_unet\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from imutils.paths import list_images\n",
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-13tOJejCxA",
        "outputId": "a7a1b811-8607-4205-959f-89e6ee10fe3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pv-vision in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imutils>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.5.4)\n",
            "Requirement already satisfied: ipywidgets>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (8.1.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (3.9.1)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.2.0.post100 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.15.2a0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from pv-vision) (4.66.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (4.0.11)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.1.2->pv-vision) (3.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->pv-vision) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->pv-vision) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0.post100->pv-vision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0.post100->pv-vision) (12.5.82)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->pv-vision) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0.post100->pv-vision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0.post100->pv-vision) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->pv-vision) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Importación de la librería de pv-vision\n",
        "!pip install pv-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YVtXGzixG09T"
      },
      "outputs": [],
      "source": [
        "# Importar el manejador de modelo: ModelHandler\n",
        "from pv_vision.nn import ModelHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ia6yr7DDG09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para el conjunto de datos solar,\n",
        "# que hereda de la clase VisionDataset de PyTorch.\n",
        "class SolarDataset(VisionDataset):\n",
        "    \"\"\"Un conjunto de datos que lee directamente las imágenes y las máscaras desde una carpeta.\"\"\"\n",
        "\n",
        "    # Se definió el método de inicialización para la clase.\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 image_folder,\n",
        "                 mask_folder,\n",
        "                 transforms,\n",
        "                 mode = \"train\",\n",
        "                 random_seed=42):\n",
        "        # Se llamó al método de inicialización de la clase padre.\n",
        "        super().__init__(root, transforms)\n",
        "        # Se establecieron las rutas a las carpetas de imágenes y máscaras.\n",
        "        self.image_path = Path(self.root) / image_folder\n",
        "        self.mask_path = Path(self.root) / mask_folder\n",
        "\n",
        "        # Se verificó que las carpetas de imágenes y máscaras existan.\n",
        "        if not os.path.exists(self.image_path):\n",
        "            raise OSError(f\"{self.image_path} no encontrado.\")\n",
        "\n",
        "        if not os.path.exists(self.mask_path):\n",
        "            raise OSError(f\"{self.mask_path} no encontrado.\")\n",
        "\n",
        "        # Se obtuvieron las listas de imágenes y máscaras y se ordenaron.\n",
        "        self.image_list = sorted(list(list_images(self.image_path)))\n",
        "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
        "\n",
        "        # Se convirtieron las listas de imágenes y máscaras a arrays de numpy.\n",
        "        self.image_list = np.array(self.image_list)\n",
        "        self.mask_list = np.array(self.mask_list)\n",
        "\n",
        "        # Se estableció la semilla para la generación de números aleatorios y se mezclaron las imágenes y las máscaras.\n",
        "        np.random.seed(random_seed)\n",
        "        index = np.arange(len(self.image_list))\n",
        "        np.random.shuffle(index)\n",
        "        self.image_list = self.image_list[index]\n",
        "        self.mask_list = self.mask_list[index]\n",
        "\n",
        "    # Se definió el método para obtener la longitud del conjunto de datos.\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    # Se definió un método para obtener el nombre de una imagen o máscara.\n",
        "    def __getname__(self, index):\n",
        "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
        "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
        "\n",
        "        if image_name == mask_name:\n",
        "            return image_name\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Se definió un método para obtener una imagen y su máscara correspondiente.\n",
        "    def __getraw__(self, index):\n",
        "        if not self.__getname__(index):\n",
        "            raise ValueError(\"{}: La imagen no coincide con la máscara\".format(os.path.split(self.image_list[index])[-1]))\n",
        "        image = Image.open(self.image_list[index])\n",
        "        mask = Image.open(self.mask_list[index]).convert('L')\n",
        "        mask = np.array(mask)\n",
        "        mask = Image.fromarray(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    # Se definió el método para obtener un elemento del conjunto de datos.\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.__getraw__(index)\n",
        "        image, mask = self.transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t1nDW9d6G09T"
      },
      "outputs": [],
      "source": [
        "# Definición de una clase para componer varias transformaciones.\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        \"\"\"\n",
        "        transforms: una lista de transformaciones\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "\n",
        "    # Se definió el método para aplicar las transformaciones a la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        \"\"\"\n",
        "        image: imagen de entrada\n",
        "        target: máscara de entrada\n",
        "        \"\"\"\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para redimensionar la imagen y la máscara a un tamaño fijo.\n",
        "class FixResize:\n",
        "    # UNet requiere que el tamaño de entrada sea múltiplo de 16\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    # Se definió el método para redimensionar la imagen y la máscara.\n",
        "    def __call__(self, image, target):\n",
        "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen y la máscara a tensores.\n",
        "class ToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Escala la imagen a [0,1] float32.\n",
        "    Transforma la máscara a tensor.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para transformar la imagen a tensor manteniendo el tipo original.\n",
        "class PILToTensor:\n",
        "    \"\"\"Transforma la imagen a tensor. Mantiene el tipo original.\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = F.pil_to_tensor(image)\n",
        "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
        "        return image, target\n",
        "\n",
        "# Se definió una clase para normalizar la imagen.\n",
        "class Normalize:\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Verifica si la imagen es en escala de grises (1 canal) y la convierte a RGB (3 canales) si es necesario\n",
        "        if image.shape[0] == 1:\n",
        "            image = image.repeat(3, 1, 1)  # Repite el canal existente 3 veces\n",
        "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRAdQ8o1G09U",
        "outputId": "1d201952-5416-45a2-f88c-a2372d379160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos de entrenamiento contiene 1108 elementos.\n"
          ]
        }
      ],
      "source": [
        "# Ruta al directorio que contiene las imágenes y las máscaras.\n",
        "root = Path(\n",
        "    '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento')\n",
        "\n",
        "# Se definen las transformaciones a aplicar a las imágenes y las etiquetas.\n",
        "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/train/annotations\n",
        "#/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/img_label_for_training/train\n",
        "# Se crean los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "trainset = SolarDataset(root, image_folder=\"train/img\",\n",
        "        mask_folder=\"train/ann\", transforms=transformers)\n",
        "\n",
        "valset = SolarDataset(root, image_folder=\"val/val_resize/img\",\n",
        "        mask_folder=\"val/val_resize/ann\", transforms=transformers)\n",
        "\n",
        "testset = SolarDataset(root, image_folder=\"test/img\",\n",
        "        mask_folder=\"test/ann\", transforms=transformers)\n",
        "\n",
        "# Verificación de que la carpeta haya sido establecida correctamente\n",
        "print(f\"El conjunto de datos de entrenamiento contiene {len(trainset)} elementos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YhN5cKIpjCxD"
      },
      "outputs": [],
      "source": [
        "class Accuracy:\n",
        "    \"\"\"Calcular la precisión de un modelo\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"accuracy\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Calcular la precisión.\n",
        "        Argumentos:\n",
        "        -----------\n",
        "        outputs: torch.Tensor\n",
        "        La salida del modelo, forma (batch_size, num_classes, H, W)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        La etiqueta verdadera, forma (batch_size, H, W)\n",
        "\n",
        "        reduction: str\n",
        "        El método de reducción, 'mean' o 'sum'\n",
        "        Si es 'mean', devuelve la precisión media del lote\n",
        "        Si es 'sum', devuelve la suma de predicciones correctas del lote\n",
        "\n",
        "        Retorna:\n",
        "        --------\n",
        "        accuracy: torch.Tensor\n",
        "        \"\"\"\n",
        "        # Asegúrate de que las dimensiones de outputs y targets sean compatibles\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "\n",
        "            if reduction == 'mean':\n",
        "                return correct.float() / targets.numel()\n",
        "            elif reduction == 'sum':\n",
        "                return correct\n",
        "            else:\n",
        "                raise ValueError(\"reduction debe ser 'mean' o 'sum'\")\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Acumular la métrica a lo largo de varios lotes.\"\"\"\n",
        "        if outputs.dim() == 4 and targets.dim() == 3:\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct = torch.sum(preds == targets)\n",
        "            self._base[0] += correct\n",
        "            self._base[1] += targets.numel()\n",
        "        else:\n",
        "            raise ValueError(\"Las dimensiones de outputs y targets no son compatibles\")\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Devolver la puntuación acumulada en una época.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # advertencia de división por cero\n",
        "            warnings.warn(\"El denominador es cero, devuelve 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0].float() / self._base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaZs0hwDG09U"
      },
      "outputs": [],
      "source": [
        "# Se define una función para crear un modelo DeepLab preentrenado.\n",
        "def DeepLab_pretrained(num_classes):\n",
        "    # Se carga el modelo DeepLab con una arquitectura ResNet50 preentrenada.\n",
        "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # Se reemplaza el clasificador del modelo con un nuevo clasificador DeepLabHead.\n",
        "    # El nuevo clasificador tiene 2048 características de entrada y 'num_classes' características de salida.\n",
        "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    # Se devuelve el modelo modificado.\n",
        "    return deeplab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TZFPZp57F3wK"
      },
      "outputs": [],
      "source": [
        "# Crea una instancia del modelo U-Net con 5 canales de salida.\n",
        "# Número de canales de salida = al número de clases\n",
        "unet = construct_unet(5)\n",
        "# Se \"envuelve\" el modelo en un objeto DataParallel.\n",
        "# Esto permite que el modelo se ejecute en paralelo en múltiples GPUs, si están disponibles.\n",
        "unet = DataParallel(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnmr0nyOG09U",
        "outputId": "de0cb9c4-4b63-4a08-8ca3-601ff05efa5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Se define el dispositivo en el que se ejecutará el modelo.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Se imprime el dispositivo utilizado.\n",
        "print(f\"Dispositivo utilizado: {device}\")\n",
        "\n",
        "# Se crea el modelo utilizando la función DeepLab_pretrained definida anteriormente.\n",
        "# El modelo se envuelve en un objeto DataParallel para permitir el entrenamiento en múltiples GPUs si están disponibles.\n",
        "#model = DataParallel(DeepLab_pretrained(5))\n",
        "\n",
        "# Se define la función de pérdida a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza la pérdida de entropía cruzada.\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Se define el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza Adam con una tasa de aprendizaje de 0.01.\n",
        "#optimizer = Adam(model.parameters(), lr=0.01)\n",
        "optimizer = Adam(unet.parameters(), lr=0.01)\n",
        "\n",
        "# Se define el programador de la tasa de aprendizaje a utilizar durante el entrenamiento.\n",
        "# En este caso, se utiliza un programador de paso que disminuye la tasa de aprendizaje en un factor de 0.2 cada 5 épocas.\n",
        "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ziFXmCGaUubr"
      },
      "outputs": [],
      "source": [
        "class Precision:\n",
        "    \"\"\"Calculate precision of a model\"\"\"\n",
        "    def __init__(self):\n",
        "        self.__name__ = \"precision\"\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def calc(self, outputs, targets, reduction='mean'):\n",
        "        \"\"\" Compute the precision.\n",
        "        Args:\n",
        "        ------\n",
        "        outputs: torch.Tensor\n",
        "        The output of the model, shape (batch_size, num_classes)\n",
        "\n",
        "        targets: torch.Tensor\n",
        "        The ground truth label, shape (batch_size, )\n",
        "\n",
        "        reduction: str\n",
        "        The reduction method, 'mean' or 'sum'\n",
        "        If 'mean', return the mean precision of the batch\n",
        "        If 'sum', return the sum of correct predictions of the batch\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        precision: torch.Tensor\n",
        "        \"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return correct / total\n",
        "        elif reduction == 'sum':\n",
        "            return correct\n",
        "        else:\n",
        "            raise ValueError(\"reduction must be 'mean' or 'sum'\")\n",
        "\n",
        "    def accumulate(self, outputs, targets):\n",
        "        \"\"\" Accumulate the metric over batches.\"\"\"\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = torch.sum(preds == targets)\n",
        "        total = torch.sum(preds == preds)\n",
        "        self.base[0] += correct\n",
        "        self.base[1] += total\n",
        "\n",
        "    def reset(self):\n",
        "        self._base = [0, 0]\n",
        "\n",
        "    def accumulated_score(self):\n",
        "        \"\"\" Return the accumulated score in one epoch.\"\"\"\n",
        "        if self._base[1] == 0:\n",
        "            # divide by zero warning\n",
        "            warnings.warn(\"The denominator is zero, return 0\", RuntimeWarning)\n",
        "            return 0\n",
        "        return self._base[0] / self.base[1]\n",
        "\n",
        "    def __call__(self, outputs, targets, reduction='mean'):\n",
        "        return self.calc(outputs, targets, reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qouTmOWmA8ng",
        "outputId": "9259930e-2101-449c-ac55-6702f282b1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Cargar los pesos del modelo preentrenado\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/model.pt'\n",
        "unet.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJv6uo4G09V",
        "outputId": "2d26a851-a98c-45a4-aa46-03cd5612584a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:ModelHandler initialized.\n"
          ]
        }
      ],
      "source": [
        "# Se inicializa el manejador del modelo.\n",
        "# La salida se almacena en la carpeta de salida.\n",
        "modelhandler = ModelHandler(\n",
        "    # Se pasa el modelo que se va a entrenar.\n",
        "    #model=model,\n",
        "    model = unet,\n",
        "    # Se especifica el nombre de la carpeta de salida.\n",
        "    #model_output='out_unet',\n",
        "    # Se pasan los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "    train_dataset=trainset,\n",
        "    val_dataset=valset,\n",
        "    test_dataset=testset,\n",
        "    # Se especifica el tamaño del lote para el entrenamiento y la validación.\n",
        "    batch_size_train=16,\n",
        "    batch_size_val=16,\n",
        "    # Se pasa el programador de la tasa de aprendizaje.\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    # Se especifica el número de épocas para el entrenamiento.\n",
        "    num_epochs=15,\n",
        "    # Se pasa la función de pérdida y el optimizador.\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    # Se pasa el dispositivo en el que se ejecutará el entrenamiento.\n",
        "    device=device,\n",
        "    #evaluate_metric= Precision,\n",
        "    # Se especifica el directorio donde se guardarán los puntos de control del modelo.\n",
        "    save_dir='/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints',\n",
        "    # Se especifica el nombre del archivo de punto de control.\n",
        "    save_name='unetv6.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SfRwQCG09V",
        "outputId": "975e10cb-4e0d-46d2-a469-ca7f00d4aa12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [0/1108 (0%)]\tLoss: 0.126666\n",
            " 14%|█▍        | 10/70 [01:10<08:13,  8.22s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [160/1108 (14%)]\tLoss: 0.150863\n",
            " 29%|██▊       | 20/70 [02:11<05:12,  6.25s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [320/1108 (29%)]\tLoss: 0.163144\n",
            " 43%|████▎     | 30/70 [03:13<04:01,  6.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [480/1108 (43%)]\tLoss: 0.139730\n",
            " 57%|█████▋    | 40/70 [04:16<03:08,  6.28s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [640/1108 (57%)]\tLoss: 0.170279\n",
            " 71%|███████▏  | 50/70 [05:17<02:01,  6.09s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [800/1108 (71%)]\tLoss: 0.107573\n",
            " 86%|████████▌ | 60/70 [06:19<01:01,  6.13s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 1 [960/1108 (86%)]\tLoss: 0.121280\n",
            "100%|██████████| 70/70 [07:16<00:00,  6.24s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 1\n",
            "100%|██████████| 6/6 [00:59<00:00,  9.84s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 1 \tAverage loss: 7.8542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1435 (train) | 7.8542 (val)\n",
            "Epoch 2 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [0/1108 (0%)]\tLoss: 0.135179\n",
            " 14%|█▍        | 10/70 [00:09<01:00,  1.01s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [160/1108 (14%)]\tLoss: 0.136889\n",
            " 29%|██▊       | 20/70 [00:20<00:51,  1.03s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [320/1108 (29%)]\tLoss: 0.083301\n",
            " 43%|████▎     | 30/70 [00:30<00:42,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [480/1108 (43%)]\tLoss: 0.107187\n",
            " 57%|█████▋    | 40/70 [00:41<00:32,  1.09s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [640/1108 (57%)]\tLoss: 0.084821\n",
            " 71%|███████▏  | 50/70 [00:53<00:22,  1.11s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [800/1108 (71%)]\tLoss: 0.087923\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.09s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 2 [960/1108 (86%)]\tLoss: 0.127573\n",
            "100%|██████████| 70/70 [01:14<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 2\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 2 \tAverage loss: 0.2832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1043 (train) | 0.2832 (val)\n",
            "Epoch 3 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [0/1108 (0%)]\tLoss: 0.063905\n",
            " 14%|█▍        | 10/70 [00:10<01:02,  1.04s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [160/1108 (14%)]\tLoss: 0.084516\n",
            " 29%|██▊       | 20/70 [00:20<00:52,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [320/1108 (29%)]\tLoss: 0.107708\n",
            " 43%|████▎     | 30/70 [00:31<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [480/1108 (43%)]\tLoss: 0.080370\n",
            " 57%|█████▋    | 40/70 [00:42<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [640/1108 (57%)]\tLoss: 0.182516\n",
            " 71%|███████▏  | 50/70 [00:53<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [800/1108 (71%)]\tLoss: 0.052092\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 3 [960/1108 (86%)]\tLoss: 0.095276\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.07s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 3\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 3 \tAverage loss: 0.2318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0909 (train) | 0.2318 (val)\n",
            "Epoch 4 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [0/1108 (0%)]\tLoss: 0.055156\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [160/1108 (14%)]\tLoss: 0.076739\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [320/1108 (29%)]\tLoss: 0.105494\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [480/1108 (43%)]\tLoss: 0.129309\n",
            " 57%|█████▋    | 40/70 [00:42<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [640/1108 (57%)]\tLoss: 0.059791\n",
            " 71%|███████▏  | 50/70 [00:53<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [800/1108 (71%)]\tLoss: 0.091830\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 4 [960/1108 (86%)]\tLoss: 0.060077\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 4\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 4 \tAverage loss: 0.2771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0778 (train) | 0.2771 (val)\n",
            "Epoch 5 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [0/1108 (0%)]\tLoss: 0.100088\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [160/1108 (14%)]\tLoss: 0.065842\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [320/1108 (29%)]\tLoss: 0.073547\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [480/1108 (43%)]\tLoss: 0.078764\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [640/1108 (57%)]\tLoss: 0.120667\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [800/1108 (71%)]\tLoss: 0.055047\n",
            " 86%|████████▌ | 60/70 [01:05<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 5 [960/1108 (86%)]\tLoss: 0.074451\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 5\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 5 \tAverage loss: 0.1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0763 (train) | 0.1968 (val)\n",
            "Epoch 6 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [0/1108 (0%)]\tLoss: 0.069314\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [160/1108 (14%)]\tLoss: 0.056479\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [320/1108 (29%)]\tLoss: 0.087639\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [480/1108 (43%)]\tLoss: 0.044803\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [640/1108 (57%)]\tLoss: 0.035892\n",
            " 71%|███████▏  | 50/70 [00:53<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [800/1108 (71%)]\tLoss: 0.053232\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 6 [960/1108 (86%)]\tLoss: 0.047123\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 6\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.67it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 6 \tAverage loss: 0.1854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0649 (train) | 0.1854 (val)\n",
            "Epoch 7 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [0/1108 (0%)]\tLoss: 0.065473\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [160/1108 (14%)]\tLoss: 0.034424\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [320/1108 (29%)]\tLoss: 0.059176\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [480/1108 (43%)]\tLoss: 0.051793\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [640/1108 (57%)]\tLoss: 0.068038\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [800/1108 (71%)]\tLoss: 0.044730\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 7 [960/1108 (86%)]\tLoss: 0.079354\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 7\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.74it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 7 \tAverage loss: 0.1702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0606 (train) | 0.1702 (val)\n",
            "Epoch 8 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [0/1108 (0%)]\tLoss: 0.059079\n",
            " 14%|█▍        | 10/70 [00:10<01:04,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [160/1108 (14%)]\tLoss: 0.084823\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [320/1108 (29%)]\tLoss: 0.045952\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [480/1108 (43%)]\tLoss: 0.046809\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [640/1108 (57%)]\tLoss: 0.098372\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [800/1108 (71%)]\tLoss: 0.062829\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 8 [960/1108 (86%)]\tLoss: 0.049606\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 8\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 8 \tAverage loss: 0.1613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0580 (train) | 0.1613 (val)\n",
            "Epoch 9 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [0/1108 (0%)]\tLoss: 0.048697\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [160/1108 (14%)]\tLoss: 0.105877\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [320/1108 (29%)]\tLoss: 0.041951\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [480/1108 (43%)]\tLoss: 0.055445\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [640/1108 (57%)]\tLoss: 0.053772\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [800/1108 (71%)]\tLoss: 0.062166\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 9 [960/1108 (86%)]\tLoss: 0.056582\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 9\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 9 \tAverage loss: 0.1518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0567 (train) | 0.1518 (val)\n",
            "Epoch 10 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [0/1108 (0%)]\tLoss: 0.035876\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [160/1108 (14%)]\tLoss: 0.071624\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [320/1108 (29%)]\tLoss: 0.061933\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [480/1108 (43%)]\tLoss: 0.048645\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [640/1108 (57%)]\tLoss: 0.044376\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [800/1108 (71%)]\tLoss: 0.050769\n",
            " 86%|████████▌ | 60/70 [01:05<00:10,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 10 [960/1108 (86%)]\tLoss: 0.061263\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 10\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 10 \tAverage loss: 0.1525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0558 (train) | 0.1525 (val)\n",
            "Epoch 11 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [0/1108 (0%)]\tLoss: 0.058791\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [160/1108 (14%)]\tLoss: 0.048618\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [320/1108 (29%)]\tLoss: 0.055783\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [480/1108 (43%)]\tLoss: 0.055577\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [640/1108 (57%)]\tLoss: 0.057143\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [800/1108 (71%)]\tLoss: 0.048594\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 11 [960/1108 (86%)]\tLoss: 0.084432\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 11\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 11 \tAverage loss: 0.1459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0525 (train) | 0.1459 (val)\n",
            "Epoch 12 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [0/1108 (0%)]\tLoss: 0.047413\n",
            " 14%|█▍        | 10/70 [00:10<01:04,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [160/1108 (14%)]\tLoss: 0.042532\n",
            " 29%|██▊       | 20/70 [00:21<00:54,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [320/1108 (29%)]\tLoss: 0.046641\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [480/1108 (43%)]\tLoss: 0.055009\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [640/1108 (57%)]\tLoss: 0.039625\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [800/1108 (71%)]\tLoss: 0.039646\n",
            " 86%|████████▌ | 60/70 [01:05<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 12 [960/1108 (86%)]\tLoss: 0.043174\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 12\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 12 \tAverage loss: 0.1419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0514 (train) | 0.1419 (val)\n",
            "Epoch 13 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [0/1108 (0%)]\tLoss: 0.072143\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [160/1108 (14%)]\tLoss: 0.057301\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [320/1108 (29%)]\tLoss: 0.043661\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [480/1108 (43%)]\tLoss: 0.058518\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [640/1108 (57%)]\tLoss: 0.058975\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [800/1108 (71%)]\tLoss: 0.049405\n",
            " 86%|████████▌ | 60/70 [01:05<00:10,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 13 [960/1108 (86%)]\tLoss: 0.046450\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 13\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 13 \tAverage loss: 0.1410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0512 (train) | 0.1410 (val)\n",
            "Epoch 14 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [0/1108 (0%)]\tLoss: 0.052576\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.05s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [160/1108 (14%)]\tLoss: 0.051696\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [320/1108 (29%)]\tLoss: 0.061171\n",
            " 43%|████▎     | 30/70 [00:32<00:42,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [480/1108 (43%)]\tLoss: 0.069881\n",
            " 57%|█████▋    | 40/70 [00:42<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [640/1108 (57%)]\tLoss: 0.089243\n",
            " 71%|███████▏  | 50/70 [00:53<00:21,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [800/1108 (71%)]\tLoss: 0.066282\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 14 [960/1108 (86%)]\tLoss: 0.048501\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 14\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 14 \tAverage loss: 0.1386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0505 (train) | 0.1386 (val)\n",
            "Epoch 15 / 15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/70 [00:00<?, ?it/s]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [0/1108 (0%)]\tLoss: 0.048941\n",
            " 14%|█▍        | 10/70 [00:10<01:03,  1.06s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [160/1108 (14%)]\tLoss: 0.047357\n",
            " 29%|██▊       | 20/70 [00:21<00:53,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [320/1108 (29%)]\tLoss: 0.048409\n",
            " 43%|████▎     | 30/70 [00:32<00:43,  1.08s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [480/1108 (43%)]\tLoss: 0.037237\n",
            " 57%|█████▋    | 40/70 [00:43<00:32,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [640/1108 (57%)]\tLoss: 0.036277\n",
            " 71%|███████▏  | 50/70 [00:54<00:21,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [800/1108 (71%)]\tLoss: 0.040345\n",
            " 86%|████████▌ | 60/70 [01:04<00:10,  1.07s/it]INFO:pv_vision.nn.modelhandler:Train Epoch: 15 [960/1108 (86%)]\tLoss: 0.070245\n",
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Saved model at epoch 15\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.79it/s]\n",
            "INFO:pv_vision.nn.modelhandler:Val epoch: 15 \tAverage loss: 0.1419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0500 (train) | 0.1419 (val)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'loss': [0.14349295543204146,\n",
              "   0.10433854355009455,\n",
              "   0.090934598811697,\n",
              "   0.07779142372175675,\n",
              "   0.07628739002540653,\n",
              "   0.06492381685477301,\n",
              "   0.06060168070429499,\n",
              "   0.057965525691582406,\n",
              "   0.05674532837224351,\n",
              "   0.05584162745342358,\n",
              "   0.05245988405165044,\n",
              "   0.05144037449537417,\n",
              "   0.051166102384294414,\n",
              "   0.05046706869929276,\n",
              "   0.05000431136318923]},\n",
              " 'val': {'loss': [7.85419487953186,\n",
              "   0.28319241603215534,\n",
              "   0.23181447138388953,\n",
              "   0.27708540856838226,\n",
              "   0.19679279873768488,\n",
              "   0.18538319567839304,\n",
              "   0.17018737147251764,\n",
              "   0.16127599030733109,\n",
              "   0.1517594257990519,\n",
              "   0.1524687111377716,\n",
              "   0.14585263033707938,\n",
              "   0.14194760719935098,\n",
              "   0.1409610075255235,\n",
              "   0.13864433020353317,\n",
              "   0.141850712398688]}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Se inicializa el entrenamiento del modelo.\n",
        "modelhandler.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k55JhgMyG09V",
        "outputId": "9f012607-29a6-49a2-ed50-9ab77fd6f149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3O0lEQVR4nO3deXxTdb7/8fdJ0qZbWnbaallUFAVhVNCLOD93EZVRHPWqVUHv4zpqHUWuPpTr4DpYt0HcHiiO43IHXK84XL3KBXRwRRDEcRtQB7EOYEWl6QJpm5zfH2lC0r1Ncr4pfT0fjzxyzsk5J5+k2L79nu/3eyzbtm0BAACkIZfpAgAAANpCUAEAAGmLoAIAANIWQQUAAKQtggoAAEhbBBUAAJC2CCoAACBteUwXkIhQKKQtW7bI5/PJsizT5QAAgE6wbVvV1dUqLi6Wy9V+m0mPDipbtmxRSUmJ6TIAAEA3VFRUaO+99253nx4dVHw+n6TwB83PzzdcDQAA6Ay/36+SkpLo3/H29OigErnck5+fT1ABAKCH6Uy3DTrTAgCAtEVQAQAAaYugAgAA0laP7qMCAECqhEIh1dfXmy6jR8rIyJDb7U7KuYwGlWAwqFtuuUV//vOftW3bNhUXF2v69On63e9+x7woAABj6uvrtWnTJoVCIdOl9Fh9+vRRYWFhwn/PjQaVu+66S/Pnz9dTTz2lUaNG6cMPP9TFF1+sgoICXXXVVSZLAwD0UrZta+vWrXK73SopKelwQjLEs21bdXV1qqyslCQVFRUldD6jQeW9997T6aefrlNPPVWSNGzYMD3zzDNavXq1ybIAAL1YY2Oj6urqVFxcrJycHNPl9EjZ2dmSpMrKSg0aNCihy0BGY+KRRx6pFStWaOPGjZKkjz/+WO+8844mT57c6v6BQEB+vz/uAQBAMgWDQUlSZmam4Up6tkjIa2hoSOg8RltUbrjhBvn9fo0cOVJut1vBYFBz5sxRaWlpq/uXl5fr1ltvdbhKAEBvRF/JxCTr+zPaovL8889r4cKFWrRokdatW6ennnpK9957r5566qlW9581a5aqqqqij4qKCocrBgAATjLaonLdddfphhtu0LnnnitJOvjgg7V582aVl5dr2rRpLfb3er3yer1OlwkAAAwx2qJSV1fXoje12+1mOBgAAIYNGzZM8+bNM12G2RaVKVOmaM6cORoyZIhGjRqljz76SHPnztUll1xisiwp2CjVfC/ZQanPELO1AADQScccc4x+8YtfJCVgrFmzRrm5uYkXlSCjQeXBBx/U7NmzdcUVV6iyslLFxcX6zW9+o5tuuslkWdL6P0v/c7U0YpJU+rzZWgAASBLbthUMBuXxdPznf+DAgQ5U1DGjl358Pp/mzZunzZs3a+fOnfr666/1+9//3vyQsLzC8HPNNrN1AACMs21bdfWNRh62bXe6zunTp2vlypW6//77ZVmWLMvSk08+Kcuy9Nprr+mwww6T1+vVO++8o6+//lqnn366Bg8erLy8PI0fP17Lly+PO1/zSz+WZemPf/yjpk6dqpycHI0YMUJLlixJ1tfcJu710xpfU1CpJqgAQG+3syGog25aauS9P79tknIyO/en+v7779fGjRs1evRo3XbbbZKkzz77TFJ4OpB7771X++yzj/r27auKigqdcsopmjNnjrxer55++mlNmTJFGzZs0JAhbXd5uPXWW3X33Xfrnnvu0YMPPqjS0lJt3rxZ/fr1S/zDtoF5gVsTCSq1P0ihoNlaAADohIKCAmVmZionJ0eFhYUqLCyMzgh722236cQTT9S+++6rfv36aezYsfrNb36j0aNHa8SIEbr99tu17777dthCMn36dJ133nnab7/9dMcdd6impibls8nTotKa3IGS5ZLsUDisRIILAKDXyc5w6/PbJhl772QYN25c3HpNTY1uueUWvfrqq9q6dasaGxu1c+dOffvtt+2eZ8yYMdHl3Nxc5efnR+/pkyoElda43FLuoHAfleqtBBUA6MUsy+r05Zd01Xz0zrXXXqtly5bp3nvv1X777afs7GydddZZqq+vb/c8GRkZceuWZaV8SpGe/c2nkm9wU1D53nQlAAB0SmZmZvReRe159913NX36dE2dOlVSuIXlm2++SXF13UMflbYw8gcA0MMMGzZMH3zwgb755htt3769zdaOESNG6KWXXtL69ev18ccf6/zzz0/byVYJKm3xDQ4/06ICAOghrr32Wrndbh100EEaOHBgm31O5s6dq759++rII4/UlClTNGnSJB166KEOV9s5XPppi68o/Fy91WwdAAB00v7776/3338/btv06dNb7Dds2DC98cYbcdvKysri1ptfCmptTpcdO3Z0q86uoEWlLXlNLSo1tKgAAGAKQaUtTPoGAIBxBJW2EFQAADCOoNKWyKif2kopTXtCAwCwpyOotCVvkCRLCjVKdT+argYAgF6JoNIWd4aUOyC8zFwqAAAYQVBpTx79VAAAMImg0p7opG8EFQAATCCotIdp9AEAvciwYcM0b94802XEIai0hyHKAAAYRVBpD0EFAACjCCrtYRp9AEAPsWDBAhUXF7e4C/Lpp5+uSy65RF9//bVOP/10DR48WHl5eRo/fryWL19uqNrOI6i0J3pjQlpUAKDXsm2pvtbMo5UbAbbl7LPP1o8//qg333wzuu2nn37S66+/rtLSUtXU1OiUU07RihUr9NFHH+nkk0/WlClT2rzDcrrg7snt8cW0qNi2ZFlm6wEAOK+hTrqj2Mx7/+cWKTO3U7v27dtXkydP1qJFi3T88cdLkl588UUNGDBAxx57rFwul8aOHRvd//bbb9fixYu1ZMkSXXnllSkpPxloUWlP5NJPsF7a+bPZWgAA6EBpaan++7//W4FAQJK0cOFCnXvuuXK5XKqpqdG1116rAw88UH369FFeXp6++OILWlR6NI9Xyu4n7fwpfPknp5/pigAATsvICbdsmHrvLpgyZYps29arr76q8ePH6+2339Z9990nSbr22mu1bNky3Xvvvdpvv/2UnZ2ts846S/X19amoPGkIKh3xFTYFla3S4INMVwMAcJpldfryi2lZWVk688wztXDhQn311Vc64IADdOihh0qS3n33XU2fPl1Tp06VJNXU1Oibb74xWG3nEFQ6kjdYqvyckT8AgB6htLRUp512mj777DNdcMEF0e0jRozQSy+9pClTpsiyLM2ePbvFCKF0RB+VjjCXCgCgBznuuOPUr18/bdiwQeeff350+9y5c9W3b18deeSRmjJliiZNmhRtbUlntKh0hKACAOhBXC6Xtmxp2adm2LBheuONN+K2lZWVxa2n46UgWlQ6wv1+AAAwhqDSkegdlOmjAgCA0wgqHYnMTkuLCgAAjiOodCQy6Vv1ti5NZQwAABJnNKgMGzZMlmW1eDTv3GNUpDNt4y5pV5XZWgAAjrH5n9OEJOv7MzrqZ82aNQoGg9H1Tz/9VCeeeKLOPvtsg1U1k5EteQukQFV4LpXsPqYrAgCkkNvtliTV19crOzvbcDU9V11dnSQpIyMjofMYDSoDBw6MW7/zzju177776uijjzZUURt8heGgUr1VGniA6WoAACnk8XiUk5OjH374QRkZGXK56CXRFbZtq66uTpWVlerTp080+HVX2syjUl9frz//+c+aOXOmrDbuUhwIBKI3WpIkv9/vTHG+wdL2DYz8AYBewLIsFRUVadOmTdq8ebPpcnqsPn36qLCwMOHzpE1Qefnll7Vjxw5Nnz69zX3Ky8t16623OldUBHOpAECvkpmZqREjRqT9DfvSVUZGRsItKRFpE1Qef/xxTZ48WcXFxW3uM2vWLM2cOTO67vf7VVJSkvrimJ0WAHodl8ulrKws02X0emkRVDZv3qzly5frpZdeanc/r9crr9frUFUxCCoAABiRFj2EnnjiCQ0aNEinnnqq6VJaF5lLhTsoAwDgKONBJRQK6YknntC0adPk8aRFA09LkdlpaVEBAMBRxoPK8uXL9e233+qSSy4xXUrbuPQDAIARxpswTjrppPSf/S9y6aehVgpUS16f2XoAAOgljLeo9AjePCkzL7zMXCoAADiGoNJZ0cs/W83WAQBAL0JQ6azopG+0qAAA4BSCSmf5mvqp0KEWAADHEFQ6KzJEmWn0AQBwDEGls/JoUQEAwGkElc5iLhUAABxHUOksH51pAQBwGkGls/JoUQEAwGkElc6KjPoJ+KX6OrO1AADQSxBUOsubL3myw8uM/AEAwBEElc6yLDrUAgDgMIJKVxBUAABwFEGlKyJzqTDyBwAARxBUuiIyOy0tKgAAOIKg0hXc7wcAAEcRVLoiegdlggoAAE4gqHRFtDMtfVQAAHACQaUrokFlq9k6AADoJQgqXREZ9bNrh9Swy2gpAAD0BgSVrsjuK7m94WWGKAMAkHIEla6wrN0jfwgqAACkHEGlq/LopwIAgFMIKl0VnUuFFhUAAFKNoNJVkdlpmUsFAICUI6h0VR6z0wIA4BSCSldxB2UAABxDUOmq6DT69FEBACDVCCpdxey0AAA4hqDSVZGgUvej1FhvthYAAPZwBJWuyu4nuTzh5dpKs7UAALCHI6h0lcsVM+kb/VQAAEgl40Hln//8py644AL1799f2dnZOvjgg/Xhhx+aLqt90Unf6KcCAEAqeUy++c8//6yJEyfq2GOP1WuvvaaBAwfqyy+/VN++fU2W1bHoyB+GKAMAkEpGg8pdd92lkpISPfHEE9Ftw4cPN1hRJ/m49AMAgBOMXvpZsmSJxo0bp7PPPluDBg3SIYccoscee6zN/QOBgPx+f9zDCIYoAwDgCKNB5R//+Ifmz5+vESNGaOnSpbr88st11VVX6amnnmp1//LychUUFEQfJSUlDlfcJDKNPpO+AQCQUpZt27apN8/MzNS4ceP03nvvRbddddVVWrNmjd5///0W+wcCAQUCgei63+9XSUmJqqqqlJ+f70jNkqSNS6VF50iFY6TL3nbufQEA2AP4/X4VFBR06u+30RaVoqIiHXTQQXHbDjzwQH377bet7u/1epWfnx/3MMLHNPoAADjBaFCZOHGiNmzYELdt48aNGjp0qKGKOik66qdSCjaarQUAgD2Y0aByzTXXaNWqVbrjjjv01VdfadGiRVqwYIHKyspMltWx3AGS5ZJkS7U/mK4GAIA9ltGgMn78eC1evFjPPPOMRo8erdtvv13z5s1TaWmpybI65nLHdKhlLhUAAFLF6DwqknTaaafptNNOM11G1+UNDg9PriaoAACQKsan0O+xonOpEFQAAEgVgkp3MfIHAICUI6h0Vx6z0wIAkGoEle6K3kGZFhUAAFKFoNJd3EEZAICUI6h0F3dQBgAg5Qgq3RXbmTYUNFsLAAB7KIJKd+UOkmRJdlCq+9F0NQAA7JEIKt3l9ki5A8PLzKUCAEBKEFQSER35Q1ABACAVCCqJYOQPAAApRVBJBHOpAACQUgSVRPiKws+0qAAAkBIElUTk0UcFAIBUIqgkgjsoAwCQUgSVREQv/dBHBQCAVCCoJCL20o9tm60FAIA9EEElEZGgEmqQ6n4yWwsAAHsggkoiPJlSTv/wMiN/AABIOoJKoiKTvlVvNVsHAAB7IIJKopj0DQCAlCGoJIpp9AEASBmCSqKic6nQogIAQLIRVBLlo48KAACpQlBJVGSIMpO+AQCQdASVREVmp2UafQAAko6gkigfs9MCAJAqBJVERUb9BAPSrh1GSwEAYE9DUElURpaU1Se8zMgfAACSiqCSDD7mUgEAIBUIKskQexdlAACQNASVZIjOpUJQAQAgmYwGlVtuuUWWZcU9Ro4cabKk7ole+qGPCgAAyeQxXcCoUaO0fPny6LrHY7ykruMOygAApITxVODxeFRYWGi6jMRwB2UAAFLCeB+VL7/8UsXFxdpnn31UWlqqb7/9ts19A4GA/H5/3CMtRGanZdQPAABJZTSoHHHEEXryySf1+uuva/78+dq0aZN++ctfqrq6utX9y8vLVVBQEH2UlJQ4XHEb8pidFgCAVLBsO33+su7YsUNDhw7V3Llz9W//9m8tXg8EAgoEAtF1v9+vkpISVVVVKT8/38lS49XXSncUh5dvqJCyDNYCAECa8/v9Kigo6NTfb+N9VGL16dNH+++/v7766qtWX/d6vfJ6vQ5X1QmZuZI3Xwr4wyN/CCoAACSF8T4qsWpqavT111+rqKjIdCldx6RvAAAkndGgcu2112rlypX65ptv9N5772nq1Klyu90677zzTJbVPUz6BgBA0hm99PPdd9/pvPPO048//qiBAwfqqKOO0qpVqzRw4ECTZXVPpEWFkT8AACSN0aDy7LPPmnz75KJFBQCApEurPio9GkEFAICkI6gkSx73+wEAINkIKslCiwoAAElHUEkW7qAMAEDSEVSSJTLqJ+APz1QLAAASRlBJFq9PysgJL3P5BwCApCCoJItlcfkHAIAkI6gkU2TkT/VWs3UAALCHIKgkky9yvx9aVAAASAaCSjL5mm6myDT6AAAkBUElmbiDMgAASUVQSSYmfQMAIKkIKsnEqB8AAJKKoJJMebSoAACQTASVZIqM+tm1Q2rYabQUAAD2BASVZMrqI7m94WUu/wAAkDCCSjLFzk7LXCoAACSMoJJsPmanBQAgWQgqyRaZS4VLPwAAJIygkmyR2WkZ+QMAQMIIKsnmo0UFAIBkIagkG3dQBgAgaQgqycaoHwAAkoagkmzRafTpowIAQKIIKskWufRT96PUWG+2FgAAejiCSrLl9JNcGeFlOtQCAJAQgkqyxc5OS1ABACAh3QoqFRUV+u6776Lrq1ev1owZM7RgwYKkFdajRSZ9Y+QPAAAJ6VZQOf/88/Xmm29KkrZt26YTTzxRq1ev1o033qjbbrstqQX2SNGRP3SoBQAgEd0KKp9++qkOP/xwSdLzzz+v0aNH67333tPChQv15JNPJrO+nolLPwAAJEW3gkpDQ4O8Xq8kafny5frVr34lSRo5cqS2buVyx+5J32hRAQAgEd0KKqNGjdIjjzyit99+W8uWLdPJJ58sSdqyZYv69++f1AJ7pMg0+gQVAAAS0q2gctddd+nRRx/VMccco/POO09jx46VJC1ZsiR6Sair7rzzTlmWpRkzZnTr+LSSx6RvAAAkg6c7Bx1zzDHavn27/H6/+vbtG91+6aWXKicnp8vnW7NmjR599FGNGTOmO+WkH6bRBwAgKbrVorJz504FAoFoSNm8ebPmzZunDRs2aNCgQV06V01NjUpLS/XYY4/FhZ4eLRJUan+Qgo1mawEAoAfrVlA5/fTT9fTTT0uSduzYoSOOOEJ/+MMfdMYZZ2j+/PldOldZWZlOPfVUnXDCCR3uGwgE5Pf74x5pKWeAZLkl2VJtpelqAADosboVVNatW6df/vKXkqQXX3xRgwcP1ubNm/X000/rgQce6PR5nn32Wa1bt07l5eWd2r+8vFwFBQXRR0lJSXfKTz2XK2bSN/qpAADQXd0KKnV1dfL5fJKk//u//9OZZ54pl8ulf/mXf9HmzZs7dY6KigpdffXVWrhwobKysjp1zKxZs1RVVRV9VFRUdKd8Z0RG/jCXCgAA3datoLLffvvp5ZdfVkVFhZYuXaqTTjpJklRZWan8/PxOnWPt2rWqrKzUoYceKo/HI4/Ho5UrV+qBBx6Qx+NRMBhscYzX61V+fn7cI21F51JhXhkAALqrW6N+brrpJp1//vm65pprdNxxx2nChAmSwq0rhxxySKfOcfzxx+uTTz6J23bxxRdr5MiRuv766+V2u7tTWvpg5A8AAAnrVlA566yzdNRRR2nr1q3ROVSkcPiYOnVqp87h8/k0evTouG25ubnq379/i+09ko+5VAAASFS3gookFRYWqrCwMHoX5b333rvbk73tkehMCwBAwrrVRyUUCum2225TQUGBhg4dqqFDh6pPnz66/fbbFQqFul3MX//6V82bN6/bx6cV7qAMAEDCutWicuONN+rxxx/XnXfeqYkTJ0qS3nnnHd1yyy3atWuX5syZk9QieyTuoAwAQMK6FVSeeuop/fGPf4zeNVmSxowZo7322ktXXHEFQUWKud/P91IoKLl6eOdgAAAM6Naln59++kkjR45ssX3kyJH66aefEi5qj5A7UJIl2SGpdrvpagAA6JG6FVTGjh2rhx56qMX2hx56aM+5sWCi3B4pr+m+R4z8AQCgW7p16efuu+/WqaeequXLl0fnUHn//fdVUVGh//3f/01qgT1a3uDwpZ/q76Ui08UAANDzdKtF5eijj9bGjRs1depU7dixQzt27NCZZ56pzz77TP/1X/+V7Bp7Lh+z0wIAkIhuz6NSXFzcotPsxx9/rMcff1wLFixIuLA9AiN/AABISLdaVNBJecylAgBAIggqqeRjdloAABJBUEmlPO73AwBAIrrUR+XMM89s9/UdO3YkUsuex9c01Ic7KAMA0C1dCioFBQUdvn7RRRclVNAeJXLpp+Z7KRSSXDRgAQDQFV0KKk888USq6tgz5TZN+BZqkHb+JOUOMFsPAAA9DP+Ln0qeTCmnKZzQoRYAgC4jqKSajw61AAB0F0El1fIYogwAQHcRVFItOvKHoAIAQFcRVFItduQPAADoEoJKquVxY0IAALqLoJJq0Wn0aVEBAKCrCCqpFumjwqgfAAC6jKCSankxLSq2bbYWAAB6GIJKqkWCSjAg7fzZbC0AAPQwBJVUy8iSsvuGlxn5AwBAlxBUnBAd+UM/FQAAuoKg4gQfs9MCANAdBBUn5HG/HwAAuoOg4oTIjQmZSwUAgC4hqDiBOygDANAtBBUncAdlAAC6haDiBO6gDABAtxBUnBB7B2VmpwUAoNOMBpX58+drzJgxys/PV35+viZMmKDXXnvNZEmpERn101AnBfxmawEAoAcxGlT23ntv3XnnnVq7dq0+/PBDHXfccTr99NP12WefmSwr+TJzJG9BeJmRPwAAdJrRoDJlyhSdcsopGjFihPbff3/NmTNHeXl5WrVqlcmyUiN6+Yd+KgAAdJbHdAERwWBQL7zwgmprazVhwoRW9wkEAgoEAtF1v78HXUbJGyxt30iHWgAAusB4Z9pPPvlEeXl58nq9uuyyy7R48WIddNBBre5bXl6ugoKC6KOkpMThahPg434/AAB0lfGgcsABB2j9+vX64IMPdPnll2vatGn6/PPPW9131qxZqqqqij4qKiocrjYB0Unf6KMCAEBnGb/0k5mZqf3220+SdNhhh2nNmjW6//779eijj7bY1+v1yuv1Ol1icnAHZQAAusx4i0pzoVAorh/KHoNLPwAAdJnRFpVZs2Zp8uTJGjJkiKqrq7Vo0SL99a9/1dKlS02WlRrc7wcAgC4zGlQqKyt10UUXaevWrSooKNCYMWO0dOlSnXjiiSbLSo087qAMAEBXGQ0qjz/+uMm3d1ZkHpX6ailQI3nzzNYDAEAPkHZ9VPZYXp+U2RROGPkDAECnEFSclNfUqkKHWgAAOoWg4iQ61AIA0CUEFSfRogIAQJcQVJzkKwo/E1QAAOgUgoqTondQpjMtAACdQVBxUnQula1m6wAAoIcgqDjJx6RvAAB0BUHFSYz6AQCgSwgqToqM+tlVJTXsNFsLAAA9AEHFSVkFkicrvMzIHwAAOkRQcZJlxVz+oZ8KAAAdIag4LTryhxYVAAA6QlBxmo/ZaQEA6CyCitMis9My8gcAgA4RVJwWvd8PfVQAAOgIQcVpPmanBQCgswgqTmPUDwAAnUZQcRqjfgAA6DSCitMiLSo7f5IaA2ZrAQAgzRFUnJbdV3Jnhpe5/AMAQLsIKk6zrJjLPwQVAADaQ1AxITLpG3OpAADQLoKKCXnMTgsAQGcQVEyIzE5LUAEAoF0EFRO49AMAQKcQVExgLhUAADqFoGJC9NIPo34AAGgPQcUELv0AANApBBUTIpd+ardLwQaztQAAkMYIKibk9JdcHkm2VFNpuhoAANIWQcUEl2v3XCpc/gEAoE1Gg0p5ebnGjx8vn8+nQYMG6YwzztCGDRtMluSc6KRvdKgFAKAtRoPKypUrVVZWplWrVmnZsmVqaGjQSSedpNraWpNlOSNyF+XqrWbrAAAgjXlMvvnrr78et/7kk09q0KBBWrt2rf7f//t/hqpySCSocAdlAADaZDSoNFdVVSVJ6tevX6uvBwIBBQKB6Lrf73ekrpRg0jcAADqUNp1pQ6GQZsyYoYkTJ2r06NGt7lNeXq6CgoLoo6SkxOEqkyg6lwotKgAAtCVtgkpZWZk+/fRTPfvss23uM2vWLFVVVUUfFRUVDlaYZNHZaemjAgBAW9Li0s+VV16pV155RW+99Zb23nvvNvfzer3yer0OVpZCjPoBAKBDRltUbNvWlVdeqcWLF+uNN97Q8OHDTZbjrEhn2tpKKRQ0WwsAAGnKaItKWVmZFi1apL/85S/y+Xzati3csbSgoEDZ2dkmS0u93IGS5ZLskFT7w+7gAgAAooy2qMyfP19VVVU65phjVFRUFH0899xzJstyhsst5Q4KLzPyBwCAVhltUbFt2+Tbm+cbHJ5Cn5E/AAC0Km1G/fRKecxOCwBAewgqJkWn0adFBQCA1hBUTIpOo08fFQAAWkNQMYm5VAAAaBdBxSTuoAwAQLsIKiZxB2UAANpFUDEpLyaohEJmawEAIA0RVEzKGyTJkkKNUt2PpqsBACDtEFRMcmdIuQPCy4z8AQCgBYKKaXnMpQIAQFsIKqb5moYo06ICAEALBBXTGKIMAECbCCqmcekHAIA2EVRMYxp9AADaRFAxLTqNPkEFAIDmCCqm+YrCz1z6AQCgBYKKabGjfmzbbC0AAKQZgoppkUs/wXpp589mawEAIM0QVEzzeKXsfuFl+qkAABCHoJIOGPkDAECrCCrpIDryhw61AADEIqikg+jIH2anBQAgFkElHURH/tCiAgBALIJKOohOo08fFQAAYhFU0oGP2WkBAGgNQSUdRPqoMOoHAIA4BJV0EDvqh9lpAQCIIqikg8g8Ko07pYDfbC0AAKQRgko6yMiWsgrCy/RTAQAgiqCSLhj5AwBACwSVdMFcKgAAtEBQSRfMTgsAQAtGg8pbb72lKVOmqLi4WJZl6eWXXzZZjlnc7wcAgBaMBpXa2lqNHTtWDz/8sMky0gN3UAYAoAWPyTefPHmyJk+ebLKE9JHH7LQAADRnNKh0VSAQUCAQiK77/XvQnCPRPioEFQAAInpUZ9ry8nIVFBREHyUlJaZLSp7opR/6qAAAENGjgsqsWbNUVVUVfVRUVJguKXkil37qa6RAtdlaAABIEz3q0o/X65XX6zVdRmp486RMn1RfHR754/WZrggAAON6VIvKHi866Rv9VAAAkAy3qNTU1Oirr76Krm/atEnr169Xv379NGTIEIOVGZJXKP34FR1qAQBoYjSofPjhhzr22GOj6zNnzpQkTZs2TU8++aShqgzyMUQZAIBYRoPKMcccI9u2TZaQXiJDlLn0AwCAJPqopBem0QcAIA5BJZ0wjT4AAHEIKukkElToowIAgCSCSnrJiwQVLv0AACARVNJLZNRPoEqqrzNbCwAAaYCgkk68+VJGTniZfioAABBU0oplMfIHAIAYBJV0w8gfAACiCCrpJo/ZaQEAiCCopJvI7LQEFQAACCppJ3oHZfqoAABAUEk3eUz6BgBABEEl3TA7LQAAUQSVdMOoHwAAoggq6SYy6mfnz1JjwGwtAAAYRlBJN9l9Jbc3vMzlHwBAL0dQSTeWxcgfAACaEFTSESN/AACQRFBJT7SoAAAgiaCSnqKz0241WwcAAIYRVNIRd1AGAEASQSU9MZcKAACSCCrpKRJUqr6Tdvkl2zZbDwAAhnhMF4BWREb9/PB36c4SyXJL2X2krD7heVay+4bXs/t2sK2P5PEa+hBNQkEp4A8Hrl1VTctVraxXtXw92BDuWOwrkvL3kvKbnn1FUn5x+Dkjy+znAwCkFEElHQ08QBr2S6litRQMSHZQqvsx/OiqjJyW4aUzIcebH57TpXFXs2BR1UbQaGO9vjqx76Lq2/Zfz+kv+YqbQkxx03JxfKjJKgh/FgBAj2PZds+9ruD3+1VQUKCqqirl5+ebLic1GnaGp9PfuSP8vGtH/Hpr23btCC8rgR+t5Qq35IQaEv8MkuTJCgcGb374OSu/5bq3IP41lyc8l0z1Vsn/T8m/VfJvkaq3hJ8bd3XuvTNyWwkyxbtbZfL3knIHSi6uhAKAE7ry95sWlXSXkR1+5Bd37bhQKNz60WHA2dFyn4Y6yQ6FH1I4tHjzY8JFQStho5XgkdVn92vJvgRl2+Fa/VuagsyW+BDjbwo3u3ZIDbXSj1+FH21xecKhJXJZKb843FfIkyW53OHXIw/L3XJbq+vt7GO52z6O1h8AiCKo7Klcrt2XdTS8a8c2BsLhJdQQDh2Zeen3x9OypJx+4Ufh6Lb3q69rJcg0hZjI9prvpVCjVFURfpgWF2IyJLen6TkzZrnpEVl2eZq2Ze5ejhzrzmy2X2b8MW2er+lcLtfucBb33I3tsUEv+pxm/7YApBWCSiv8uxpU6d+lXK9HeV6PcjM9crl60S9Tj3f37Lg9XWaO1H/f8KMtwcZwWIm7xPRPqaZSCtaHQ0wo2PTc2Pa63Yl9YtfbYgelYFAKJv/rSE9WJ8JObGDydBx+4pY94VbBuHO1cXyLfd3xpba4Um6n+HWFg5zlbroc69od7iLrsa919Lorsmx14Vgr/DOKHNdi2erEPh3sb7liXmtlOfa7aE3c9rb2T3S7FfO61fa2dArett30b8puaiWPLHfiOdKibtuSJ1Py+kx9CoJKa975cruuWLgubltupjsaXPKywuElL6spyHjdyvNmKM/rblr3yJcVfs71euRreo4c5+5NoacncHukgr3CD41z7n1DoWZBpnmYaQivBxvCy8GG+OVQY9O2+t3L7e3X4rWm9wjWt7Jf4+7z2sFwrXYwJpAFw7/I4tbb2q+jxGU3BbfGXhTO0DvEBBqpa4En9pg2g0Q7YSOZRp8lnfV4cs/ZBQSVVoRsWwXZGaoNNKoxFP6B19YHVVsfVGV1IOHz58SGnmZBJxJo8jI9yspwy+2ylOG25Ha55HHvXs5wWU2vueR2WU2vhZczXK6Y48LbPZFll0tud/w+Vjr9H0Bv4nJJrkxJmaYrSb1IKOtU2Glle6ix2bbG+HDU2rk7fXwH+6rZfx8t/ntJ8euR/mLRmkJtP9p7vUvH2ru/D7X1f+Whpr+HrW1vthz9o6r4P7AdLfd4ke9u9yq6jlE/7bBtW4HGkGoCjaoNNKp6V/i5JuYRXg+qptlrre3XEEzPr9plSR53y/ATG4I8LkueprAUuxy/f3yI8rhd4X0jx0TWY87T6vHu8D5ulxT5JR753R39fw7Lillu9qz4nWOPiV/fvW/z80cWPE2BzhP9TOFll9VUY8zn2P0cPsbtsuSyRBAEuivuj3zs70+ntzdrqYjb1tn92tgWPUdr25r2j/6CanYJrdXntvZRJ/Zp5zxJ/j3W40b9PPzww7rnnnu0bds2jR07Vg8++KAOP/xw02XJsixlZbiVleHWgLzER60EGiOBJqjqQINqA8FwAIoEm13xISfQGFJjyFZjsPmzrcbQ7uWGYEjBkB1eD4WattkKNi1HtrcVlEK2VN8YUn3CnxCtaRFkmoKZ29odfna/7oruFxt0LEkuy5Jl7X7evT28HL6iGDmmtf1ijlfTdqvpeFlNo7ObHd/0GaIhr2nf8LPizh/eoZXXY9Yjv+xaey1yrpjdoq9Hjom+TfNQGrNNcfu1DKcxpcbtE3/eVt6sjRp2v9Z6LW0dY6nFCdo4xop+P5GfYfPtVszPTXHf6e7tVviHs/tnr5h/I01vGvvzcLl2n7+1ylr/ubT8rtr6zK3/vFru25W/j13at/n33+F5m/5oS60e2fK9W+7V6mdusU8rx8VkmfbOFT5f6y90/N3sDlPN983J9KhfrrmWX+NB5bnnntPMmTP1yCOP6IgjjtC8efM0adIkbdiwQYMGDTJdXlJ5PW5589zqn2fm/W3bVsjW7mATtNUQCi9HtoUDTni9MdQ87LQSliL7h2KPD0XP0xg9T8xrIVvBmPeOPVds2Ao2XXazY+rfvay41yIbWr5ux6/HHNe8MbG1Y4K2Ha0xEgaDod2fKfKIXCJsTeS7S/yiIQA471dji/XAeYcYe3/jQWXu3Ln693//d1188cWSpEceeUSvvvqq/vSnP+mGG24wXN2exbIsuS3J3XwkAxIWCYGNod2tW8GgvTvoNK3HvR7zHAzZLY5tDNnRcBaybdl2+Flx600Bzg4HrFBTq3Go6Tg75rg2j1fT8Xaz42PCnx27X8x6pNuBFFtH/P7R16L7tTyXojXEB8XmwbNpz8hCzLbd79NyW4vd4z5b8wPsmK1tXXmw449ssxuC3dobtNjeem2R7bu/Jzv+u2trWTE/y6Y3i/2ZhELxQb3Fv5emN478u+vo87d5daadz9TZc7Yd/1t7jy7s3IUzt/ezCr9ud/B61/ZvMRCs3dpaf7X9Y9rY3s5RGW6zk2EaDSr19fVau3atZs2aFd3mcrl0wgkn6P3332+xfyAQUCCw+/9L/X6/I3UCHSEEAkBqGI1J27dvVzAY1ODB8XN2DB48WNu2bWuxf3l5uQoKCqKPkpISp0oFAAAG9Kibm8yaNUtVVVXRR0VFGswiCgAAUsbopZ8BAwbI7Xbr+++/j9v+/fffq7CwsMX+Xq9XXm+S7xkDAADSltEWlczMTB122GFasWJFdFsoFNKKFSs0YcIEg5UBAIB0YHzUz8yZMzVt2jSNGzdOhx9+uObNm6fa2troKCAAANB7GQ8q//qv/6offvhBN910k7Zt26Zf/OIXev3111t0sAUAAL0PU+gDAABHdeXvd48a9QMAAHoXggoAAEhbBBUAAJC2CCoAACBtEVQAAEDaIqgAAIC0RVABAABpy/iEb4mITAHj9/sNVwIAADor8ne7M1O59eigUl1dLUkqKSkxXAkAAOiq6upqFRQUtLtPj56ZNhQKacuWLfL5fLIsK6nn9vv9KikpUUVFRa+c9ba3f36J74DP37s/v8R30Ns/v5S678C2bVVXV6u4uFguV/u9UHp0i4rL5dLee++d0vfIz8/vtf9AJT6/xHfA5+/dn1/iO+jtn19KzXfQUUtKBJ1pAQBA2iKoAACAtEVQaYPX69XNN98sr9druhQjevvnl/gO+Py9+/NLfAe9/fNL6fEd9OjOtAAAYM9GiwoAAEhbBBUAAJC2CCoAACBtEVQAAEDaIqi04uGHH9awYcOUlZWlI444QqtXrzZdkmPKy8s1fvx4+Xw+DRo0SGeccYY2bNhguixj7rzzTlmWpRkzZpguxVH//Oc/dcEFF6h///7Kzs7WwQcfrA8//NB0WY4IBoOaPXu2hg8fruzsbO277766/fbbO3VPkp7qrbfe0pQpU1RcXCzLsvTyyy/HvW7btm666SYVFRUpOztbJ5xwgr788kszxaZAe5+/oaFB119/vQ4++GDl5uaquLhYF110kbZs2WKu4CTr6Ocf67LLLpNlWZo3b55j9RFUmnnuuec0c+ZM3XzzzVq3bp3Gjh2rSZMmqbKy0nRpjli5cqXKysq0atUqLVu2TA0NDTrppJNUW1trujTHrVmzRo8++qjGjBljuhRH/fzzz5o4caIyMjL02muv6fPPP9cf/vAH9e3b13Rpjrjrrrs0f/58PfTQQ/riiy9011136e6779aDDz5ourSUqa2t1dixY/Xwww+3+vrdd9+tBx54QI888og++OAD5ebmatKkSdq1a5fDlaZGe5+/rq5O69at0+zZs7Vu3Tq99NJL2rBhg371q18ZqDQ1Ovr5RyxevFirVq1ScXGxQ5U1sRHn8MMPt8vKyqLrwWDQLi4utsvLyw1WZU5lZaUtyV65cqXpUhxVXV1tjxgxwl62bJl99NFH21dffbXpkhxz/fXX20cddZTpMow59dRT7UsuuSRu25lnnmmXlpYaqshZkuzFixdH10OhkF1YWGjfc8890W07duywvV6v/cwzzxioMLWaf/7WrF692pZkb9682ZmiHNTW5//uu+/svfbay/7000/toUOH2vfdd59jNdGiEqO+vl5r167VCSecEN3mcrl0wgkn6P333zdYmTlVVVWSpH79+hmuxFllZWU69dRT4/4t9BZLlizRuHHjdPbZZ2vQoEE65JBD9Nhjj5kuyzFHHnmkVqxYoY0bN0qSPv74Y73zzjuaPHmy4crM2LRpk7Zt2xb330JBQYGOOOKIXv170bIs9enTx3QpjgiFQrrwwgt13XXXadSoUY6/f4++KWGybd++XcFgUIMHD47bPnjwYP397383VJU5oVBIM2bM0MSJEzV69GjT5Tjm2Wef1bp167RmzRrTpRjxj3/8Q/Pnz9fMmTP1n//5n1qzZo2uuuoqZWZmatq0aabLS7kbbrhBfr9fI0eOlNvtVjAY1Jw5c1RaWmq6NCO2bdsmSa3+Xoy81pvs2rVL119/vc4777xec6PCu+66Sx6PR1dddZWR9yeooE1lZWX69NNP9c4775guxTEVFRW6+uqrtWzZMmVlZZkux4hQKKRx48bpjjvukCQdcsgh+vTTT/XII4/0iqDy/PPPa+HChVq0aJFGjRql9evXa8aMGSouLu4Vnx9ta2ho0DnnnCPbtjV//nzT5Thi7dq1uv/++7Vu3TpZlmWkBi79xBgwYIDcbre+//77uO3ff/+9CgsLDVVlxpVXXqlXXnlFb775pvbee2/T5Thm7dq1qqys1KGHHiqPxyOPx6OVK1fqgQcekMfjUTAYNF1iyhUVFemggw6K23bggQfq22+/NVSRs6677jrdcMMNOvfcc3XwwQfrwgsv1DXXXKPy8nLTpRkR+d3X238vRkLK5s2btWzZsl7TmvL222+rsrJSQ4YMif5O3Lx5s/7jP/5Dw4YNc6QGgkqMzMxMHXbYYVqxYkV0WygU0ooVKzRhwgSDlTnHtm1deeWVWrx4sd544w0NHz7cdEmOOv744/XJJ59o/fr10ce4ceNUWlqq9evXy+12my4x5SZOnNhiSPrGjRs1dOhQQxU5q66uTi5X/K9Gt9utUChkqCKzhg8frsLCwrjfi36/Xx988EGv+b0YCSlffvmlli9frv79+5suyTEXXnih/va3v8X9TiwuLtZ1112npUuXOlIDl36amTlzpqZNm6Zx48bp8MMP17x581RbW6uLL77YdGmOKCsr06JFi/SXv/xFPp8veg26oKBA2dnZhqtLPZ/P16I/Tm5urvr3799r+ulcc801OvLII3XHHXfonHPO0erVq7VgwQItWLDAdGmOmDJliubMmaMhQ4Zo1KhR+uijjzR37lxdcsklpktLmZqaGn311VfR9U2bNmn9+vXq16+fhgwZohkzZuj3v/+9RowYoeHDh2v27NkqLi7WGWecYa7oJGrv8xcVFemss87SunXr9MorrygYDEZ/L/br10+ZmZmmyk6ajn7+zYNZRkaGCgsLdcABBzhToGPji3qQBx980B4yZIidmZlpH3744faqVatMl+QYSa0+nnjiCdOlGdPbhifbtm3/z//8jz169Gjb6/XaI0eOtBcsWGC6JMf4/X776quvtocMGWJnZWXZ++yzj33jjTfagUDAdGkp8+abb7b63/20adNs2w4PUZ49e7Y9ePBg2+v12scff7y9YcMGs0UnUXuff9OmTW3+XnzzzTdNl54UHf38m3N6eLJl23vwdIsAAKBHo48KAABIWwQVAACQtggqAAAgbRFUAABA2iKoAACAtEVQAQAAaYugAgAA0hZBBQAApC2CCoA9imVZevnll02XASBJCCoAkmb69OmyLKvF4+STTzZdGoAeipsSAkiqk08+WU888UTcNq/Xa6gaAD0dLSoAksrr9aqwsDDu0bdvX0nhyzLz58/X5MmTlZ2drX322Ucvvvhi3PGffPKJjjvuOGVnZ6t///669NJLVVNTE7fPn/70J40aNUper1dFRUW68sor417fvn27pk6dqpycHI0YMUJLlixJ7YcGkDIEFQCOmj17tn7961/r448/Vmlpqc4991x98cUXkqTa2lpNmjRJffv21Zo1a/TCCy9o+fLlcUFk/vz5Kisr06WXXqpPPvlES5Ys0X777Rf3HrfeeqvOOecc/e1vf9Mpp5yi0tJS/fTTT45+TgBJ4th9mgHs8aZNm2a73W47Nzc37jFnzhzbtm1bkn3ZZZfFHXPEEUfYl19+uW3btr1gwQK7b9++dk1NTfT1V1991Xa5XPa2bdts27bt4uJi+8Ybb2yzBkn27373u+h6TU2NLcl+7bXXkvY5ATiHPioAkurYY4/V/Pnz47b169cvujxhwoS41yZMmKD169dLkr744guNHTtWubm50dcnTpyoUCikDRs2yLIsbdmyRccff3y7NYwZMya6nJubq/z8fFVWVnb3IwEwiKACIKlyc3NbXIpJluzs7E7tl5GREbduWZZCoVAqSgKQYvRRAeCoVatWtVg/8MADJUkHHnigPv74Y9XW1kZff/fdd+VyuXTAAQfI5/Np2LBhWrFihaM1AzCHFhUASRUIBLRt27a4bR6PRwMGDJAkvfDCCxo3bpyOOuooLVy4UKtXr9bjjz8uSSotLdXNN9+sadOm6ZZbbtEPP/yg3/72t7rwwgs1ePBgSdItt9yiyy67TIMGDdLkyZNVXV2td999V7/97W+d/aAAHEFQAZBUr7/+uoqKiuK2HXDAAfr73/8uKTwi59lnn9UVV1yhoqIiPfPMMzrooIMkSTk5OVq6dKmuvvpqjR8/Xjk5Ofr1r3+tuXPnRs81bdo07dq1S/fdd5+uvfZaDRgwQGeddZZzHxCAoyzbtm3TRQDoHSzL0uLFi3XGGWeYLgVAD0EfFQAAkLYIKgAAIG3RRwWAY7jSDKCraFEBAABpi6ACAADSFkEFAACkLYIKAABIWwQVAACQtggqAAAgbRFUAABA2iKoAACAtPX/ARkKFmyzewEVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se visualiza el proceso de entrenamiento.\n",
        "# Esta función traza la pérdida del modelo durante el entrenamiento.\n",
        "modelhandler.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E52bTEXnG09W",
        "outputId": "55eab4e0-a9be-4c7b-f183-34c6573e1571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se busca la pérdida mínima en la validación, que corresponde al mejor modelo.\n",
        "# 'np.argmin' devuelve el índice de la pérdida mínima en el conjunto de validación.\n",
        "# Se suma 1 porque los índices en Python comienzan en 0, pero las épocas comienzan en 1.\n",
        "np.argmin(modelhandler.running_record['val']['loss'])+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kH5xVXQyG09W",
        "outputId": "386e7798-c7b4-4bcf-f065-10a443baf108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pv_vision.nn.modelhandler:Loaded model from /content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints/epoch_14/unetv6.pt\n"
          ]
        }
      ],
      "source": [
        "# Se carga el mejor modelo entrenado y se verifica su rendimiento en el conjunto de prueba.\n",
        "# Se emplea `load_model` para cargar el modelo entrenado. Este método toma el nombre del archivo de punto de control.\n",
        "modelhandler.load_model('/content/drive/MyDrive/Trabajo de titulación/PV_vision/Entrenamiento/PuntosControl/checkpoints/epoch_14/unetv6.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-Fdu8ZG09W"
      },
      "source": [
        "El siguiente código prueba el modelo en el conjunto de prueba y almacena la salida en 'testset_output'. También se hace un comentario sobre la puntuación de la prueba y la puntuación de la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1q3LEUNaG09W",
        "outputId": "f6f996b0-b479-4e9f-a42f-7f06beb69c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [04:31<00:00, 11.80s/it]\n",
            "INFO:pv_vision.nn.modelhandler:Test set: Average loss: 0.1331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1331\n"
          ]
        }
      ],
      "source": [
        "# Se evalúa el modelo en el conjunto de prueba. `test_model` es una función de ModelHandler\n",
        "# que evalúa el modelo en el conjunto de prueba y almacena la salida en la caché.\n",
        "_ = modelhandler.test_model(cache_output='testset_output')\n",
        "\n",
        "# La salida del modelo se almacena en self.cache['testset_output']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}